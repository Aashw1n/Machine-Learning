{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "import requests\n",
    "import io\n",
    "\n",
    "       \n",
    "#url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.254</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.455</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>117.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.403</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>1.127</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.855</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "303              0                   161.0            50.0             0.0   \n",
       "656              0                   179.0            50.0            36.0   \n",
       "137              1                   117.0            88.0            24.0   \n",
       "323              7                   109.0            80.0            31.0   \n",
       "75               0                   109.0            88.0            30.0   \n",
       "\n",
       "     insulin   bmi  pedigree_function   age  has_diabetes  \n",
       "303      0.0  21.9              0.254  65.0           0.0  \n",
       "656    159.0  37.8              0.455  22.0           1.0  \n",
       "137    145.0  34.5              0.403  40.0           1.0  \n",
       "323      0.0  35.9              1.127  43.0           1.0  \n",
       "75       0.0  32.5              0.855  38.0           1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n",
      "777\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "X = X[9:]\n",
    "y = y[9:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions.\n",
    "\n",
    "__Note:__ AUROC is a figure for comparing **false positive rate** to **true positive rate**. To know more about how to calculate AUROC refer to __[here](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it)__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.832\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "\n",
    "# predict(X)\n",
    "# Predict class for X.\n",
    "# predict_proba(X)\n",
    "# Predict class probabilities for X.\n",
    "\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Below two results should be equal for big data sets.\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code will generate AUROC plot for the random forest prediction result.<br>\n",
    "The **Accuracy** in AUROC is measured by the area under the ROC curve. An area of 1 represents a perfect test; an area of .5 represents a worthless. <br>\n",
    "The x axis is the **False positive rate (FPR)** and the y axis is the **True positive rate (TPR)**. Check this __[Ref](http://gim.unmc.edu/dxtests/roc3.htm)__ for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "## The StandardScaler assumes your data is normally distributed within each feature and will scale them such \n",
    "## that the distribution is now centred around 0, with a standard deviation of 1.\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Conda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 740us/step - loss: 0.9340 - acc: 0.3264 - val_loss: 0.8772 - val_acc: 0.3646\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.9139 - acc: 0.3351 - val_loss: 0.8618 - val_acc: 0.3646\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.8951 - acc: 0.3351 - val_loss: 0.8474 - val_acc: 0.3542\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.8775 - acc: 0.3455 - val_loss: 0.8340 - val_acc: 0.3594\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.8612 - acc: 0.3698 - val_loss: 0.8214 - val_acc: 0.3698\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.8458 - acc: 0.3802 - val_loss: 0.8096 - val_acc: 0.3802\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.8314 - acc: 0.3785 - val_loss: 0.7985 - val_acc: 0.3958\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.8179 - acc: 0.3854 - val_loss: 0.7882 - val_acc: 0.4010\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.8052 - acc: 0.4010 - val_loss: 0.7784 - val_acc: 0.4062\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7933 - acc: 0.4080 - val_loss: 0.7693 - val_acc: 0.4115\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7820 - acc: 0.4375 - val_loss: 0.7606 - val_acc: 0.4219\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.7713 - acc: 0.4479 - val_loss: 0.7525 - val_acc: 0.4323\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.7614 - acc: 0.4792 - val_loss: 0.7447 - val_acc: 0.4479\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.7519 - acc: 0.4896 - val_loss: 0.7374 - val_acc: 0.4740\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7430 - acc: 0.5069 - val_loss: 0.7304 - val_acc: 0.4792\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.7345 - acc: 0.5035 - val_loss: 0.7238 - val_acc: 0.4948\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.7265 - acc: 0.5226 - val_loss: 0.7175 - val_acc: 0.5104\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7190 - acc: 0.5295 - val_loss: 0.7114 - val_acc: 0.5365\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.7118 - acc: 0.5434 - val_loss: 0.7057 - val_acc: 0.5573\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7049 - acc: 0.5556 - val_loss: 0.7002 - val_acc: 0.5677\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6984 - acc: 0.5556 - val_loss: 0.6950 - val_acc: 0.5833\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6923 - acc: 0.5625 - val_loss: 0.6899 - val_acc: 0.5938\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6863 - acc: 0.5781 - val_loss: 0.6851 - val_acc: 0.5938\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6806 - acc: 0.5833 - val_loss: 0.6805 - val_acc: 0.5885\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6753 - acc: 0.5833 - val_loss: 0.6760 - val_acc: 0.5990\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6702 - acc: 0.5833 - val_loss: 0.6717 - val_acc: 0.5990\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6652 - acc: 0.5955 - val_loss: 0.6676 - val_acc: 0.5990\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6605 - acc: 0.5990 - val_loss: 0.6637 - val_acc: 0.5990\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.6560 - acc: 0.6007 - val_loss: 0.6599 - val_acc: 0.6094\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6517 - acc: 0.6111 - val_loss: 0.6562 - val_acc: 0.6198\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6476 - acc: 0.6233 - val_loss: 0.6527 - val_acc: 0.6302\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6436 - acc: 0.6267 - val_loss: 0.6493 - val_acc: 0.6250\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6398 - acc: 0.6285 - val_loss: 0.6460 - val_acc: 0.6406\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6362 - acc: 0.6319 - val_loss: 0.6429 - val_acc: 0.6406\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6327 - acc: 0.6424 - val_loss: 0.6398 - val_acc: 0.6510\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6293 - acc: 0.6510 - val_loss: 0.6369 - val_acc: 0.6562\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6260 - acc: 0.6562 - val_loss: 0.6340 - val_acc: 0.6615\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6228 - acc: 0.6615 - val_loss: 0.6311 - val_acc: 0.6719\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6197 - acc: 0.6701 - val_loss: 0.6284 - val_acc: 0.6719\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6167 - acc: 0.6719 - val_loss: 0.6257 - val_acc: 0.6771\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6139 - acc: 0.6753 - val_loss: 0.6232 - val_acc: 0.6771\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6111 - acc: 0.6771 - val_loss: 0.6207 - val_acc: 0.6823\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6084 - acc: 0.6788 - val_loss: 0.6183 - val_acc: 0.6875\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6058 - acc: 0.6753 - val_loss: 0.6159 - val_acc: 0.6875\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6032 - acc: 0.6806 - val_loss: 0.6137 - val_acc: 0.6875\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6007 - acc: 0.6788 - val_loss: 0.6114 - val_acc: 0.6927\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5983 - acc: 0.6806 - val_loss: 0.6092 - val_acc: 0.6927\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5959 - acc: 0.6823 - val_loss: 0.6071 - val_acc: 0.6927\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5936 - acc: 0.6823 - val_loss: 0.6050 - val_acc: 0.6927\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5913 - acc: 0.6806 - val_loss: 0.6030 - val_acc: 0.6927\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5892 - acc: 0.6840 - val_loss: 0.6011 - val_acc: 0.6927\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5870 - acc: 0.6840 - val_loss: 0.5991 - val_acc: 0.6979\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5849 - acc: 0.6840 - val_loss: 0.5972 - val_acc: 0.7031\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5829 - acc: 0.6910 - val_loss: 0.5954 - val_acc: 0.7083\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5809 - acc: 0.6927 - val_loss: 0.5936 - val_acc: 0.7135\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5790 - acc: 0.6962 - val_loss: 0.5918 - val_acc: 0.7188\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5771 - acc: 0.7031 - val_loss: 0.5901 - val_acc: 0.7188\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5753 - acc: 0.7083 - val_loss: 0.5884 - val_acc: 0.7188\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5735 - acc: 0.7118 - val_loss: 0.5867 - val_acc: 0.7135\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5717 - acc: 0.7135 - val_loss: 0.5851 - val_acc: 0.7135\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5700 - acc: 0.7135 - val_loss: 0.5835 - val_acc: 0.7188\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5683 - acc: 0.7135 - val_loss: 0.5819 - val_acc: 0.7188\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5667 - acc: 0.7135 - val_loss: 0.5804 - val_acc: 0.7135\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5650 - acc: 0.7170 - val_loss: 0.5789 - val_acc: 0.7188\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5635 - acc: 0.7170 - val_loss: 0.5774 - val_acc: 0.7188\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5619 - acc: 0.7170 - val_loss: 0.5760 - val_acc: 0.7188\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5604 - acc: 0.7135 - val_loss: 0.5746 - val_acc: 0.7188\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5589 - acc: 0.7135 - val_loss: 0.5732 - val_acc: 0.7188\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5575 - acc: 0.7135 - val_loss: 0.5719 - val_acc: 0.7240\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5560 - acc: 0.7135 - val_loss: 0.5706 - val_acc: 0.7240\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5547 - acc: 0.7118 - val_loss: 0.5693 - val_acc: 0.7240\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5533 - acc: 0.7135 - val_loss: 0.5681 - val_acc: 0.7240\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5520 - acc: 0.7170 - val_loss: 0.5668 - val_acc: 0.7188\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5507 - acc: 0.7188 - val_loss: 0.5656 - val_acc: 0.7188\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5494 - acc: 0.7170 - val_loss: 0.5644 - val_acc: 0.7188\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5481 - acc: 0.7205 - val_loss: 0.5633 - val_acc: 0.7188\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5469 - acc: 0.7205 - val_loss: 0.5621 - val_acc: 0.7240\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5457 - acc: 0.7222 - val_loss: 0.5610 - val_acc: 0.7240\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5445 - acc: 0.7222 - val_loss: 0.5599 - val_acc: 0.7240\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5433 - acc: 0.7257 - val_loss: 0.5588 - val_acc: 0.7240\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5422 - acc: 0.7257 - val_loss: 0.5578 - val_acc: 0.7292\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5410 - acc: 0.7257 - val_loss: 0.5567 - val_acc: 0.7292\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5399 - acc: 0.7292 - val_loss: 0.5557 - val_acc: 0.7344\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5388 - acc: 0.7274 - val_loss: 0.5547 - val_acc: 0.7292\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5377 - acc: 0.7292 - val_loss: 0.5537 - val_acc: 0.7292\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5367 - acc: 0.7292 - val_loss: 0.5528 - val_acc: 0.7344\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5357 - acc: 0.7326 - val_loss: 0.5518 - val_acc: 0.7344\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5346 - acc: 0.7326 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5336 - acc: 0.7396 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5326 - acc: 0.7413 - val_loss: 0.5491 - val_acc: 0.7344\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5317 - acc: 0.7378 - val_loss: 0.5482 - val_acc: 0.7344\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5307 - acc: 0.7396 - val_loss: 0.5473 - val_acc: 0.7344\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5297 - acc: 0.7396 - val_loss: 0.5465 - val_acc: 0.7396\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5288 - acc: 0.7361 - val_loss: 0.5457 - val_acc: 0.7396\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5279 - acc: 0.7396 - val_loss: 0.5448 - val_acc: 0.7344\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5270 - acc: 0.7413 - val_loss: 0.5440 - val_acc: 0.7344\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5261 - acc: 0.7396 - val_loss: 0.5433 - val_acc: 0.7344\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5252 - acc: 0.7431 - val_loss: 0.5425 - val_acc: 0.7344\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5243 - acc: 0.7413 - val_loss: 0.5417 - val_acc: 0.7344\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5235 - acc: 0.7448 - val_loss: 0.5410 - val_acc: 0.7344\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5226 - acc: 0.7431 - val_loss: 0.5402 - val_acc: 0.7344\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5218 - acc: 0.7465 - val_loss: 0.5395 - val_acc: 0.7344\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5210 - acc: 0.7483 - val_loss: 0.5388 - val_acc: 0.7344\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5202 - acc: 0.7483 - val_loss: 0.5381 - val_acc: 0.7344\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5194 - acc: 0.7483 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5186 - acc: 0.7465 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5179 - acc: 0.7465 - val_loss: 0.5361 - val_acc: 0.7396\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5171 - acc: 0.7483 - val_loss: 0.5355 - val_acc: 0.7448\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5163 - acc: 0.7500 - val_loss: 0.5348 - val_acc: 0.7552\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5156 - acc: 0.7483 - val_loss: 0.5342 - val_acc: 0.7552\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5149 - acc: 0.7483 - val_loss: 0.5336 - val_acc: 0.7552\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5142 - acc: 0.7500 - val_loss: 0.5330 - val_acc: 0.7552\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5135 - acc: 0.7517 - val_loss: 0.5324 - val_acc: 0.7552\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5128 - acc: 0.7535 - val_loss: 0.5318 - val_acc: 0.7552\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5121 - acc: 0.7569 - val_loss: 0.5312 - val_acc: 0.7552\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5114 - acc: 0.7569 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5107 - acc: 0.7569 - val_loss: 0.5301 - val_acc: 0.7552\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5101 - acc: 0.7569 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.5094 - acc: 0.7569 - val_loss: 0.5291 - val_acc: 0.7552\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5088 - acc: 0.7569 - val_loss: 0.5285 - val_acc: 0.7552\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5082 - acc: 0.7552 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5076 - acc: 0.7552 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5070 - acc: 0.7552 - val_loss: 0.5270 - val_acc: 0.7604\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5063 - acc: 0.7552 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5058 - acc: 0.7535 - val_loss: 0.5261 - val_acc: 0.7604\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5052 - acc: 0.7587 - val_loss: 0.5256 - val_acc: 0.7604\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5046 - acc: 0.7569 - val_loss: 0.5251 - val_acc: 0.7552\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5040 - acc: 0.7587 - val_loss: 0.5247 - val_acc: 0.7552\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5034 - acc: 0.7622 - val_loss: 0.5242 - val_acc: 0.7552\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5029 - acc: 0.7622 - val_loss: 0.5238 - val_acc: 0.7552\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5024 - acc: 0.7639 - val_loss: 0.5234 - val_acc: 0.7552\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5018 - acc: 0.7656 - val_loss: 0.5230 - val_acc: 0.7552\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5013 - acc: 0.7674 - val_loss: 0.5226 - val_acc: 0.7552\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5008 - acc: 0.7656 - val_loss: 0.5222 - val_acc: 0.7552\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5003 - acc: 0.7674 - val_loss: 0.5218 - val_acc: 0.7552\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4998 - acc: 0.7674 - val_loss: 0.5214 - val_acc: 0.7552\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4993 - acc: 0.7674 - val_loss: 0.5210 - val_acc: 0.7552\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4988 - acc: 0.7674 - val_loss: 0.5206 - val_acc: 0.7552\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4983 - acc: 0.7604 - val_loss: 0.5203 - val_acc: 0.7552\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4978 - acc: 0.7622 - val_loss: 0.5199 - val_acc: 0.7552\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5147 - acc: 0.718 - 0s 36us/step - loss: 0.4974 - acc: 0.7604 - val_loss: 0.5196 - val_acc: 0.7552\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4969 - acc: 0.7604 - val_loss: 0.5192 - val_acc: 0.7552\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4965 - acc: 0.7587 - val_loss: 0.5189 - val_acc: 0.7552\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4960 - acc: 0.7587 - val_loss: 0.5186 - val_acc: 0.7552\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4955 - acc: 0.7622 - val_loss: 0.5182 - val_acc: 0.7552\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4951 - acc: 0.7604 - val_loss: 0.5179 - val_acc: 0.7552\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4947 - acc: 0.7604 - val_loss: 0.5176 - val_acc: 0.7552\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4943 - acc: 0.7604 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4938 - acc: 0.7622 - val_loss: 0.5170 - val_acc: 0.7552\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4934 - acc: 0.7639 - val_loss: 0.5167 - val_acc: 0.7604\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4930 - acc: 0.7622 - val_loss: 0.5164 - val_acc: 0.7656\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4926 - acc: 0.7656 - val_loss: 0.5161 - val_acc: 0.7656\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4922 - acc: 0.7674 - val_loss: 0.5158 - val_acc: 0.7656\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4918 - acc: 0.7691 - val_loss: 0.5156 - val_acc: 0.7656\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4914 - acc: 0.7674 - val_loss: 0.5153 - val_acc: 0.7656\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4911 - acc: 0.7691 - val_loss: 0.5150 - val_acc: 0.7656\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4907 - acc: 0.7691 - val_loss: 0.5148 - val_acc: 0.7656\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4903 - acc: 0.7691 - val_loss: 0.5145 - val_acc: 0.7656\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4900 - acc: 0.7691 - val_loss: 0.5142 - val_acc: 0.7656\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4896 - acc: 0.7691 - val_loss: 0.5140 - val_acc: 0.7656\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4893 - acc: 0.7708 - val_loss: 0.5138 - val_acc: 0.7656\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4889 - acc: 0.7708 - val_loss: 0.5135 - val_acc: 0.7656\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4886 - acc: 0.7708 - val_loss: 0.5133 - val_acc: 0.7656\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4882 - acc: 0.7708 - val_loss: 0.5131 - val_acc: 0.7656\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4879 - acc: 0.7726 - val_loss: 0.5128 - val_acc: 0.7708\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4875 - acc: 0.7726 - val_loss: 0.5126 - val_acc: 0.7708\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4872 - acc: 0.7726 - val_loss: 0.5124 - val_acc: 0.7708\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4869 - acc: 0.7760 - val_loss: 0.5122 - val_acc: 0.7760\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4866 - acc: 0.7760 - val_loss: 0.5120 - val_acc: 0.7760\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4862 - acc: 0.7743 - val_loss: 0.5118 - val_acc: 0.7760\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4859 - acc: 0.7743 - val_loss: 0.5116 - val_acc: 0.7812\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4856 - acc: 0.7760 - val_loss: 0.5115 - val_acc: 0.7812\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4853 - acc: 0.7743 - val_loss: 0.5113 - val_acc: 0.7812\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4850 - acc: 0.7708 - val_loss: 0.5111 - val_acc: 0.7812\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4847 - acc: 0.7726 - val_loss: 0.5109 - val_acc: 0.7812\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4844 - acc: 0.7726 - val_loss: 0.5108 - val_acc: 0.7812\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4841 - acc: 0.7708 - val_loss: 0.5106 - val_acc: 0.7812\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4838 - acc: 0.7760 - val_loss: 0.5104 - val_acc: 0.7812\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4835 - acc: 0.7743 - val_loss: 0.5103 - val_acc: 0.7812\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4832 - acc: 0.7726 - val_loss: 0.5101 - val_acc: 0.7812\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4829 - acc: 0.7726 - val_loss: 0.5099 - val_acc: 0.7812\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4826 - acc: 0.7760 - val_loss: 0.5098 - val_acc: 0.7812\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4823 - acc: 0.7760 - val_loss: 0.5096 - val_acc: 0.7812\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5538 - acc: 0.750 - 0s 42us/step - loss: 0.4821 - acc: 0.7743 - val_loss: 0.5095 - val_acc: 0.7812\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4818 - acc: 0.7743 - val_loss: 0.5093 - val_acc: 0.7812\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4815 - acc: 0.7760 - val_loss: 0.5092 - val_acc: 0.7812\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4813 - acc: 0.7778 - val_loss: 0.5091 - val_acc: 0.7812\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4810 - acc: 0.7778 - val_loss: 0.5089 - val_acc: 0.7812\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4808 - acc: 0.7778 - val_loss: 0.5088 - val_acc: 0.7812\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4805 - acc: 0.7795 - val_loss: 0.5087 - val_acc: 0.7865\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4803 - acc: 0.7795 - val_loss: 0.5085 - val_acc: 0.7865\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4800 - acc: 0.7812 - val_loss: 0.5084 - val_acc: 0.7865\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4797 - acc: 0.7812 - val_loss: 0.5083 - val_acc: 0.7865\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4795 - acc: 0.7812 - val_loss: 0.5082 - val_acc: 0.7865\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4793 - acc: 0.7830 - val_loss: 0.5081 - val_acc: 0.7865\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4790 - acc: 0.7830 - val_loss: 0.5079 - val_acc: 0.7865\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4788 - acc: 0.7830 - val_loss: 0.5078 - val_acc: 0.7865\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4786 - acc: 0.7830 - val_loss: 0.5077 - val_acc: 0.7865\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4784 - acc: 0.7830 - val_loss: 0.5076 - val_acc: 0.7812\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4781 - acc: 0.7830 - val_loss: 0.5075 - val_acc: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48051032],\n",
       "       [0.7046775 ],\n",
       "       [0.220938  ],\n",
       "       [0.1712474 ],\n",
       "       [0.21636963],\n",
       "       [0.40717775],\n",
       "       [0.08508104],\n",
       "       [0.27732122],\n",
       "       [0.73519886],\n",
       "       [0.24163154]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2611658a320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4779 - acc: 0.7830 - val_loss: 0.5074 - val_acc: 0.7812\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4777 - acc: 0.7847 - val_loss: 0.5073 - val_acc: 0.7812\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4775 - acc: 0.7847 - val_loss: 0.5072 - val_acc: 0.7812\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4772 - acc: 0.7847 - val_loss: 0.5071 - val_acc: 0.7812\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4770 - acc: 0.7847 - val_loss: 0.5070 - val_acc: 0.7812\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4768 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7812\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4766 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4764 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4762 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4760 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4758 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4756 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4754 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4752 - acc: 0.7865 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4750 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4748 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4746 - acc: 0.7847 - val_loss: 0.5061 - val_acc: 0.7812\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4744 - acc: 0.7847 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4742 - acc: 0.7847 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4741 - acc: 0.7865 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4739 - acc: 0.7847 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4737 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4735 - acc: 0.7847 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4733 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4732 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7760\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4730 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7708\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4728 - acc: 0.7899 - val_loss: 0.5056 - val_acc: 0.7708\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4727 - acc: 0.7899 - val_loss: 0.5055 - val_acc: 0.7708\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4725 - acc: 0.7899 - val_loss: 0.5055 - val_acc: 0.7708\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4724 - acc: 0.7899 - val_loss: 0.5054 - val_acc: 0.7708\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4722 - acc: 0.7899 - val_loss: 0.5054 - val_acc: 0.7708\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4721 - acc: 0.7899 - val_loss: 0.5053 - val_acc: 0.7708\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4719 - acc: 0.7899 - val_loss: 0.5053 - val_acc: 0.7708\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4717 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4715 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4714 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4712 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4710 - acc: 0.7882 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4709 - acc: 0.7882 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4707 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4705 - acc: 0.7882 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4704 - acc: 0.7882 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4702 - acc: 0.7882 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4701 - acc: 0.7882 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4700 - acc: 0.7882 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4698 - acc: 0.7882 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4697 - acc: 0.7882 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4695 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4694 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4692 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4691 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4689 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4688 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4687 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4685 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4684 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4682 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4681 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4680 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4679 - acc: 0.7917 - val_loss: 0.5044 - val_acc: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4677 - acc: 0.7917 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4676 - acc: 0.7917 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4675 - acc: 0.7917 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4673 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4672 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4671 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4669 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4668 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4667 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4666 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4665 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4663 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4662 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4661 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4660 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4658 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4657 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4656 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4655 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4653 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4652 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4651 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4650 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4649 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4648 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4647 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4645 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4644 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4643 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4642 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4641 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4640 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4639 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4638 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4637 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4635 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4635 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4633 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4632 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3591 - acc: 0.812 - 0s 40us/step - loss: 0.4631 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4630 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4629 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4628 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4627 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4626 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4625 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4625 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4623 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4622 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4621 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4621 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4620 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4619 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4618 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4617 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7812\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4616 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4615 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4614 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4614 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4613 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4612 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7812\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4611 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4610 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4609 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4609 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4608 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4607 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4607 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4606 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4605 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4604 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4603 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4602 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4602 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4601 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4600 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4599 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4598 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4598 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4597 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4596 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4596 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4595 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4594 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4593 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4593 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4592 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4591 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4590 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4590 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4589 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4587 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4586 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4586 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4585 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4584 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4583 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4583 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4582 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4581 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7812\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4580 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7812\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4580 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7812\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4579 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4579 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4578 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4577 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4576 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4576 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4575 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4575 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4574 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4573 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7812\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4573 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7812\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4572 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7812\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4572 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7812\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4570 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7812\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4570 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7865\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4570 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4569 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4568 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4568 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4567 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4567 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4566 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4565 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7865\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4564 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4564 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4563 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4563 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4562 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4561 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4561 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4560 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4559 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4559 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4558 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4558 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4557 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4557 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4556 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4556 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4555 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4554 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4554 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4553 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4553 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4552 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4552 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4551 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4551 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4550 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4550 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4549 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4548 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4548 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4548 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7865\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4547 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4547 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4546 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4546 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4545 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4545 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4544 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4544 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4543 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4543 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4542 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4542 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4542 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4541 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4540 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4540 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4540 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4539 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7865\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4539 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4538 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4538 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4537 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4537 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4536 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4536 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4535 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4535 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4535 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4535 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4534 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7865\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4533 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4533 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4532 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4532 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4532 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4531 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4531 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4530 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4530 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4530 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4529 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4529 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4528 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4528 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4527 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4527 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4527 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4526 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4526 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4525 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4525 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4525 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4524 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4524 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4524 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4523 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4523 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4522 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4522 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4522 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4521 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4521 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4520 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4520 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4520 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4519 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4519 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4518 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4518 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4518 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4517 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4517 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4516 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4516 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4516 - acc: 0.7865 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4515 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4515 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4515 - acc: 0.7865 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4514 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4514 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4513 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4513 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4512 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4512 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4512 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4511 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4511 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4511 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4510 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7865\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4510 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4510 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4509 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4509 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4508 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4508 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4508 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4506 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4506 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4506 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7865\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7812\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7812\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7812\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4504 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7812\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4504 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7812\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4504 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7812\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4503 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7812\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4503 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4503 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4502 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4502 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4501 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4501 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4501 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4501 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4501 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4500 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4500 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4499 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4499 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4499 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4499 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7865\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4498 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4498 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4498 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4497 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4497 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4496 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4496 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4496 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4496 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4495 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4495 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4495 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4495 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7865\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4493 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4493 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4490 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4490 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4490 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7865\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4489 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4489 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4489 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4488 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4488 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4488 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4486 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4486 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4486 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4485 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4485 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4485 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4484 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4484 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4484 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4484 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4483 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4483 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4483 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4482 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4482 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4482 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4481 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4481 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4480 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4480 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4480 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4479 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4479 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4479 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4478 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4478 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4477 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4477 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4477 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4476 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4476 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4475 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4475 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4475 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4475 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4474 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4474 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4474 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4472 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4472 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4471 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4471 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4471 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4470 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4470 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7865\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4470 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4469 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4469 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4469 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4468 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4468 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4468 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4467 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4467 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4467 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4466 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4466 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4466 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4465 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4465 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4465 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4464 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4464 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4463 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4463 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4463 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4463 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4462 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4462 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4461 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4461 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4461 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4460 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4460 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4460 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4459 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4459 - acc: 0.7899 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4459 - acc: 0.7899 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4458 - acc: 0.7882 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4458 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7865\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4456 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4456 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4456 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4455 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4455 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4455 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4454 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7865\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4454 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4454 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4453 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4453 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4453 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4452 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4452 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4451 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4451 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4451 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - acc: 0.7847 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4449 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4449 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4449 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4448 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4448 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7812\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4448 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4448 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4447 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4447 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4446 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4446 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4445 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4445 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4445 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4445 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7812\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4444 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4443 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4443 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4443 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4442 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4442 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4442 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4440 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4440 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7812\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4440 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4439 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3683 - acc: 0.812 - 0s 38us/step - loss: 0.4439 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4439 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4438 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4438 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4438 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4438 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4437 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4437 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4436 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4436 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4435 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4434 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4434 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4434 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4434 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4433 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4433 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4433 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4432 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4432 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4432 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4431 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4431 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4431 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4430 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4430 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4430 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4429 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4429 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4429 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4428 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4428 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4427 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7812\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4427 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4427 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4427 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4426 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4426 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4426 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4425 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4425 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4425 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4424 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4423 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4423 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4423 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4422 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4422 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4422 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4421 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4421 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4420 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4420 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4419 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4418 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4418 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4418 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4418 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4417 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4416 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4416 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4416 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4416 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4415 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4414 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4414 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4413 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4413 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4413 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4413 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4412 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4412 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4411 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4412 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4411 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4410 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4410 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4410 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4410 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4409 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4409 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4408 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4408 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4408 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4408 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4406 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4406 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4406 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4405 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4405 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4405 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4404 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4404 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4403 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4403 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4403 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4403 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4402 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4402 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4402 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4401 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4401 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4401 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4401 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3842 - acc: 0.781 - 0s 38us/step - loss: 0.4400 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4400 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4400 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4399 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4399 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4399 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4399 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4398 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4398 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4397 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4397 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4397 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4397 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4396 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4396 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4394 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4394 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4394 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4394 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7812\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7812\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4382 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4382 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4381 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4380 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4380 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4380 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7847 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4379 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4378 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4377 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4377 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4377 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4376 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4376 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4375 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4374 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4374 - acc: 0.7830 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4373 - acc: 0.7830 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4373 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4373 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4373 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4372 - acc: 0.7847 - val_loss: 0.5065 - val_acc: 0.7760\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4372 - acc: 0.7830 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4372 - acc: 0.7847 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4372 - acc: 0.7847 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4370 - acc: 0.7847 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4370 - acc: 0.7847 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4369 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4369 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4368 - acc: 0.7865 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4368 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4368 - acc: 0.7865 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4368 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7708\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4367 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7708\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7708\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4366 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7656\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7656\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4366 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7656\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4365 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4365 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4365 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4364 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4364 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4363 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4364 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4363 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7656\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4363 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4363 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4362 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4362 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4362 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4361 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4361 - acc: 0.7865 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4361 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4361 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7708\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4357 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4357 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7708\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4357 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4356 - acc: 0.7865 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4356 - acc: 0.7865 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4354 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4353 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7812\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7865\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4350 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4350 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4350 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4350 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7865\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7812\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7812\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - acc: 0.7882 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4338 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4337 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4337 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4337 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4337 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4336 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4333 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7708\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4333 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7708\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4333 - acc: 0.7882 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4332 - acc: 0.7882 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4332 - acc: 0.7882 - val_loss: 0.5052 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4332 - acc: 0.7882 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4332 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5126 - acc: 0.656 - 0s 43us/step - loss: 0.4331 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4331 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4331 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7708\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4330 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4330 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4330 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.7760\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4321 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4320 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4319 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4319 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4319 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4318 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4318 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4317 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4317 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4317 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4317 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4316 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4316 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4315 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4315 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4315 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4314 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4314 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4314 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4313 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4313 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4313 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4313 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4312 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4312 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4311 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4311 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4310 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4307 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4306 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4306 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4306 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4305 - acc: 0.7917 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4305 - acc: 0.7899 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - acc: 0.7899 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4304 - acc: 0.7917 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - acc: 0.7934 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4303 - acc: 0.7934 - val_loss: 0.5040 - val_acc: 0.7760\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26116625d68>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 1s 897us/step - loss: 0.6126 - acc: 0.6545 - val_loss: 0.6279 - val_acc: 0.6406\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6104 - acc: 0.6545 - val_loss: 0.6261 - val_acc: 0.6406\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6082 - acc: 0.6545 - val_loss: 0.6243 - val_acc: 0.6406\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6061 - acc: 0.6545 - val_loss: 0.6226 - val_acc: 0.6406\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6040 - acc: 0.6545 - val_loss: 0.6209 - val_acc: 0.6406\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6020 - acc: 0.6545 - val_loss: 0.6192 - val_acc: 0.6406\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6000 - acc: 0.6545 - val_loss: 0.6176 - val_acc: 0.6406\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5980 - acc: 0.6545 - val_loss: 0.6160 - val_acc: 0.6406\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5961 - acc: 0.6545 - val_loss: 0.6145 - val_acc: 0.6406\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5942 - acc: 0.6545 - val_loss: 0.6130 - val_acc: 0.6406\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5923 - acc: 0.6545 - val_loss: 0.6115 - val_acc: 0.6406\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5904 - acc: 0.6545 - val_loss: 0.6100 - val_acc: 0.6406\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5886 - acc: 0.6545 - val_loss: 0.6086 - val_acc: 0.6406\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5868 - acc: 0.6545 - val_loss: 0.6072 - val_acc: 0.6406\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5851 - acc: 0.6545 - val_loss: 0.6059 - val_acc: 0.6406\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5834 - acc: 0.6545 - val_loss: 0.6046 - val_acc: 0.6406\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5817 - acc: 0.6545 - val_loss: 0.6033 - val_acc: 0.6406\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5800 - acc: 0.6545 - val_loss: 0.6020 - val_acc: 0.6406\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5784 - acc: 0.6545 - val_loss: 0.6008 - val_acc: 0.6406\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5768 - acc: 0.6545 - val_loss: 0.5996 - val_acc: 0.6406\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5752 - acc: 0.6545 - val_loss: 0.5985 - val_acc: 0.6406\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5736 - acc: 0.6545 - val_loss: 0.5973 - val_acc: 0.6406\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5721 - acc: 0.6545 - val_loss: 0.5962 - val_acc: 0.6406\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5706 - acc: 0.6545 - val_loss: 0.5952 - val_acc: 0.6406\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5692 - acc: 0.6545 - val_loss: 0.5941 - val_acc: 0.6406\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5677 - acc: 0.6545 - val_loss: 0.5931 - val_acc: 0.6406\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5663 - acc: 0.6545 - val_loss: 0.5921 - val_acc: 0.6406\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5650 - acc: 0.6545 - val_loss: 0.5912 - val_acc: 0.6406\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5636 - acc: 0.6545 - val_loss: 0.5903 - val_acc: 0.6406\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5623 - acc: 0.6545 - val_loss: 0.5894 - val_acc: 0.6406\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5610 - acc: 0.6545 - val_loss: 0.5885 - val_acc: 0.6406\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5598 - acc: 0.6545 - val_loss: 0.5876 - val_acc: 0.6406\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5585 - acc: 0.6545 - val_loss: 0.5868 - val_acc: 0.6406\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5573 - acc: 0.6545 - val_loss: 0.5859 - val_acc: 0.6406\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5561 - acc: 0.6545 - val_loss: 0.5852 - val_acc: 0.6406\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5549 - acc: 0.6545 - val_loss: 0.5844 - val_acc: 0.6406\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5537 - acc: 0.6545 - val_loss: 0.5837 - val_acc: 0.6406\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5526 - acc: 0.6545 - val_loss: 0.5829 - val_acc: 0.6406\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5515 - acc: 0.6545 - val_loss: 0.5822 - val_acc: 0.6406\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5504 - acc: 0.6545 - val_loss: 0.5815 - val_acc: 0.6406\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5493 - acc: 0.6545 - val_loss: 0.5808 - val_acc: 0.6406\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5483 - acc: 0.6545 - val_loss: 0.5802 - val_acc: 0.6406\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5472 - acc: 0.6545 - val_loss: 0.5795 - val_acc: 0.6406\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5462 - acc: 0.6545 - val_loss: 0.5789 - val_acc: 0.6406\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5452 - acc: 0.6545 - val_loss: 0.5783 - val_acc: 0.6406\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5442 - acc: 0.6545 - val_loss: 0.5777 - val_acc: 0.6406\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5432 - acc: 0.6545 - val_loss: 0.5771 - val_acc: 0.6406\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5423 - acc: 0.6545 - val_loss: 0.5765 - val_acc: 0.6406\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5414 - acc: 0.6545 - val_loss: 0.5760 - val_acc: 0.6406\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5405 - acc: 0.6545 - val_loss: 0.5755 - val_acc: 0.6406\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5396 - acc: 0.6545 - val_loss: 0.5750 - val_acc: 0.6406\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5387 - acc: 0.6545 - val_loss: 0.5744 - val_acc: 0.6406\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5378 - acc: 0.6545 - val_loss: 0.5739 - val_acc: 0.6406\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5370 - acc: 0.6545 - val_loss: 0.5735 - val_acc: 0.6406\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5361 - acc: 0.6545 - val_loss: 0.5730 - val_acc: 0.6406\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5353 - acc: 0.6545 - val_loss: 0.5725 - val_acc: 0.6406\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5345 - acc: 0.6545 - val_loss: 0.5721 - val_acc: 0.6406\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5337 - acc: 0.6545 - val_loss: 0.5716 - val_acc: 0.6406\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5329 - acc: 0.6545 - val_loss: 0.5712 - val_acc: 0.6406\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5321 - acc: 0.6545 - val_loss: 0.5707 - val_acc: 0.6406\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5313 - acc: 0.6545 - val_loss: 0.5703 - val_acc: 0.6406\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5306 - acc: 0.6545 - val_loss: 0.5699 - val_acc: 0.6406\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5298 - acc: 0.6545 - val_loss: 0.5695 - val_acc: 0.6406\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5291 - acc: 0.6545 - val_loss: 0.5691 - val_acc: 0.6406\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5283 - acc: 0.6545 - val_loss: 0.5687 - val_acc: 0.6406\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5276 - acc: 0.6545 - val_loss: 0.5684 - val_acc: 0.6406\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5269 - acc: 0.6545 - val_loss: 0.5680 - val_acc: 0.6406\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5262 - acc: 0.6545 - val_loss: 0.5676 - val_acc: 0.6406\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5255 - acc: 0.6545 - val_loss: 0.5673 - val_acc: 0.6406\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5248 - acc: 0.6545 - val_loss: 0.5669 - val_acc: 0.6406\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5241 - acc: 0.6545 - val_loss: 0.5666 - val_acc: 0.6406\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5234 - acc: 0.6545 - val_loss: 0.5662 - val_acc: 0.6406\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5228 - acc: 0.6545 - val_loss: 0.5659 - val_acc: 0.6406\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5221 - acc: 0.6545 - val_loss: 0.5656 - val_acc: 0.6406\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5215 - acc: 0.6545 - val_loss: 0.5652 - val_acc: 0.6406\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5208 - acc: 0.6545 - val_loss: 0.5649 - val_acc: 0.6406\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5202 - acc: 0.6545 - val_loss: 0.5646 - val_acc: 0.6406\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5196 - acc: 0.6545 - val_loss: 0.5643 - val_acc: 0.6406\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5190 - acc: 0.6545 - val_loss: 0.5640 - val_acc: 0.6406\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5184 - acc: 0.6545 - val_loss: 0.5637 - val_acc: 0.6406\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5178 - acc: 0.6545 - val_loss: 0.5634 - val_acc: 0.6406\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5173 - acc: 0.6545 - val_loss: 0.5631 - val_acc: 0.6406\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5167 - acc: 0.6545 - val_loss: 0.5629 - val_acc: 0.6406\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5162 - acc: 0.6545 - val_loss: 0.5626 - val_acc: 0.6406\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5157 - acc: 0.6545 - val_loss: 0.5624 - val_acc: 0.6406\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5151 - acc: 0.6441 - val_loss: 0.5621 - val_acc: 0.6562\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5146 - acc: 0.6476 - val_loss: 0.5619 - val_acc: 0.6510\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5141 - acc: 0.6545 - val_loss: 0.5616 - val_acc: 0.6510\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5136 - acc: 0.6719 - val_loss: 0.5614 - val_acc: 0.6875\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5131 - acc: 0.6858 - val_loss: 0.5612 - val_acc: 0.6927\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5126 - acc: 0.6892 - val_loss: 0.5610 - val_acc: 0.6927\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5121 - acc: 0.6875 - val_loss: 0.5608 - val_acc: 0.6927\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5116 - acc: 0.6910 - val_loss: 0.5606 - val_acc: 0.6927\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5112 - acc: 0.6962 - val_loss: 0.5604 - val_acc: 0.6927\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5107 - acc: 0.6997 - val_loss: 0.5602 - val_acc: 0.6979\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5103 - acc: 0.7083 - val_loss: 0.5600 - val_acc: 0.7031\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5098 - acc: 0.7083 - val_loss: 0.5598 - val_acc: 0.6927\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5094 - acc: 0.7066 - val_loss: 0.5596 - val_acc: 0.6875\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5090 - acc: 0.7049 - val_loss: 0.5595 - val_acc: 0.6875\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5086 - acc: 0.7101 - val_loss: 0.5593 - val_acc: 0.6875\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5082 - acc: 0.7135 - val_loss: 0.5592 - val_acc: 0.6875\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5078 - acc: 0.7135 - val_loss: 0.5590 - val_acc: 0.6875\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5074 - acc: 0.7135 - val_loss: 0.5588 - val_acc: 0.6927\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5070 - acc: 0.7101 - val_loss: 0.5587 - val_acc: 0.6927\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5066 - acc: 0.7118 - val_loss: 0.5585 - val_acc: 0.6927\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5062 - acc: 0.7101 - val_loss: 0.5584 - val_acc: 0.6927\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5059 - acc: 0.7135 - val_loss: 0.5582 - val_acc: 0.6927\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5055 - acc: 0.7135 - val_loss: 0.5581 - val_acc: 0.6927\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5051 - acc: 0.7135 - val_loss: 0.5579 - val_acc: 0.6979\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5048 - acc: 0.7153 - val_loss: 0.5578 - val_acc: 0.6927\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5044 - acc: 0.7153 - val_loss: 0.5577 - val_acc: 0.6927\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5040 - acc: 0.7153 - val_loss: 0.5575 - val_acc: 0.7031\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5037 - acc: 0.7153 - val_loss: 0.5574 - val_acc: 0.7031\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5033 - acc: 0.7170 - val_loss: 0.5572 - val_acc: 0.6979\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 48us/step - loss: 0.5030 - acc: 0.7170 - val_loss: 0.5571 - val_acc: 0.6979\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5027 - acc: 0.7188 - val_loss: 0.5570 - val_acc: 0.6979\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5023 - acc: 0.7205 - val_loss: 0.5568 - val_acc: 0.7031\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5020 - acc: 0.7205 - val_loss: 0.5567 - val_acc: 0.7031\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5016 - acc: 0.7222 - val_loss: 0.5566 - val_acc: 0.7083\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5013 - acc: 0.7222 - val_loss: 0.5564 - val_acc: 0.7135\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5010 - acc: 0.7222 - val_loss: 0.5563 - val_acc: 0.7135\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5007 - acc: 0.7292 - val_loss: 0.5562 - val_acc: 0.7135\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5003 - acc: 0.7292 - val_loss: 0.5560 - val_acc: 0.7135\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5000 - acc: 0.7326 - val_loss: 0.5559 - val_acc: 0.7135\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4997 - acc: 0.7292 - val_loss: 0.5558 - val_acc: 0.7135\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4994 - acc: 0.7309 - val_loss: 0.5557 - val_acc: 0.7083\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4991 - acc: 0.7309 - val_loss: 0.5556 - val_acc: 0.7083\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4988 - acc: 0.7309 - val_loss: 0.5554 - val_acc: 0.7135\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4984 - acc: 0.7309 - val_loss: 0.5553 - val_acc: 0.7031\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4982 - acc: 0.7326 - val_loss: 0.5552 - val_acc: 0.7031\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4979 - acc: 0.7344 - val_loss: 0.5551 - val_acc: 0.7031\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4975 - acc: 0.7361 - val_loss: 0.5550 - val_acc: 0.6979\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4973 - acc: 0.7396 - val_loss: 0.5549 - val_acc: 0.6979\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4970 - acc: 0.7396 - val_loss: 0.5548 - val_acc: 0.6979\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4967 - acc: 0.7413 - val_loss: 0.5547 - val_acc: 0.6979\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4964 - acc: 0.7413 - val_loss: 0.5546 - val_acc: 0.6927\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4961 - acc: 0.7413 - val_loss: 0.5546 - val_acc: 0.6927\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4958 - acc: 0.7396 - val_loss: 0.5545 - val_acc: 0.6875\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4955 - acc: 0.7396 - val_loss: 0.5544 - val_acc: 0.6875\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4953 - acc: 0.7413 - val_loss: 0.5543 - val_acc: 0.6875\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4950 - acc: 0.7413 - val_loss: 0.5542 - val_acc: 0.6875\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4947 - acc: 0.7413 - val_loss: 0.5541 - val_acc: 0.6875\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4945 - acc: 0.7413 - val_loss: 0.5540 - val_acc: 0.6875\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4942 - acc: 0.7431 - val_loss: 0.5540 - val_acc: 0.6979\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4940 - acc: 0.7431 - val_loss: 0.5539 - val_acc: 0.6979\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4937 - acc: 0.7448 - val_loss: 0.5538 - val_acc: 0.7031\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4935 - acc: 0.7465 - val_loss: 0.5537 - val_acc: 0.7083\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4932 - acc: 0.7465 - val_loss: 0.5536 - val_acc: 0.7083\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4929 - acc: 0.7448 - val_loss: 0.5536 - val_acc: 0.7083\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4927 - acc: 0.7465 - val_loss: 0.5535 - val_acc: 0.7135\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4924 - acc: 0.7483 - val_loss: 0.5534 - val_acc: 0.7135\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4922 - acc: 0.7483 - val_loss: 0.5533 - val_acc: 0.7135\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4919 - acc: 0.7483 - val_loss: 0.5532 - val_acc: 0.7135\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4917 - acc: 0.7500 - val_loss: 0.5531 - val_acc: 0.7135\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4915 - acc: 0.7517 - val_loss: 0.5531 - val_acc: 0.7135\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4912 - acc: 0.7517 - val_loss: 0.5530 - val_acc: 0.7135\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4910 - acc: 0.7552 - val_loss: 0.5529 - val_acc: 0.7135\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4908 - acc: 0.7552 - val_loss: 0.5528 - val_acc: 0.7135\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4906 - acc: 0.7587 - val_loss: 0.5527 - val_acc: 0.7135\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4903 - acc: 0.7569 - val_loss: 0.5527 - val_acc: 0.7135\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4901 - acc: 0.7569 - val_loss: 0.5526 - val_acc: 0.7188\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4898 - acc: 0.7552 - val_loss: 0.5525 - val_acc: 0.7188\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4896 - acc: 0.7552 - val_loss: 0.5524 - val_acc: 0.7240\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4894 - acc: 0.7552 - val_loss: 0.5523 - val_acc: 0.7240\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4891 - acc: 0.7552 - val_loss: 0.5523 - val_acc: 0.7240\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4889 - acc: 0.7569 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4887 - acc: 0.7587 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4885 - acc: 0.7604 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4882 - acc: 0.7604 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4880 - acc: 0.7604 - val_loss: 0.5519 - val_acc: 0.7292\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4878 - acc: 0.7604 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4876 - acc: 0.7639 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4874 - acc: 0.7622 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4872 - acc: 0.7622 - val_loss: 0.5516 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4869 - acc: 0.7604 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4867 - acc: 0.7604 - val_loss: 0.5514 - val_acc: 0.7240\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4865 - acc: 0.7604 - val_loss: 0.5514 - val_acc: 0.7240\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4863 - acc: 0.7622 - val_loss: 0.5513 - val_acc: 0.7240\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4861 - acc: 0.7622 - val_loss: 0.5512 - val_acc: 0.7240\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4859 - acc: 0.7622 - val_loss: 0.5512 - val_acc: 0.7240\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4857 - acc: 0.7622 - val_loss: 0.5511 - val_acc: 0.7240\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4855 - acc: 0.7622 - val_loss: 0.5510 - val_acc: 0.7240\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4853 - acc: 0.7639 - val_loss: 0.5510 - val_acc: 0.7240\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4851 - acc: 0.7639 - val_loss: 0.5509 - val_acc: 0.7240\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4849 - acc: 0.7639 - val_loss: 0.5509 - val_acc: 0.7240\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4847 - acc: 0.7656 - val_loss: 0.5508 - val_acc: 0.7240\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4845 - acc: 0.7639 - val_loss: 0.5507 - val_acc: 0.7240\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4843 - acc: 0.7639 - val_loss: 0.5507 - val_acc: 0.7240\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4841 - acc: 0.7622 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4840 - acc: 0.7622 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4837 - acc: 0.7604 - val_loss: 0.5505 - val_acc: 0.7292\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4836 - acc: 0.7604 - val_loss: 0.5505 - val_acc: 0.7292\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4834 - acc: 0.7587 - val_loss: 0.5505 - val_acc: 0.7292\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4832 - acc: 0.7587 - val_loss: 0.5504 - val_acc: 0.7292\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4830 - acc: 0.7604 - val_loss: 0.5504 - val_acc: 0.7292\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4828 - acc: 0.7587 - val_loss: 0.5503 - val_acc: 0.7240\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4826 - acc: 0.7604 - val_loss: 0.5502 - val_acc: 0.7240\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4825 - acc: 0.7604 - val_loss: 0.5502 - val_acc: 0.7240\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4823 - acc: 0.7622 - val_loss: 0.5501 - val_acc: 0.7240\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4821 - acc: 0.7639 - val_loss: 0.5501 - val_acc: 0.7240\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4819 - acc: 0.7639 - val_loss: 0.5500 - val_acc: 0.7188\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4817 - acc: 0.7639 - val_loss: 0.5500 - val_acc: 0.7188\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4816 - acc: 0.7639 - val_loss: 0.5499 - val_acc: 0.7188\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4814 - acc: 0.7639 - val_loss: 0.5499 - val_acc: 0.7188\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4812 - acc: 0.7639 - val_loss: 0.5498 - val_acc: 0.7188\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4811 - acc: 0.7639 - val_loss: 0.5498 - val_acc: 0.7188\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4809 - acc: 0.7622 - val_loss: 0.5498 - val_acc: 0.7188\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4807 - acc: 0.7604 - val_loss: 0.5497 - val_acc: 0.7188\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4806 - acc: 0.7604 - val_loss: 0.5497 - val_acc: 0.7188\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4804 - acc: 0.7604 - val_loss: 0.5497 - val_acc: 0.7188\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4802 - acc: 0.7604 - val_loss: 0.5497 - val_acc: 0.7188\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4800 - acc: 0.7604 - val_loss: 0.5497 - val_acc: 0.7188\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4799 - acc: 0.7604 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4797 - acc: 0.7604 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4796 - acc: 0.7604 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4794 - acc: 0.7604 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4792 - acc: 0.7622 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4791 - acc: 0.7622 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4789 - acc: 0.7622 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4788 - acc: 0.7622 - val_loss: 0.5496 - val_acc: 0.7188\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4786 - acc: 0.7622 - val_loss: 0.5495 - val_acc: 0.7188\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4785 - acc: 0.7622 - val_loss: 0.5495 - val_acc: 0.7188\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4783 - acc: 0.7622 - val_loss: 0.5495 - val_acc: 0.7188\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4781 - acc: 0.7622 - val_loss: 0.5495 - val_acc: 0.7188\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4780 - acc: 0.7622 - val_loss: 0.5495 - val_acc: 0.7188\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4778 - acc: 0.7622 - val_loss: 0.5494 - val_acc: 0.7188\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4776 - acc: 0.7622 - val_loss: 0.5494 - val_acc: 0.7188\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4775 - acc: 0.7622 - val_loss: 0.5494 - val_acc: 0.7188\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4774 - acc: 0.7622 - val_loss: 0.5494 - val_acc: 0.7188\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4772 - acc: 0.7604 - val_loss: 0.5493 - val_acc: 0.7188\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4770 - acc: 0.7604 - val_loss: 0.5493 - val_acc: 0.7188\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4769 - acc: 0.7604 - val_loss: 0.5493 - val_acc: 0.7188\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4767 - acc: 0.7604 - val_loss: 0.5493 - val_acc: 0.7188\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4766 - acc: 0.7604 - val_loss: 0.5493 - val_acc: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4764 - acc: 0.7639 - val_loss: 0.5493 - val_acc: 0.7188\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4763 - acc: 0.7639 - val_loss: 0.5493 - val_acc: 0.7240\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4762 - acc: 0.7639 - val_loss: 0.5493 - val_acc: 0.7240\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4760 - acc: 0.7639 - val_loss: 0.5493 - val_acc: 0.7240\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4758 - acc: 0.7639 - val_loss: 0.5493 - val_acc: 0.7240\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4757 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7240\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4756 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4754 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4753 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4751 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4750 - acc: 0.7639 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4749 - acc: 0.7656 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4747 - acc: 0.7691 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4746 - acc: 0.7656 - val_loss: 0.5491 - val_acc: 0.7344\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4744 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4743 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4742 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4740 - acc: 0.7691 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4739 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4738 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4736 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4735 - acc: 0.7708 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4734 - acc: 0.7726 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4732 - acc: 0.7726 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4731 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4730 - acc: 0.7726 - val_loss: 0.5492 - val_acc: 0.7240\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4729 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7240\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4727 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7240\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4726 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4725 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4723 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4722 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7292\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4721 - acc: 0.7743 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4720 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7344\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4718 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7344\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4717 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7292\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4716 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7292\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4715 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7292\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4713 - acc: 0.7726 - val_loss: 0.5491 - val_acc: 0.7292\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4712 - acc: 0.7743 - val_loss: 0.5491 - val_acc: 0.7292\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4711 - acc: 0.7760 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4710 - acc: 0.7743 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4709 - acc: 0.7743 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4707 - acc: 0.7743 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4706 - acc: 0.7743 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4705 - acc: 0.7743 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4703 - acc: 0.7726 - val_loss: 0.5489 - val_acc: 0.7292\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4702 - acc: 0.7726 - val_loss: 0.5489 - val_acc: 0.7292\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4701 - acc: 0.7726 - val_loss: 0.5489 - val_acc: 0.7292\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4700 - acc: 0.7726 - val_loss: 0.5489 - val_acc: 0.7292\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4699 - acc: 0.7726 - val_loss: 0.5489 - val_acc: 0.7240\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4697 - acc: 0.7743 - val_loss: 0.5489 - val_acc: 0.7240\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4696 - acc: 0.7743 - val_loss: 0.5489 - val_acc: 0.7240\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4695 - acc: 0.7743 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4694 - acc: 0.7743 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4692 - acc: 0.7743 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4692 - acc: 0.7743 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4690 - acc: 0.7743 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4689 - acc: 0.7743 - val_loss: 0.5487 - val_acc: 0.7292\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4688 - acc: 0.7743 - val_loss: 0.5487 - val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4687 - acc: 0.7743 - val_loss: 0.5487 - val_acc: 0.7292\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4686 - acc: 0.7743 - val_loss: 0.5487 - val_acc: 0.7292\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4684 - acc: 0.7743 - val_loss: 0.5486 - val_acc: 0.7292\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4683 - acc: 0.7743 - val_loss: 0.5486 - val_acc: 0.7292\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4682 - acc: 0.7743 - val_loss: 0.5485 - val_acc: 0.7292\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4681 - acc: 0.7743 - val_loss: 0.5485 - val_acc: 0.7292\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4679 - acc: 0.7760 - val_loss: 0.5485 - val_acc: 0.7292\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4678 - acc: 0.7743 - val_loss: 0.5484 - val_acc: 0.7292\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4677 - acc: 0.7743 - val_loss: 0.5484 - val_acc: 0.7292\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4676 - acc: 0.7743 - val_loss: 0.5483 - val_acc: 0.7292\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4674 - acc: 0.7743 - val_loss: 0.5483 - val_acc: 0.7292\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4673 - acc: 0.7743 - val_loss: 0.5483 - val_acc: 0.7292\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4672 - acc: 0.7743 - val_loss: 0.5482 - val_acc: 0.7292\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4671 - acc: 0.7743 - val_loss: 0.5482 - val_acc: 0.7344\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4670 - acc: 0.7743 - val_loss: 0.5481 - val_acc: 0.7344\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4668 - acc: 0.7743 - val_loss: 0.5481 - val_acc: 0.7344\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4667 - acc: 0.7743 - val_loss: 0.5481 - val_acc: 0.7344\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.5481 - val_acc: 0.7344\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4665 - acc: 0.7743 - val_loss: 0.5480 - val_acc: 0.7344\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4664 - acc: 0.7743 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4662 - acc: 0.7743 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4660 - acc: 0.7743 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4659 - acc: 0.7726 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4658 - acc: 0.7726 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4657 - acc: 0.7726 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4655 - acc: 0.7726 - val_loss: 0.5478 - val_acc: 0.7396\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4654 - acc: 0.7743 - val_loss: 0.5478 - val_acc: 0.7396\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4653 - acc: 0.7743 - val_loss: 0.5478 - val_acc: 0.7396\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4652 - acc: 0.7743 - val_loss: 0.5478 - val_acc: 0.7396\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4651 - acc: 0.7743 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4649 - acc: 0.7743 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4648 - acc: 0.7743 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4647 - acc: 0.7743 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4646 - acc: 0.7726 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4645 - acc: 0.7726 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4644 - acc: 0.7726 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4642 - acc: 0.7726 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4641 - acc: 0.7726 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4636 - acc: 0.7726 - val_loss: 0.5474 - val_acc: 0.7396\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4635 - acc: 0.7726 - val_loss: 0.5474 - val_acc: 0.7396\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4634 - acc: 0.7726 - val_loss: 0.5474 - val_acc: 0.7396\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4633 - acc: 0.7726 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4633 - acc: 0.7726 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4632 - acc: 0.7726 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4630 - acc: 0.7726 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4630 - acc: 0.7708 - val_loss: 0.5472 - val_acc: 0.7396\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4629 - acc: 0.7708 - val_loss: 0.5472 - val_acc: 0.7396\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4628 - acc: 0.7708 - val_loss: 0.5472 - val_acc: 0.7396\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4626 - acc: 0.7708 - val_loss: 0.5471 - val_acc: 0.7396\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4626 - acc: 0.7708 - val_loss: 0.5471 - val_acc: 0.7396\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4625 - acc: 0.7708 - val_loss: 0.5471 - val_acc: 0.7344\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4624 - acc: 0.7708 - val_loss: 0.5471 - val_acc: 0.7344\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4623 - acc: 0.7708 - val_loss: 0.5470 - val_acc: 0.7344\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4622 - acc: 0.7708 - val_loss: 0.5470 - val_acc: 0.7344\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4621 - acc: 0.7708 - val_loss: 0.5470 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4620 - acc: 0.7708 - val_loss: 0.5470 - val_acc: 0.7344\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.5469 - val_acc: 0.7344\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.5469 - val_acc: 0.7344\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.5469 - val_acc: 0.7344\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4616 - acc: 0.7726 - val_loss: 0.5469 - val_acc: 0.7344\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4616 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4615 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4613 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4613 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4612 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4610 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4606 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4605 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4603 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4603 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4601 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4600 - acc: 0.7726 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4599 - acc: 0.7743 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4599 - acc: 0.7743 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4598 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4597 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4596 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4596 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4595 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4594 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7396\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4593 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4593 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4592 - acc: 0.7743 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4591 - acc: 0.7726 - val_loss: 0.5468 - val_acc: 0.7344\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4591 - acc: 0.7743 - val_loss: 0.5469 - val_acc: 0.7344\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4590 - acc: 0.7743 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4589 - acc: 0.7743 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4588 - acc: 0.7743 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4588 - acc: 0.7760 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4587 - acc: 0.7760 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4586 - acc: 0.7760 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4586 - acc: 0.7778 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4585 - acc: 0.7778 - val_loss: 0.5469 - val_acc: 0.7292\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4584 - acc: 0.7778 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4583 - acc: 0.7795 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4583 - acc: 0.7795 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4582 - acc: 0.7812 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4581 - acc: 0.7830 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4581 - acc: 0.7830 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4580 - acc: 0.7830 - val_loss: 0.5470 - val_acc: 0.7292\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4579 - acc: 0.7830 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4579 - acc: 0.7847 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4578 - acc: 0.7830 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4578 - acc: 0.7865 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4577 - acc: 0.7847 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - acc: 0.7847 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4576 - acc: 0.7865 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4575 - acc: 0.7865 - val_loss: 0.5471 - val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4574 - acc: 0.7865 - val_loss: 0.5471 - val_acc: 0.7292\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4574 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4573 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4572 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4572 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4571 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4570 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4570 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4569 - acc: 0.7865 - val_loss: 0.5472 - val_acc: 0.7292\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4568 - acc: 0.7865 - val_loss: 0.5473 - val_acc: 0.7292\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4568 - acc: 0.7865 - val_loss: 0.5473 - val_acc: 0.7292\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4567 - acc: 0.7865 - val_loss: 0.5473 - val_acc: 0.7344\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4566 - acc: 0.7865 - val_loss: 0.5473 - val_acc: 0.7344\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4566 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4564 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4563 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4563 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4562 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4561 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4561 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4560 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4560 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4559 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4558 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4558 - acc: 0.7865 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4557 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7344\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4556 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7344\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4556 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7344\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4555 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7344\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4555 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7344\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4554 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4553 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4553 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4552 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4552 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4551 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4550 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4550 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4549 - acc: 0.7865 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4549 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4548 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4548 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4547 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4547 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4546 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4545 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4545 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4544 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4544 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4543 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4543 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4542 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4541 - acc: 0.7865 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4541 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4540 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4540 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4539 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4539 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4538 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4538 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4537 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4537 - acc: 0.7882 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4536 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4535 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4535 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4534 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4534 - acc: 0.7865 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4534 - acc: 0.7882 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4533 - acc: 0.7865 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4532 - acc: 0.7882 - val_loss: 0.5478 - val_acc: 0.7500\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4532 - acc: 0.7882 - val_loss: 0.5478 - val_acc: 0.7500\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4531 - acc: 0.7899 - val_loss: 0.5478 - val_acc: 0.7500\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4531 - acc: 0.7899 - val_loss: 0.5478 - val_acc: 0.7500\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4530 - acc: 0.7899 - val_loss: 0.5478 - val_acc: 0.7500\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4530 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4529 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4529 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4528 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4528 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4527 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4527 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7500\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4526 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4526 - acc: 0.7899 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4525 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4525 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4524 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4523 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4523 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4523 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4522 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4522 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4521 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4521 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4520 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4519 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4519 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4518 - acc: 0.7899 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4518 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4517 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4517 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4517 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4516 - acc: 0.7882 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4515 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4514 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4514 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4514 - acc: 0.7882 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4513 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4512 - acc: 0.7899 - val_loss: 0.5481 - val_acc: 0.7448\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4512 - acc: 0.7899 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4512 - acc: 0.7899 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4511 - acc: 0.7899 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4511 - acc: 0.7882 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4510 - acc: 0.7882 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4509 - acc: 0.7882 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4509 - acc: 0.7882 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4509 - acc: 0.7882 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4508 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4507 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4506 - acc: 0.7882 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4506 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4506 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4505 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4504 - acc: 0.7865 - val_loss: 0.5483 - val_acc: 0.7448\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4504 - acc: 0.7865 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4503 - acc: 0.7865 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4503 - acc: 0.7865 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4503 - acc: 0.7865 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4502 - acc: 0.7882 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4502 - acc: 0.7865 - val_loss: 0.5484 - val_acc: 0.7448\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4501 - acc: 0.7882 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4501 - acc: 0.7865 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4501 - acc: 0.7865 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4500 - acc: 0.7882 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4499 - acc: 0.7865 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4499 - acc: 0.7882 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4499 - acc: 0.7865 - val_loss: 0.5485 - val_acc: 0.7448\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4498 - acc: 0.7882 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4498 - acc: 0.7865 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4497 - acc: 0.7865 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4497 - acc: 0.7865 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4496 - acc: 0.7865 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4496 - acc: 0.7882 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4496 - acc: 0.7899 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4495 - acc: 0.7865 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4494 - acc: 0.7899 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4494 - acc: 0.7899 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4493 - acc: 0.7882 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4493 - acc: 0.7899 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4492 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4492 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4491 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4491 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4490 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4490 - acc: 0.7917 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4490 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4489 - acc: 0.7899 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4489 - acc: 0.7899 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4488 - acc: 0.7899 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4488 - acc: 0.7917 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4487 - acc: 0.7917 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4487 - acc: 0.7917 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4486 - acc: 0.7899 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4486 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4486 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4486 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4485 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4484 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4484 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4484 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4483 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4483 - acc: 0.7917 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4482 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4482 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4481 - acc: 0.7899 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4481 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4481 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4480 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4480 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - acc: 0.7917 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4479 - acc: 0.7899 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - acc: 0.7917 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4478 - acc: 0.7899 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4478 - acc: 0.7917 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4477 - acc: 0.7917 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4477 - acc: 0.7899 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4476 - acc: 0.7899 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4476 - acc: 0.7917 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4476 - acc: 0.7917 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4476 - acc: 0.7899 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4475 - acc: 0.7899 - val_loss: 0.5492 - val_acc: 0.7344\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4474 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4474 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4472 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4472 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4471 - acc: 0.7899 - val_loss: 0.5493 - val_acc: 0.7344\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4471 - acc: 0.7917 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4470 - acc: 0.7934 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4470 - acc: 0.7917 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4470 - acc: 0.7917 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4469 - acc: 0.7934 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4469 - acc: 0.7951 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4469 - acc: 0.7934 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4468 - acc: 0.7934 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4468 - acc: 0.7951 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4467 - acc: 0.7951 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4467 - acc: 0.7951 - val_loss: 0.5494 - val_acc: 0.7344\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4467 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4467 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4466 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4466 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4465 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4465 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4464 - acc: 0.7951 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4464 - acc: 0.7969 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4464 - acc: 0.7969 - val_loss: 0.5495 - val_acc: 0.7344\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4463 - acc: 0.7969 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4463 - acc: 0.7986 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4463 - acc: 0.7986 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4462 - acc: 0.7969 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4462 - acc: 0.7986 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4462 - acc: 0.7986 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4461 - acc: 0.7969 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4461 - acc: 0.7969 - val_loss: 0.5496 - val_acc: 0.7344\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4460 - acc: 0.7986 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4460 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4460 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4460 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4459 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4459 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4458 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4458 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7344\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4458 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4458 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4457 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4457 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4456 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4456 - acc: 0.7969 - val_loss: 0.5498 - val_acc: 0.7344\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4456 - acc: 0.7969 - val_loss: 0.5499 - val_acc: 0.7344\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4455 - acc: 0.7969 - val_loss: 0.5499 - val_acc: 0.7344\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4455 - acc: 0.7969 - val_loss: 0.5499 - val_acc: 0.7344\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4455 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4454 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4454 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4453 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4453 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4453 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4453 - acc: 0.7969 - val_loss: 0.5500 - val_acc: 0.7344\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4452 - acc: 0.7969 - val_loss: 0.5501 - val_acc: 0.7344\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4451 - acc: 0.7969 - val_loss: 0.5501 - val_acc: 0.7344\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4451 - acc: 0.7969 - val_loss: 0.5501 - val_acc: 0.7344\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4451 - acc: 0.7969 - val_loss: 0.5501 - val_acc: 0.7344\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4451 - acc: 0.7969 - val_loss: 0.5502 - val_acc: 0.7344\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4450 - acc: 0.7969 - val_loss: 0.5502 - val_acc: 0.7344\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4450 - acc: 0.7969 - val_loss: 0.5502 - val_acc: 0.7344\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4450 - acc: 0.7969 - val_loss: 0.5502 - val_acc: 0.7344\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4449 - acc: 0.7969 - val_loss: 0.5502 - val_acc: 0.7344\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4449 - acc: 0.7969 - val_loss: 0.5503 - val_acc: 0.7344\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4449 - acc: 0.7969 - val_loss: 0.5503 - val_acc: 0.7344\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4448 - acc: 0.7969 - val_loss: 0.5503 - val_acc: 0.7344\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4448 - acc: 0.7969 - val_loss: 0.5503 - val_acc: 0.7344\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4447 - acc: 0.7969 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7969 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4446 - acc: 0.7969 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7969 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4446 - acc: 0.7969 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4446 - acc: 0.7969 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4445 - acc: 0.7969 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4445 - acc: 0.7969 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4445 - acc: 0.7969 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4444 - acc: 0.7969 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7969 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4444 - acc: 0.7969 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4443 - acc: 0.7969 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4443 - acc: 0.7969 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4442 - acc: 0.7969 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4442 - acc: 0.7969 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4441 - acc: 0.7951 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4441 - acc: 0.7969 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4441 - acc: 0.7951 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4441 - acc: 0.7951 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4441 - acc: 0.7969 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4440 - acc: 0.7951 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4440 - acc: 0.7951 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4440 - acc: 0.7951 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4439 - acc: 0.7951 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4439 - acc: 0.7951 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4438 - acc: 0.7951 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4438 - acc: 0.7951 - val_loss: 0.5510 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4438 - acc: 0.7951 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4438 - acc: 0.7951 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4437 - acc: 0.7934 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4437 - acc: 0.7951 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4437 - acc: 0.7951 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4436 - acc: 0.7934 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4436 - acc: 0.7934 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7934 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7934 - val_loss: 0.5511 - val_acc: 0.7344\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4435 - acc: 0.7934 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7951 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4434 - acc: 0.7934 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4434 - acc: 0.7934 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4433 - acc: 0.7934 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4434 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4433 - acc: 0.7951 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4433 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4433 - acc: 0.7951 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4432 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4432 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4432 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4431 - acc: 0.7934 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4431 - acc: 0.7951 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4431 - acc: 0.7951 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4430 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4430 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4430 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4430 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4429 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4429 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4428 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4428 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4428 - acc: 0.7951 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4428 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4427 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4427 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4427 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4426 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4427 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4426 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4426 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4425 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4425 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4425 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4425 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4424 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4423 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4423 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4422 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4422 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4422 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4421 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4421 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4421 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4419 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4418 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4418 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4418 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4418 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4417 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4417 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4416 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7969 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4415 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4414 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4415 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4414 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4414 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4413 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4413 - acc: 0.7969 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4413 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4413 - acc: 0.7951 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4412 - acc: 0.7969 - val_loss: 0.5516 - val_acc: 0.7344\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4412 - acc: 0.7951 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4411 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4411 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4410 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4410 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4410 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4409 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4409 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4409 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4408 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4408 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4408 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4408 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4407 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4407 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4406 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4406 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4406 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4405 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4405 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4404 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4403 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4403 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4403 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4402 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4402 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4401 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4401 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4401 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4400 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4400 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4400 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4400 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4399 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4399 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4398 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4398 - acc: 0.7969 - val_loss: 0.5515 - val_acc: 0.7344\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4398 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4397 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4397 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4397 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4396 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4396 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4395 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4394 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4394 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4393 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4393 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4393 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4391 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4391 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4390 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4390 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4389 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4389 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4389 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4388 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4388 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4387 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4387 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4387 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4387 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4387 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4386 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4385 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4385 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4385 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4384 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4384 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4384 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4384 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4383 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4383 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4382 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4382 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4382 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4382 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4380 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4380 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4380 - acc: 0.7986 - val_loss: 0.5512 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4379 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.7969 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4378 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4378 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4377 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4377 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4377 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4375 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4375 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4374 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4373 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4373 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4373 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4372 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4372 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4371 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - acc: 0.7969 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4370 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4369 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4368 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4368 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4367 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4367 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4366 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4366 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4365 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4365 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4365 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4364 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4364 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4364 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4363 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4363 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4363 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4362 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4362 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7344\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4362 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4361 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4361 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4361 - acc: 0.8003 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4360 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4360 - acc: 0.8003 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - acc: 0.7986 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4359 - acc: 0.8003 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4359 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4359 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4358 - acc: 0.8003 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4358 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4358 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4357 - acc: 0.8003 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4357 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4357 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4356 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4356 - acc: 0.8003 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4356 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4355 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4355 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4355 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4354 - acc: 0.8021 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4353 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4353 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4353 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4352 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4352 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4352 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4352 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4352 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4351 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4351 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4349 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4349 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4348 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4349 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4348 - acc: 0.8056 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4348 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4347 - acc: 0.8056 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4347 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4347 - acc: 0.8056 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4347 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4346 - acc: 0.8056 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4346 - acc: 0.8056 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4346 - acc: 0.8056 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4345 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4345 - acc: 0.8056 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4345 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4345 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4344 - acc: 0.8056 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4344 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4344 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4343 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4343 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4343 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4343 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4343 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4342 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4342 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4341 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4341 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4341 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4341 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4340 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4339 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4339 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4339 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4338 - acc: 0.8003 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4338 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4338 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4337 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4338 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4337 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4337 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.5517 - val_acc: 0.7292\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7292\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4335 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4334 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4333 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4333 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4333 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4333 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4332 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4333 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4332 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4332 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4331 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4331 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4331 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4330 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4329 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4329 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4329 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4327 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4327 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4327 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4326 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4326 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4326 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4325 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4325 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4325 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4324 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4322 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4322 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4321 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4321 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4321 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4320 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4320 - acc: 0.8038 - val_loss: 0.5522 - val_acc: 0.7240\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4319 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4319 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4318 - acc: 0.8056 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.8038 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4317 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4317 - acc: 0.8021 - val_loss: 0.5521 - val_acc: 0.7240\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4317 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4316 - acc: 0.8056 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4317 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4316 - acc: 0.8038 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4316 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4315 - acc: 0.8038 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4315 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4314 - acc: 0.8021 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - acc: 0.8038 - val_loss: 0.5520 - val_acc: 0.7240\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4314 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - acc: 0.8021 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4313 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4313 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5519 - val_acc: 0.7240\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4309 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4309 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1133/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4309 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4308 - acc: 0.8021 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4308 - acc: 0.8038 - val_loss: 0.5518 - val_acc: 0.7240\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4308 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4307 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4307 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4307 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - acc: 0.8038 - val_loss: 0.5517 - val_acc: 0.7240\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4305 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4305 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4305 - acc: 0.8021 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4305 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4304 - acc: 0.8038 - val_loss: 0.5516 - val_acc: 0.7240\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4303 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4303 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4303 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4303 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4302 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7240\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4302 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4301 - acc: 0.8038 - val_loss: 0.5515 - val_acc: 0.7292\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - acc: 0.8038 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4301 - acc: 0.8038 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4300 - acc: 0.8021 - val_loss: 0.5514 - val_acc: 0.7292\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4299 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4299 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4298 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4298 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4298 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4298 - acc: 0.8021 - val_loss: 0.5513 - val_acc: 0.7292\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4297 - acc: 0.8021 - val_loss: 0.5512 - val_acc: 0.7292\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4297 - acc: 0.8021 - val_loss: 0.5512 - val_acc: 0.7292\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4297 - acc: 0.8021 - val_loss: 0.5512 - val_acc: 0.7292\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4297 - acc: 0.8021 - val_loss: 0.5512 - val_acc: 0.7292\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4296 - acc: 0.8021 - val_loss: 0.5511 - val_acc: 0.7292\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4296 - acc: 0.8021 - val_loss: 0.5511 - val_acc: 0.7292\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4296 - acc: 0.8021 - val_loss: 0.5511 - val_acc: 0.7292\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.8021 - val_loss: 0.5511 - val_acc: 0.7292\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4295 - acc: 0.8021 - val_loss: 0.5511 - val_acc: 0.7292\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.8003 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.8021 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4295 - acc: 0.8021 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4294 - acc: 0.8003 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4293 - acc: 0.8003 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4294 - acc: 0.8021 - val_loss: 0.5510 - val_acc: 0.7292\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4293 - acc: 0.8021 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4293 - acc: 0.8003 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4293 - acc: 0.8003 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - acc: 0.8021 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4292 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4291 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4291 - acc: 0.8021 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4291 - acc: 0.8003 - val_loss: 0.5507 - val_acc: 0.7292\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4290 - acc: 0.8003 - val_loss: 0.5507 - val_acc: 0.7292\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - acc: 0.8003 - val_loss: 0.5507 - val_acc: 0.7292\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4290 - acc: 0.8021 - val_loss: 0.5507 - val_acc: 0.7292\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.8021 - val_loss: 0.5507 - val_acc: 0.7292\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4289 - acc: 0.8021 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4289 - acc: 0.8003 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.8021 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4288 - acc: 0.8021 - val_loss: 0.5506 - val_acc: 0.7292\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4288 - acc: 0.8021 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4287 - acc: 0.8021 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8021 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8003 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8003 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8021 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4285 - acc: 0.8021 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4285 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4284 - acc: 0.8021 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4284 - acc: 0.8021 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4284 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4284 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4283 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4281 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4281 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4281 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4280 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4280 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4280 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4279 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4279 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4279 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4279 - acc: 0.8038 - val_loss: 0.5504 - val_acc: 0.7344\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4278 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4278 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4277 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4277 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4276 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4276 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4275 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4275 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4275 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4274 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4274 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.7344\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4273 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4273 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4273 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4271 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4271 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4271 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4270 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4269 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8038 - val_loss: 0.5506 - val_acc: 0.7344\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4269 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4269 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4268 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4268 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4268 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4268 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4267 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4267 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4267 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4267 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4266 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4266 - acc: 0.8038 - val_loss: 0.5507 - val_acc: 0.7344\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4266 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4265 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4265 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4265 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7344\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4265 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4264 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4264 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4264 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4263 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4263 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4263 - acc: 0.8038 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4263 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7292\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4262 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4262 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4262 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4261 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4260 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4260 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4259 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4259 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4259 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4259 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4258 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4258 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4258 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4257 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4257 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4257 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4257 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4256 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4256 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4255 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4255 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4255 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4255 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4254 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4254 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4254 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4254 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4253 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4253 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4253 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4252 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4252 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4252 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4252 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4251 - acc: 0.8073 - val_loss: 0.5509 - val_acc: 0.7344\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4251 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4251 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4251 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4250 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4250 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4250 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4248 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4248 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4248 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4247 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4246 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4246 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4246 - acc: 0.8073 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4246 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7396\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7396\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7396\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4245 - acc: 0.8056 - val_loss: 0.5510 - val_acc: 0.7396\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4244 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4244 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4243 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4243 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4243 - acc: 0.8056 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4243 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1369/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4242 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4242 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4240 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4240 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4241 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4240 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4240 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4239 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4239 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4239 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4239 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4239 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4238 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4238 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4238 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4237 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4238 - acc: 0.8056 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4237 - acc: 0.8056 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4237 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4237 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4237 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4237 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4236 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4236 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4236 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4235 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4236 - acc: 0.8056 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4235 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4235 - acc: 0.8073 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4234 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4235 - acc: 0.8073 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4234 - acc: 0.8073 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4234 - acc: 0.8073 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4234 - acc: 0.8073 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4233 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4233 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4233 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4233 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4232 - acc: 0.8056 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4232 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4232 - acc: 0.8073 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4232 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4232 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4231 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4231 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4230 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4229 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4228 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4228 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4228 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4227 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4227 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4227 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4226 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4226 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4226 - acc: 0.8056 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4226 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4225 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4225 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4225 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4224 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4223 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4223 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4223 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4223 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4222 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4222 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4222 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4222 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4221 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4222 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4221 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4221 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4219 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4219 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4219 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4218 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4218 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4218 - acc: 0.8090 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4218 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4218 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4217 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4217 - acc: 0.8090 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4217 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4216 - acc: 0.8073 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4217 - acc: 0.8090 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1487/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 45us/step - loss: 0.4216 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4216 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4216 - acc: 0.8090 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4216 - acc: 0.8090 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4216 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4215 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4215 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4214 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4214 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4214 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4214 - acc: 0.8108 - val_loss: 0.5505 - val_acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "#Creating Model with 2 hidden layers, each has 6 nodes and relu activation \n",
    "#The final layers has 1 node and sigmoid activation\n",
    "\n",
    "model_2 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape=(8,),activation=\"relu\"), \n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "]) \n",
    "\n",
    "#This function summarizes the details of the model \n",
    "model_2.summary()\n",
    "\n",
    "#Compiling the model with lr=0.003, training for 1500 epochs \n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.740\n",
      "roc-auc is 0.798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/500\n",
      "576/576 [==============================] - 1s 990us/step - loss: 0.8442 - acc: 0.4358 - val_loss: 0.8241 - val_acc: 0.4115\n",
      "Epoch 2/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.8229 - acc: 0.4479 - val_loss: 0.8039 - val_acc: 0.4219\n",
      "Epoch 3/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.8046 - acc: 0.4618 - val_loss: 0.7865 - val_acc: 0.4323\n",
      "Epoch 4/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7887 - acc: 0.4878 - val_loss: 0.7713 - val_acc: 0.4375\n",
      "Epoch 5/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7746 - acc: 0.5069 - val_loss: 0.7583 - val_acc: 0.4635\n",
      "Epoch 6/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7625 - acc: 0.5365 - val_loss: 0.7471 - val_acc: 0.4792\n",
      "Epoch 7/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7515 - acc: 0.5486 - val_loss: 0.7374 - val_acc: 0.4896\n",
      "Epoch 8/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7415 - acc: 0.5608 - val_loss: 0.7283 - val_acc: 0.5260\n",
      "Epoch 9/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.7325 - acc: 0.5833 - val_loss: 0.7203 - val_acc: 0.5417\n",
      "Epoch 10/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.7245 - acc: 0.5920 - val_loss: 0.7131 - val_acc: 0.5469\n",
      "Epoch 11/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.7178 - acc: 0.6059 - val_loss: 0.7067 - val_acc: 0.5729\n",
      "Epoch 12/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7116 - acc: 0.6163 - val_loss: 0.7007 - val_acc: 0.5885\n",
      "Epoch 13/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.7059 - acc: 0.6302 - val_loss: 0.6953 - val_acc: 0.6094\n",
      "Epoch 14/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.7008 - acc: 0.6389 - val_loss: 0.6902 - val_acc: 0.6146\n",
      "Epoch 15/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6958 - acc: 0.6493 - val_loss: 0.6855 - val_acc: 0.6198\n",
      "Epoch 16/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6914 - acc: 0.6476 - val_loss: 0.6811 - val_acc: 0.6198\n",
      "Epoch 17/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6871 - acc: 0.6476 - val_loss: 0.6771 - val_acc: 0.6198\n",
      "Epoch 18/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6832 - acc: 0.6458 - val_loss: 0.6734 - val_acc: 0.6302\n",
      "Epoch 19/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6797 - acc: 0.6458 - val_loss: 0.6701 - val_acc: 0.6354\n",
      "Epoch 20/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6765 - acc: 0.6424 - val_loss: 0.6671 - val_acc: 0.6406\n",
      "Epoch 21/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6734 - acc: 0.6441 - val_loss: 0.6643 - val_acc: 0.6354\n",
      "Epoch 22/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6706 - acc: 0.6476 - val_loss: 0.6616 - val_acc: 0.6406\n",
      "Epoch 23/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6679 - acc: 0.6493 - val_loss: 0.6590 - val_acc: 0.6406\n",
      "Epoch 24/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6653 - acc: 0.6476 - val_loss: 0.6565 - val_acc: 0.6458\n",
      "Epoch 25/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6628 - acc: 0.6476 - val_loss: 0.6543 - val_acc: 0.6510\n",
      "Epoch 26/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6604 - acc: 0.6545 - val_loss: 0.6520 - val_acc: 0.6510\n",
      "Epoch 27/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6580 - acc: 0.6562 - val_loss: 0.6499 - val_acc: 0.6562\n",
      "Epoch 28/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6558 - acc: 0.6562 - val_loss: 0.6479 - val_acc: 0.6562\n",
      "Epoch 29/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6536 - acc: 0.6562 - val_loss: 0.6459 - val_acc: 0.6562\n",
      "Epoch 30/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6514 - acc: 0.6562 - val_loss: 0.6440 - val_acc: 0.6562\n",
      "Epoch 31/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6492 - acc: 0.6562 - val_loss: 0.6421 - val_acc: 0.6458\n",
      "Epoch 32/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6470 - acc: 0.6545 - val_loss: 0.6401 - val_acc: 0.6458\n",
      "Epoch 33/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6448 - acc: 0.6545 - val_loss: 0.6382 - val_acc: 0.6458\n",
      "Epoch 34/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6427 - acc: 0.6528 - val_loss: 0.6363 - val_acc: 0.6458\n",
      "Epoch 35/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6406 - acc: 0.6528 - val_loss: 0.6344 - val_acc: 0.6458\n",
      "Epoch 36/500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6385 - acc: 0.6528 - val_loss: 0.6326 - val_acc: 0.6458\n",
      "Epoch 37/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6365 - acc: 0.6545 - val_loss: 0.6308 - val_acc: 0.6458\n",
      "Epoch 38/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6346 - acc: 0.6545 - val_loss: 0.6290 - val_acc: 0.6458\n",
      "Epoch 39/500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.6328 - acc: 0.6545 - val_loss: 0.6274 - val_acc: 0.6458\n",
      "Epoch 40/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6309 - acc: 0.6562 - val_loss: 0.6257 - val_acc: 0.6458\n",
      "Epoch 41/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6290 - acc: 0.6562 - val_loss: 0.6242 - val_acc: 0.6458\n",
      "Epoch 42/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6272 - acc: 0.6562 - val_loss: 0.6226 - val_acc: 0.6458\n",
      "Epoch 43/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6252 - acc: 0.6562 - val_loss: 0.6211 - val_acc: 0.6458\n",
      "Epoch 44/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6234 - acc: 0.6562 - val_loss: 0.6196 - val_acc: 0.6458\n",
      "Epoch 45/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6216 - acc: 0.6562 - val_loss: 0.6181 - val_acc: 0.6458\n",
      "Epoch 46/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6199 - acc: 0.6562 - val_loss: 0.6167 - val_acc: 0.6458\n",
      "Epoch 47/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6181 - acc: 0.6562 - val_loss: 0.6151 - val_acc: 0.6458\n",
      "Epoch 48/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6162 - acc: 0.6562 - val_loss: 0.6135 - val_acc: 0.6458\n",
      "Epoch 49/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6144 - acc: 0.6562 - val_loss: 0.6119 - val_acc: 0.6458\n",
      "Epoch 50/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6126 - acc: 0.6562 - val_loss: 0.6103 - val_acc: 0.6458\n",
      "Epoch 51/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6108 - acc: 0.6562 - val_loss: 0.6087 - val_acc: 0.6458\n",
      "Epoch 52/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6092 - acc: 0.6562 - val_loss: 0.6071 - val_acc: 0.6458\n",
      "Epoch 53/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6075 - acc: 0.6562 - val_loss: 0.6055 - val_acc: 0.6458\n",
      "Epoch 54/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6058 - acc: 0.6562 - val_loss: 0.6040 - val_acc: 0.6458\n",
      "Epoch 55/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6042 - acc: 0.6562 - val_loss: 0.6025 - val_acc: 0.6458\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 36us/step - loss: 0.6026 - acc: 0.6562 - val_loss: 0.6010 - val_acc: 0.6458\n",
      "Epoch 57/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6009 - acc: 0.6562 - val_loss: 0.5996 - val_acc: 0.6458\n",
      "Epoch 58/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5994 - acc: 0.6562 - val_loss: 0.5983 - val_acc: 0.6458\n",
      "Epoch 59/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5978 - acc: 0.6562 - val_loss: 0.5969 - val_acc: 0.6458\n",
      "Epoch 60/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5963 - acc: 0.6562 - val_loss: 0.5956 - val_acc: 0.6458\n",
      "Epoch 61/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5946 - acc: 0.6562 - val_loss: 0.5942 - val_acc: 0.6458\n",
      "Epoch 62/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5930 - acc: 0.6562 - val_loss: 0.5930 - val_acc: 0.6458\n",
      "Epoch 63/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5915 - acc: 0.6562 - val_loss: 0.5917 - val_acc: 0.6458\n",
      "Epoch 64/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5900 - acc: 0.6562 - val_loss: 0.5905 - val_acc: 0.6458\n",
      "Epoch 65/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5884 - acc: 0.6562 - val_loss: 0.5892 - val_acc: 0.6458\n",
      "Epoch 66/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5869 - acc: 0.6562 - val_loss: 0.5880 - val_acc: 0.6458\n",
      "Epoch 67/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5853 - acc: 0.6562 - val_loss: 0.5867 - val_acc: 0.6458\n",
      "Epoch 68/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5837 - acc: 0.6562 - val_loss: 0.5855 - val_acc: 0.6458\n",
      "Epoch 69/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5821 - acc: 0.6562 - val_loss: 0.5843 - val_acc: 0.6458\n",
      "Epoch 70/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5805 - acc: 0.6562 - val_loss: 0.5832 - val_acc: 0.6458\n",
      "Epoch 71/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5790 - acc: 0.6562 - val_loss: 0.5821 - val_acc: 0.6458\n",
      "Epoch 72/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5775 - acc: 0.6545 - val_loss: 0.5809 - val_acc: 0.6458\n",
      "Epoch 73/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5760 - acc: 0.6545 - val_loss: 0.5798 - val_acc: 0.6458\n",
      "Epoch 74/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5744 - acc: 0.6545 - val_loss: 0.5787 - val_acc: 0.6458\n",
      "Epoch 75/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5728 - acc: 0.6545 - val_loss: 0.5776 - val_acc: 0.6458\n",
      "Epoch 76/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5712 - acc: 0.6545 - val_loss: 0.5766 - val_acc: 0.6458\n",
      "Epoch 77/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5697 - acc: 0.6545 - val_loss: 0.5755 - val_acc: 0.6458\n",
      "Epoch 78/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5682 - acc: 0.6545 - val_loss: 0.5745 - val_acc: 0.6458\n",
      "Epoch 79/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5665 - acc: 0.6545 - val_loss: 0.5735 - val_acc: 0.6458\n",
      "Epoch 80/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5648 - acc: 0.6545 - val_loss: 0.5725 - val_acc: 0.6458\n",
      "Epoch 81/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5632 - acc: 0.6562 - val_loss: 0.5715 - val_acc: 0.6510\n",
      "Epoch 82/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5616 - acc: 0.6562 - val_loss: 0.5705 - val_acc: 0.6510\n",
      "Epoch 83/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5600 - acc: 0.6562 - val_loss: 0.5694 - val_acc: 0.6510\n",
      "Epoch 84/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5582 - acc: 0.6562 - val_loss: 0.5684 - val_acc: 0.6458\n",
      "Epoch 85/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5566 - acc: 0.6580 - val_loss: 0.5674 - val_acc: 0.6458\n",
      "Epoch 86/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5550 - acc: 0.6580 - val_loss: 0.5663 - val_acc: 0.6458\n",
      "Epoch 87/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5533 - acc: 0.6580 - val_loss: 0.5654 - val_acc: 0.6458\n",
      "Epoch 88/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5517 - acc: 0.6580 - val_loss: 0.5645 - val_acc: 0.6458\n",
      "Epoch 89/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5501 - acc: 0.6580 - val_loss: 0.5636 - val_acc: 0.6458\n",
      "Epoch 90/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5485 - acc: 0.6580 - val_loss: 0.5627 - val_acc: 0.6458\n",
      "Epoch 91/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5469 - acc: 0.6597 - val_loss: 0.5618 - val_acc: 0.6510\n",
      "Epoch 92/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5451 - acc: 0.6597 - val_loss: 0.5609 - val_acc: 0.6510\n",
      "Epoch 93/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5435 - acc: 0.6615 - val_loss: 0.5600 - val_acc: 0.6562\n",
      "Epoch 94/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5419 - acc: 0.6632 - val_loss: 0.5591 - val_acc: 0.6562\n",
      "Epoch 95/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5402 - acc: 0.6597 - val_loss: 0.5582 - val_acc: 0.6562\n",
      "Epoch 96/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5387 - acc: 0.6597 - val_loss: 0.5574 - val_acc: 0.6562\n",
      "Epoch 97/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5372 - acc: 0.6615 - val_loss: 0.5566 - val_acc: 0.6562\n",
      "Epoch 98/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5357 - acc: 0.6615 - val_loss: 0.5558 - val_acc: 0.6510\n",
      "Epoch 99/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5341 - acc: 0.6632 - val_loss: 0.5551 - val_acc: 0.6510\n",
      "Epoch 100/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5327 - acc: 0.6667 - val_loss: 0.5543 - val_acc: 0.6562\n",
      "Epoch 101/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5312 - acc: 0.6649 - val_loss: 0.5536 - val_acc: 0.6562\n",
      "Epoch 102/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5298 - acc: 0.6667 - val_loss: 0.5529 - val_acc: 0.6562\n",
      "Epoch 103/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5284 - acc: 0.6649 - val_loss: 0.5522 - val_acc: 0.6562\n",
      "Epoch 104/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5270 - acc: 0.6684 - val_loss: 0.5515 - val_acc: 0.6562\n",
      "Epoch 105/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5257 - acc: 0.6701 - val_loss: 0.5509 - val_acc: 0.6562\n",
      "Epoch 106/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5244 - acc: 0.6684 - val_loss: 0.5502 - val_acc: 0.6562\n",
      "Epoch 107/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5231 - acc: 0.6684 - val_loss: 0.5495 - val_acc: 0.6615\n",
      "Epoch 108/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5219 - acc: 0.6701 - val_loss: 0.5489 - val_acc: 0.6719\n",
      "Epoch 109/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5207 - acc: 0.6736 - val_loss: 0.5482 - val_acc: 0.6771\n",
      "Epoch 110/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5194 - acc: 0.6771 - val_loss: 0.5476 - val_acc: 0.6667\n",
      "Epoch 111/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5183 - acc: 0.6753 - val_loss: 0.5470 - val_acc: 0.6667\n",
      "Epoch 112/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5171 - acc: 0.6771 - val_loss: 0.5464 - val_acc: 0.6771\n",
      "Epoch 113/500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5159 - acc: 0.6840 - val_loss: 0.5458 - val_acc: 0.6719\n",
      "Epoch 114/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5148 - acc: 0.6823 - val_loss: 0.5453 - val_acc: 0.6771\n",
      "Epoch 115/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5136 - acc: 0.6858 - val_loss: 0.5448 - val_acc: 0.6667\n",
      "Epoch 116/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5125 - acc: 0.6944 - val_loss: 0.5442 - val_acc: 0.6719\n",
      "Epoch 117/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5115 - acc: 0.6962 - val_loss: 0.5437 - val_acc: 0.6823\n",
      "Epoch 118/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5104 - acc: 0.6910 - val_loss: 0.5431 - val_acc: 0.6823\n",
      "Epoch 119/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5093 - acc: 0.6910 - val_loss: 0.5426 - val_acc: 0.6875\n",
      "Epoch 120/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5083 - acc: 0.6944 - val_loss: 0.5420 - val_acc: 0.6927\n",
      "Epoch 121/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5072 - acc: 0.6979 - val_loss: 0.5415 - val_acc: 0.6927\n",
      "Epoch 122/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5062 - acc: 0.7066 - val_loss: 0.5409 - val_acc: 0.6927\n",
      "Epoch 123/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5052 - acc: 0.7101 - val_loss: 0.5404 - val_acc: 0.6823\n",
      "Epoch 124/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5043 - acc: 0.7153 - val_loss: 0.5398 - val_acc: 0.6875\n",
      "Epoch 125/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5033 - acc: 0.7153 - val_loss: 0.5393 - val_acc: 0.6823\n",
      "Epoch 126/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5023 - acc: 0.7222 - val_loss: 0.5387 - val_acc: 0.6927\n",
      "Epoch 127/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5014 - acc: 0.7205 - val_loss: 0.5382 - val_acc: 0.6979\n",
      "Epoch 128/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5005 - acc: 0.7257 - val_loss: 0.5377 - val_acc: 0.6927\n",
      "Epoch 129/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4995 - acc: 0.7309 - val_loss: 0.5372 - val_acc: 0.6979\n",
      "Epoch 130/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4986 - acc: 0.7378 - val_loss: 0.5367 - val_acc: 0.6979\n",
      "Epoch 131/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4977 - acc: 0.7431 - val_loss: 0.5361 - val_acc: 0.7031\n",
      "Epoch 132/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4968 - acc: 0.7465 - val_loss: 0.5356 - val_acc: 0.7135\n",
      "Epoch 133/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4959 - acc: 0.7465 - val_loss: 0.5351 - val_acc: 0.7135\n",
      "Epoch 134/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4950 - acc: 0.7465 - val_loss: 0.5346 - val_acc: 0.7135\n",
      "Epoch 135/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4941 - acc: 0.7552 - val_loss: 0.5342 - val_acc: 0.7135\n",
      "Epoch 136/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4933 - acc: 0.7535 - val_loss: 0.5337 - val_acc: 0.7135\n",
      "Epoch 137/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4923 - acc: 0.7500 - val_loss: 0.5333 - val_acc: 0.7135\n",
      "Epoch 138/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4914 - acc: 0.7552 - val_loss: 0.5329 - val_acc: 0.7135\n",
      "Epoch 139/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4906 - acc: 0.7587 - val_loss: 0.5325 - val_acc: 0.7135\n",
      "Epoch 140/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4898 - acc: 0.7604 - val_loss: 0.5321 - val_acc: 0.7135\n",
      "Epoch 141/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4889 - acc: 0.7604 - val_loss: 0.5317 - val_acc: 0.7135\n",
      "Epoch 142/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4880 - acc: 0.7674 - val_loss: 0.5313 - val_acc: 0.7188\n",
      "Epoch 143/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4873 - acc: 0.7656 - val_loss: 0.5309 - val_acc: 0.7188\n",
      "Epoch 144/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4865 - acc: 0.7674 - val_loss: 0.5305 - val_acc: 0.7240\n",
      "Epoch 145/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4856 - acc: 0.7691 - val_loss: 0.5301 - val_acc: 0.7240\n",
      "Epoch 146/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4848 - acc: 0.7674 - val_loss: 0.5297 - val_acc: 0.7240\n",
      "Epoch 147/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4840 - acc: 0.7708 - val_loss: 0.5293 - val_acc: 0.7240\n",
      "Epoch 148/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4832 - acc: 0.7708 - val_loss: 0.5289 - val_acc: 0.7240\n",
      "Epoch 149/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4825 - acc: 0.7674 - val_loss: 0.5285 - val_acc: 0.7240\n",
      "Epoch 150/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4818 - acc: 0.7708 - val_loss: 0.5282 - val_acc: 0.7292\n",
      "Epoch 151/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4810 - acc: 0.7726 - val_loss: 0.5278 - val_acc: 0.7292\n",
      "Epoch 152/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4803 - acc: 0.7708 - val_loss: 0.5274 - val_acc: 0.7292\n",
      "Epoch 153/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4796 - acc: 0.7708 - val_loss: 0.5270 - val_acc: 0.7292\n",
      "Epoch 154/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4789 - acc: 0.7708 - val_loss: 0.5267 - val_acc: 0.7292\n",
      "Epoch 155/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4781 - acc: 0.7691 - val_loss: 0.5263 - val_acc: 0.7240\n",
      "Epoch 156/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4775 - acc: 0.7726 - val_loss: 0.5260 - val_acc: 0.7292\n",
      "Epoch 157/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4768 - acc: 0.7708 - val_loss: 0.5256 - val_acc: 0.7292\n",
      "Epoch 158/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4761 - acc: 0.7726 - val_loss: 0.5253 - val_acc: 0.7344\n",
      "Epoch 159/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4755 - acc: 0.7743 - val_loss: 0.5249 - val_acc: 0.7344\n",
      "Epoch 160/500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4748 - acc: 0.7743 - val_loss: 0.5246 - val_acc: 0.7344\n",
      "Epoch 161/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4742 - acc: 0.7743 - val_loss: 0.5243 - val_acc: 0.7344\n",
      "Epoch 162/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4736 - acc: 0.7743 - val_loss: 0.5240 - val_acc: 0.7344\n",
      "Epoch 163/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4729 - acc: 0.7743 - val_loss: 0.5236 - val_acc: 0.7344\n",
      "Epoch 164/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4723 - acc: 0.7743 - val_loss: 0.5233 - val_acc: 0.7344\n",
      "Epoch 165/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4717 - acc: 0.7743 - val_loss: 0.5229 - val_acc: 0.7344\n",
      "Epoch 166/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4712 - acc: 0.7760 - val_loss: 0.5225 - val_acc: 0.7344\n",
      "Epoch 167/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4705 - acc: 0.7743 - val_loss: 0.5222 - val_acc: 0.7292\n",
      "Epoch 168/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4699 - acc: 0.7743 - val_loss: 0.5218 - val_acc: 0.7292\n",
      "Epoch 169/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4694 - acc: 0.7760 - val_loss: 0.5214 - val_acc: 0.7292\n",
      "Epoch 170/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4688 - acc: 0.7760 - val_loss: 0.5211 - val_acc: 0.7292\n",
      "Epoch 171/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4682 - acc: 0.7760 - val_loss: 0.5208 - val_acc: 0.7292\n",
      "Epoch 172/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4677 - acc: 0.7743 - val_loss: 0.5205 - val_acc: 0.7292\n",
      "Epoch 173/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4672 - acc: 0.7743 - val_loss: 0.5202 - val_acc: 0.7292\n",
      "Epoch 174/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.5200 - val_acc: 0.7240\n",
      "Epoch 175/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4661 - acc: 0.7760 - val_loss: 0.5197 - val_acc: 0.7240\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4655 - acc: 0.7760 - val_loss: 0.5194 - val_acc: 0.7240\n",
      "Epoch 177/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4650 - acc: 0.7778 - val_loss: 0.5192 - val_acc: 0.7240\n",
      "Epoch 178/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4645 - acc: 0.7778 - val_loss: 0.5190 - val_acc: 0.7240\n",
      "Epoch 179/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4640 - acc: 0.7778 - val_loss: 0.5188 - val_acc: 0.7240\n",
      "Epoch 180/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4635 - acc: 0.7778 - val_loss: 0.5186 - val_acc: 0.7240\n",
      "Epoch 181/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4631 - acc: 0.7795 - val_loss: 0.5185 - val_acc: 0.7292\n",
      "Epoch 182/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4625 - acc: 0.7795 - val_loss: 0.5184 - val_acc: 0.7292\n",
      "Epoch 183/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4621 - acc: 0.7812 - val_loss: 0.5184 - val_acc: 0.7292\n",
      "Epoch 184/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4616 - acc: 0.7795 - val_loss: 0.5183 - val_acc: 0.7292\n",
      "Epoch 185/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4611 - acc: 0.7778 - val_loss: 0.5182 - val_acc: 0.7292\n",
      "Epoch 186/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4607 - acc: 0.7812 - val_loss: 0.5182 - val_acc: 0.7292\n",
      "Epoch 187/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4603 - acc: 0.7830 - val_loss: 0.5182 - val_acc: 0.7292\n",
      "Epoch 188/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4599 - acc: 0.7830 - val_loss: 0.5181 - val_acc: 0.7292\n",
      "Epoch 189/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4595 - acc: 0.7830 - val_loss: 0.5180 - val_acc: 0.7240\n",
      "Epoch 190/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4591 - acc: 0.7830 - val_loss: 0.5179 - val_acc: 0.7240\n",
      "Epoch 191/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4588 - acc: 0.7830 - val_loss: 0.5178 - val_acc: 0.7240\n",
      "Epoch 192/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4583 - acc: 0.7830 - val_loss: 0.5176 - val_acc: 0.7240\n",
      "Epoch 193/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4579 - acc: 0.7830 - val_loss: 0.5175 - val_acc: 0.7240\n",
      "Epoch 194/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4575 - acc: 0.7830 - val_loss: 0.5173 - val_acc: 0.7240\n",
      "Epoch 195/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4571 - acc: 0.7830 - val_loss: 0.5171 - val_acc: 0.7240\n",
      "Epoch 196/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4568 - acc: 0.7830 - val_loss: 0.5169 - val_acc: 0.7292\n",
      "Epoch 197/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4564 - acc: 0.7812 - val_loss: 0.5167 - val_acc: 0.7292\n",
      "Epoch 198/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4561 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7292\n",
      "Epoch 199/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4558 - acc: 0.7778 - val_loss: 0.5164 - val_acc: 0.7292\n",
      "Epoch 200/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4555 - acc: 0.7830 - val_loss: 0.5163 - val_acc: 0.7292\n",
      "Epoch 201/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4551 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7292\n",
      "Epoch 202/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4548 - acc: 0.7812 - val_loss: 0.5159 - val_acc: 0.7292\n",
      "Epoch 203/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4546 - acc: 0.7795 - val_loss: 0.5158 - val_acc: 0.7292\n",
      "Epoch 204/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4543 - acc: 0.7778 - val_loss: 0.5157 - val_acc: 0.7292\n",
      "Epoch 205/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4541 - acc: 0.7760 - val_loss: 0.5156 - val_acc: 0.7292\n",
      "Epoch 206/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4537 - acc: 0.7760 - val_loss: 0.5155 - val_acc: 0.7292\n",
      "Epoch 207/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4536 - acc: 0.7760 - val_loss: 0.5154 - val_acc: 0.7292\n",
      "Epoch 208/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4533 - acc: 0.7760 - val_loss: 0.5153 - val_acc: 0.7292\n",
      "Epoch 209/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4530 - acc: 0.7743 - val_loss: 0.5152 - val_acc: 0.7292\n",
      "Epoch 210/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4528 - acc: 0.7760 - val_loss: 0.5151 - val_acc: 0.7292\n",
      "Epoch 211/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4524 - acc: 0.7778 - val_loss: 0.5150 - val_acc: 0.7292\n",
      "Epoch 212/500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4521 - acc: 0.7760 - val_loss: 0.5148 - val_acc: 0.7292\n",
      "Epoch 213/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4520 - acc: 0.7760 - val_loss: 0.5147 - val_acc: 0.7292\n",
      "Epoch 214/500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4517 - acc: 0.7778 - val_loss: 0.5145 - val_acc: 0.7240\n",
      "Epoch 215/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4514 - acc: 0.7778 - val_loss: 0.5144 - val_acc: 0.7240\n",
      "Epoch 216/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4512 - acc: 0.7795 - val_loss: 0.5142 - val_acc: 0.7240\n",
      "Epoch 217/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4509 - acc: 0.7778 - val_loss: 0.5141 - val_acc: 0.7240\n",
      "Epoch 218/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4508 - acc: 0.7795 - val_loss: 0.5140 - val_acc: 0.7240\n",
      "Epoch 219/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4505 - acc: 0.7778 - val_loss: 0.5138 - val_acc: 0.7240\n",
      "Epoch 220/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4502 - acc: 0.7795 - val_loss: 0.5136 - val_acc: 0.7240\n",
      "Epoch 221/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4500 - acc: 0.7778 - val_loss: 0.5134 - val_acc: 0.7240\n",
      "Epoch 222/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4497 - acc: 0.7778 - val_loss: 0.5132 - val_acc: 0.7240\n",
      "Epoch 223/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4495 - acc: 0.7778 - val_loss: 0.5130 - val_acc: 0.7240\n",
      "Epoch 224/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4493 - acc: 0.7778 - val_loss: 0.5129 - val_acc: 0.7240\n",
      "Epoch 225/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4490 - acc: 0.7778 - val_loss: 0.5128 - val_acc: 0.7240\n",
      "Epoch 226/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4488 - acc: 0.7760 - val_loss: 0.5126 - val_acc: 0.7240\n",
      "Epoch 227/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4486 - acc: 0.7760 - val_loss: 0.5124 - val_acc: 0.7240\n",
      "Epoch 228/500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4483 - acc: 0.7760 - val_loss: 0.5123 - val_acc: 0.7240\n",
      "Epoch 229/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4481 - acc: 0.7743 - val_loss: 0.5121 - val_acc: 0.7240\n",
      "Epoch 230/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4479 - acc: 0.7760 - val_loss: 0.5120 - val_acc: 0.7240\n",
      "Epoch 231/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4478 - acc: 0.7743 - val_loss: 0.5118 - val_acc: 0.7240\n",
      "Epoch 232/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4475 - acc: 0.7726 - val_loss: 0.5117 - val_acc: 0.7240\n",
      "Epoch 233/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4473 - acc: 0.7743 - val_loss: 0.5116 - val_acc: 0.7240\n",
      "Epoch 234/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4471 - acc: 0.7726 - val_loss: 0.5116 - val_acc: 0.7240\n",
      "Epoch 235/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4468 - acc: 0.7726 - val_loss: 0.5114 - val_acc: 0.7240\n",
      "Epoch 236/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4466 - acc: 0.7726 - val_loss: 0.5112 - val_acc: 0.7240\n",
      "Epoch 237/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4464 - acc: 0.7726 - val_loss: 0.5111 - val_acc: 0.7240\n",
      "Epoch 238/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4463 - acc: 0.7726 - val_loss: 0.5110 - val_acc: 0.7240\n",
      "Epoch 239/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4460 - acc: 0.7726 - val_loss: 0.5108 - val_acc: 0.7292\n",
      "Epoch 240/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4458 - acc: 0.7726 - val_loss: 0.5107 - val_acc: 0.7292\n",
      "Epoch 241/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4455 - acc: 0.7726 - val_loss: 0.5105 - val_acc: 0.7292\n",
      "Epoch 242/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4455 - acc: 0.7726 - val_loss: 0.5104 - val_acc: 0.7292\n",
      "Epoch 243/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4452 - acc: 0.7726 - val_loss: 0.5102 - val_acc: 0.7292\n",
      "Epoch 244/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4451 - acc: 0.7726 - val_loss: 0.5101 - val_acc: 0.7292\n",
      "Epoch 245/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4448 - acc: 0.7726 - val_loss: 0.5100 - val_acc: 0.7292\n",
      "Epoch 246/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7743 - val_loss: 0.5098 - val_acc: 0.7292\n",
      "Epoch 247/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7726 - val_loss: 0.5096 - val_acc: 0.7292\n",
      "Epoch 248/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4442 - acc: 0.7760 - val_loss: 0.5094 - val_acc: 0.7292\n",
      "Epoch 249/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4441 - acc: 0.7743 - val_loss: 0.5093 - val_acc: 0.7292\n",
      "Epoch 250/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4439 - acc: 0.7743 - val_loss: 0.5091 - val_acc: 0.7292\n",
      "Epoch 251/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4437 - acc: 0.7760 - val_loss: 0.5090 - val_acc: 0.7292\n",
      "Epoch 252/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4435 - acc: 0.7760 - val_loss: 0.5088 - val_acc: 0.7292\n",
      "Epoch 253/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4434 - acc: 0.7743 - val_loss: 0.5087 - val_acc: 0.7292\n",
      "Epoch 254/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4432 - acc: 0.7760 - val_loss: 0.5086 - val_acc: 0.7292\n",
      "Epoch 255/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4430 - acc: 0.7743 - val_loss: 0.5086 - val_acc: 0.7292\n",
      "Epoch 256/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4428 - acc: 0.7760 - val_loss: 0.5084 - val_acc: 0.7292\n",
      "Epoch 257/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4426 - acc: 0.7760 - val_loss: 0.5084 - val_acc: 0.7292\n",
      "Epoch 258/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4425 - acc: 0.7743 - val_loss: 0.5083 - val_acc: 0.7292\n",
      "Epoch 259/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4424 - acc: 0.7760 - val_loss: 0.5082 - val_acc: 0.7292\n",
      "Epoch 260/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4422 - acc: 0.7743 - val_loss: 0.5080 - val_acc: 0.7292\n",
      "Epoch 261/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4421 - acc: 0.7760 - val_loss: 0.5080 - val_acc: 0.7292\n",
      "Epoch 262/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4419 - acc: 0.7743 - val_loss: 0.5079 - val_acc: 0.7292\n",
      "Epoch 263/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4417 - acc: 0.7743 - val_loss: 0.5078 - val_acc: 0.7292\n",
      "Epoch 264/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4416 - acc: 0.7726 - val_loss: 0.5077 - val_acc: 0.7292\n",
      "Epoch 265/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7743 - val_loss: 0.5075 - val_acc: 0.7292\n",
      "Epoch 266/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4412 - acc: 0.7743 - val_loss: 0.5075 - val_acc: 0.7292\n",
      "Epoch 267/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4411 - acc: 0.7743 - val_loss: 0.5074 - val_acc: 0.7292\n",
      "Epoch 268/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4409 - acc: 0.7743 - val_loss: 0.5073 - val_acc: 0.7292\n",
      "Epoch 269/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4408 - acc: 0.7726 - val_loss: 0.5073 - val_acc: 0.7292\n",
      "Epoch 270/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4406 - acc: 0.7743 - val_loss: 0.5072 - val_acc: 0.7292\n",
      "Epoch 271/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4405 - acc: 0.7743 - val_loss: 0.5072 - val_acc: 0.7292\n",
      "Epoch 272/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4403 - acc: 0.7743 - val_loss: 0.5071 - val_acc: 0.7292\n",
      "Epoch 273/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4401 - acc: 0.7743 - val_loss: 0.5070 - val_acc: 0.7292\n",
      "Epoch 274/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4401 - acc: 0.7760 - val_loss: 0.5070 - val_acc: 0.7292\n",
      "Epoch 275/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4398 - acc: 0.7760 - val_loss: 0.5069 - val_acc: 0.7292\n",
      "Epoch 276/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4398 - acc: 0.7760 - val_loss: 0.5069 - val_acc: 0.7292\n",
      "Epoch 277/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4396 - acc: 0.7760 - val_loss: 0.5068 - val_acc: 0.7292\n",
      "Epoch 278/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4394 - acc: 0.7743 - val_loss: 0.5067 - val_acc: 0.7292\n",
      "Epoch 279/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4393 - acc: 0.7795 - val_loss: 0.5066 - val_acc: 0.7292\n",
      "Epoch 280/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4392 - acc: 0.7760 - val_loss: 0.5066 - val_acc: 0.7292\n",
      "Epoch 281/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4390 - acc: 0.7795 - val_loss: 0.5067 - val_acc: 0.7292\n",
      "Epoch 282/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4389 - acc: 0.7760 - val_loss: 0.5066 - val_acc: 0.7292\n",
      "Epoch 283/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4388 - acc: 0.7778 - val_loss: 0.5066 - val_acc: 0.7292\n",
      "Epoch 284/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4386 - acc: 0.7812 - val_loss: 0.5065 - val_acc: 0.7292\n",
      "Epoch 285/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4386 - acc: 0.7795 - val_loss: 0.5064 - val_acc: 0.7240\n",
      "Epoch 286/500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4384 - acc: 0.7795 - val_loss: 0.5064 - val_acc: 0.7240\n",
      "Epoch 287/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4382 - acc: 0.7795 - val_loss: 0.5064 - val_acc: 0.7240\n",
      "Epoch 288/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4382 - acc: 0.7778 - val_loss: 0.5064 - val_acc: 0.7240\n",
      "Epoch 289/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4380 - acc: 0.7812 - val_loss: 0.5062 - val_acc: 0.7240\n",
      "Epoch 290/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4378 - acc: 0.7795 - val_loss: 0.5061 - val_acc: 0.7240\n",
      "Epoch 291/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4377 - acc: 0.7812 - val_loss: 0.5061 - val_acc: 0.7240\n",
      "Epoch 292/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4375 - acc: 0.7812 - val_loss: 0.5061 - val_acc: 0.7292\n",
      "Epoch 293/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7812 - val_loss: 0.5059 - val_acc: 0.7292\n",
      "Epoch 294/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - acc: 0.7830 - val_loss: 0.5059 - val_acc: 0.7292\n",
      "Epoch 295/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4371 - acc: 0.7812 - val_loss: 0.5059 - val_acc: 0.7292\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4371 - acc: 0.7812 - val_loss: 0.5057 - val_acc: 0.7292\n",
      "Epoch 297/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4369 - acc: 0.7830 - val_loss: 0.5058 - val_acc: 0.7292\n",
      "Epoch 298/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4368 - acc: 0.7847 - val_loss: 0.5057 - val_acc: 0.7292\n",
      "Epoch 299/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - acc: 0.7830 - val_loss: 0.5057 - val_acc: 0.7292\n",
      "Epoch 300/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4366 - acc: 0.7812 - val_loss: 0.5057 - val_acc: 0.7292\n",
      "Epoch 301/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4366 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7292\n",
      "Epoch 302/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4364 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7292\n",
      "Epoch 303/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4362 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7240\n",
      "Epoch 304/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4361 - acc: 0.7830 - val_loss: 0.5056 - val_acc: 0.7240\n",
      "Epoch 305/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4361 - acc: 0.7830 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 306/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4359 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7240\n",
      "Epoch 307/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4359 - acc: 0.7830 - val_loss: 0.5056 - val_acc: 0.7240\n",
      "Epoch 308/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4358 - acc: 0.7830 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 309/500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7292\n",
      "Epoch 310/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4355 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 311/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4354 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7292\n",
      "Epoch 312/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 313/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 314/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4352 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7240\n",
      "Epoch 315/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4351 - acc: 0.7830 - val_loss: 0.5054 - val_acc: 0.7240\n",
      "Epoch 316/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 317/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4349 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 318/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4347 - acc: 0.7830 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 319/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - acc: 0.7830 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 320/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4346 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7240\n",
      "Epoch 321/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4344 - acc: 0.7830 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 322/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7240\n",
      "Epoch 323/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4343 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7240\n",
      "Epoch 324/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4342 - acc: 0.7830 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 325/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 326/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 327/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4339 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 328/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4337 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 329/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7240\n",
      "Epoch 330/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4335 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7240\n",
      "Epoch 331/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5051 - val_acc: 0.7240\n",
      "Epoch 332/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4333 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 333/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4333 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 334/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4332 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 335/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 336/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4329 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 337/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4328 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 338/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4327 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 339/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4326 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 340/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4326 - acc: 0.7865 - val_loss: 0.5052 - val_acc: 0.7240\n",
      "Epoch 341/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4324 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 342/500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4323 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 343/500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 344/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4321 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7240\n",
      "Epoch 345/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4321 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7292\n",
      "Epoch 346/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4320 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7292\n",
      "Epoch 347/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4318 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 348/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4318 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 349/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4317 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7292\n",
      "Epoch 350/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4316 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 351/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4315 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 352/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4314 - acc: 0.7882 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 353/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4312 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7292\n",
      "Epoch 354/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4312 - acc: 0.7882 - val_loss: 0.5055 - val_acc: 0.7292\n",
      "Epoch 355/500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4311 - acc: 0.7882 - val_loss: 0.5055 - val_acc: 0.7292\n",
      "Epoch 356/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4309 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7292\n",
      "Epoch 357/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4309 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7344\n",
      "Epoch 358/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4308 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7344\n",
      "Epoch 359/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7344\n",
      "Epoch 360/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7344\n",
      "Epoch 361/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7344\n",
      "Epoch 362/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4305 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7344\n",
      "Epoch 363/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4304 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7344\n",
      "Epoch 364/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4303 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7344\n",
      "Epoch 365/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4301 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7344\n",
      "Epoch 366/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4301 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7344\n",
      "Epoch 367/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4299 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7344\n",
      "Epoch 368/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4300 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7344\n",
      "Epoch 369/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4297 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7344\n",
      "Epoch 370/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4297 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7344\n",
      "Epoch 371/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4296 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7344\n",
      "Epoch 372/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4296 - acc: 0.7899 - val_loss: 0.5061 - val_acc: 0.7344\n",
      "Epoch 373/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4294 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7344\n",
      "Epoch 374/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4293 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7344\n",
      "Epoch 375/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4293 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7344\n",
      "Epoch 376/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4292 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7344\n",
      "Epoch 377/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7344\n",
      "Epoch 378/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4290 - acc: 0.7882 - val_loss: 0.5065 - val_acc: 0.7344\n",
      "Epoch 379/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4291 - acc: 0.7882 - val_loss: 0.5065 - val_acc: 0.7344\n",
      "Epoch 380/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4290 - acc: 0.7882 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 381/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4288 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 382/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4287 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 383/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4287 - acc: 0.7882 - val_loss: 0.5068 - val_acc: 0.7344\n",
      "Epoch 384/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4286 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 385/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 386/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4286 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 387/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4284 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 388/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 389/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4282 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 390/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4282 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 391/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4280 - acc: 0.7882 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 392/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4280 - acc: 0.7847 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 393/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4278 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 394/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - acc: 0.7882 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 395/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4276 - acc: 0.7847 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 396/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4276 - acc: 0.7865 - val_loss: 0.5066 - val_acc: 0.7344\n",
      "Epoch 397/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 398/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 399/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4274 - acc: 0.7865 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 400/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4273 - acc: 0.7899 - val_loss: 0.5067 - val_acc: 0.7344\n",
      "Epoch 401/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4272 - acc: 0.7865 - val_loss: 0.5068 - val_acc: 0.7344\n",
      "Epoch 402/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4271 - acc: 0.7882 - val_loss: 0.5069 - val_acc: 0.7344\n",
      "Epoch 403/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4270 - acc: 0.7882 - val_loss: 0.5069 - val_acc: 0.7344\n",
      "Epoch 404/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4269 - acc: 0.7882 - val_loss: 0.5069 - val_acc: 0.7344\n",
      "Epoch 405/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4269 - acc: 0.7899 - val_loss: 0.5070 - val_acc: 0.7344\n",
      "Epoch 406/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4269 - acc: 0.7899 - val_loss: 0.5071 - val_acc: 0.7344\n",
      "Epoch 407/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4267 - acc: 0.7882 - val_loss: 0.5072 - val_acc: 0.7344\n",
      "Epoch 408/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4267 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7396\n",
      "Epoch 409/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4267 - acc: 0.7899 - val_loss: 0.5071 - val_acc: 0.7396\n",
      "Epoch 410/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4265 - acc: 0.7865 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 411/500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4265 - acc: 0.7899 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 412/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4263 - acc: 0.7899 - val_loss: 0.5073 - val_acc: 0.7396\n",
      "Epoch 413/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4264 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 414/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4262 - acc: 0.7899 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 415/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4262 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 416/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4260 - acc: 0.7899 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 417/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4260 - acc: 0.7899 - val_loss: 0.5073 - val_acc: 0.7396\n",
      "Epoch 418/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4258 - acc: 0.7899 - val_loss: 0.5073 - val_acc: 0.7396\n",
      "Epoch 419/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4259 - acc: 0.7917 - val_loss: 0.5073 - val_acc: 0.7396\n",
      "Epoch 420/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4257 - acc: 0.7899 - val_loss: 0.5073 - val_acc: 0.7396\n",
      "Epoch 421/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - acc: 0.7917 - val_loss: 0.5074 - val_acc: 0.7396\n",
      "Epoch 422/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4255 - acc: 0.7917 - val_loss: 0.5074 - val_acc: 0.7396\n",
      "Epoch 423/500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4255 - acc: 0.7899 - val_loss: 0.5074 - val_acc: 0.7396\n",
      "Epoch 424/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5075 - val_acc: 0.7396\n",
      "Epoch 425/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4253 - acc: 0.7899 - val_loss: 0.5075 - val_acc: 0.7396\n",
      "Epoch 426/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5076 - val_acc: 0.7396\n",
      "Epoch 427/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4251 - acc: 0.7899 - val_loss: 0.5075 - val_acc: 0.7396\n",
      "Epoch 428/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5076 - val_acc: 0.7396\n",
      "Epoch 429/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5076 - val_acc: 0.7396\n",
      "Epoch 430/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5077 - val_acc: 0.7396\n",
      "Epoch 431/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5078 - val_acc: 0.7396\n",
      "Epoch 432/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5078 - val_acc: 0.7396\n",
      "Epoch 433/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4246 - acc: 0.7917 - val_loss: 0.5078 - val_acc: 0.7396\n",
      "Epoch 434/500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4247 - acc: 0.7917 - val_loss: 0.5079 - val_acc: 0.7396\n",
      "Epoch 435/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4245 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7396\n",
      "Epoch 436/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7396\n",
      "Epoch 437/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4243 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7396\n",
      "Epoch 438/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7396\n",
      "Epoch 439/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7396\n",
      "Epoch 440/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7396\n",
      "Epoch 441/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4241 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7396\n",
      "Epoch 442/500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4240 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7396\n",
      "Epoch 443/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4239 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7396\n",
      "Epoch 444/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4239 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7396\n",
      "Epoch 445/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4238 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7396\n",
      "Epoch 446/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7396\n",
      "Epoch 447/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4237 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7396\n",
      "Epoch 448/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7396\n",
      "Epoch 449/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5087 - val_acc: 0.7396\n",
      "Epoch 450/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5087 - val_acc: 0.7396\n",
      "Epoch 451/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5087 - val_acc: 0.7396\n",
      "Epoch 452/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4233 - acc: 0.7951 - val_loss: 0.5087 - val_acc: 0.7396\n",
      "Epoch 453/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5088 - val_acc: 0.7396\n",
      "Epoch 454/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5088 - val_acc: 0.7396\n",
      "Epoch 455/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4230 - acc: 0.7951 - val_loss: 0.5089 - val_acc: 0.7396\n",
      "Epoch 456/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4229 - acc: 0.7951 - val_loss: 0.5089 - val_acc: 0.7344\n",
      "Epoch 457/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4229 - acc: 0.7951 - val_loss: 0.5090 - val_acc: 0.7344\n",
      "Epoch 458/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4227 - acc: 0.7951 - val_loss: 0.5090 - val_acc: 0.7344\n",
      "Epoch 459/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4226 - acc: 0.7969 - val_loss: 0.5092 - val_acc: 0.7344\n",
      "Epoch 460/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4226 - acc: 0.7951 - val_loss: 0.5092 - val_acc: 0.7344\n",
      "Epoch 461/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4225 - acc: 0.7951 - val_loss: 0.5093 - val_acc: 0.7344\n",
      "Epoch 462/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4224 - acc: 0.7951 - val_loss: 0.5093 - val_acc: 0.7344\n",
      "Epoch 463/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4224 - acc: 0.7951 - val_loss: 0.5093 - val_acc: 0.7344\n",
      "Epoch 464/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4223 - acc: 0.7951 - val_loss: 0.5093 - val_acc: 0.7344\n",
      "Epoch 465/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4222 - acc: 0.7951 - val_loss: 0.5094 - val_acc: 0.7344\n",
      "Epoch 466/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4222 - acc: 0.7969 - val_loss: 0.5095 - val_acc: 0.7344\n",
      "Epoch 467/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4221 - acc: 0.7951 - val_loss: 0.5095 - val_acc: 0.7344\n",
      "Epoch 468/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4220 - acc: 0.7969 - val_loss: 0.5097 - val_acc: 0.7344\n",
      "Epoch 469/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4219 - acc: 0.7951 - val_loss: 0.5098 - val_acc: 0.7344\n",
      "Epoch 470/500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4218 - acc: 0.7951 - val_loss: 0.5098 - val_acc: 0.7344\n",
      "Epoch 471/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4217 - acc: 0.7969 - val_loss: 0.5100 - val_acc: 0.7344\n",
      "Epoch 472/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4217 - acc: 0.7951 - val_loss: 0.5100 - val_acc: 0.7344\n",
      "Epoch 473/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4216 - acc: 0.7951 - val_loss: 0.5101 - val_acc: 0.7344\n",
      "Epoch 474/500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4215 - acc: 0.7969 - val_loss: 0.5102 - val_acc: 0.7344\n",
      "Epoch 475/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4215 - acc: 0.7951 - val_loss: 0.5103 - val_acc: 0.7344\n",
      "Epoch 476/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4214 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7344\n",
      "Epoch 477/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4213 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7344\n",
      "Epoch 478/500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4212 - acc: 0.7951 - val_loss: 0.5106 - val_acc: 0.7344\n",
      "Epoch 479/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4213 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7344\n",
      "Epoch 480/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4211 - acc: 0.7951 - val_loss: 0.5107 - val_acc: 0.7344\n",
      "Epoch 481/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4211 - acc: 0.7934 - val_loss: 0.5107 - val_acc: 0.7344\n",
      "Epoch 482/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4211 - acc: 0.7951 - val_loss: 0.5107 - val_acc: 0.7344\n",
      "Epoch 483/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4209 - acc: 0.7951 - val_loss: 0.5109 - val_acc: 0.7344\n",
      "Epoch 484/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4209 - acc: 0.7969 - val_loss: 0.5110 - val_acc: 0.7344\n",
      "Epoch 485/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4208 - acc: 0.7951 - val_loss: 0.5111 - val_acc: 0.7344\n",
      "Epoch 486/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4209 - acc: 0.7969 - val_loss: 0.5111 - val_acc: 0.7344\n",
      "Epoch 487/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.5112 - val_acc: 0.7344\n",
      "Epoch 488/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4207 - acc: 0.7969 - val_loss: 0.5114 - val_acc: 0.7344\n",
      "Epoch 489/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4206 - acc: 0.7951 - val_loss: 0.5115 - val_acc: 0.7344\n",
      "Epoch 490/500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4205 - acc: 0.7969 - val_loss: 0.5115 - val_acc: 0.7344\n",
      "Epoch 491/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5116 - val_acc: 0.7344\n",
      "Epoch 492/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5117 - val_acc: 0.7344\n",
      "Epoch 493/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4204 - acc: 0.7969 - val_loss: 0.5117 - val_acc: 0.7344\n",
      "Epoch 494/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.5118 - val_acc: 0.7344\n",
      "Epoch 495/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4202 - acc: 0.7969 - val_loss: 0.5117 - val_acc: 0.7344\n",
      "Epoch 496/500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4201 - acc: 0.7969 - val_loss: 0.5118 - val_acc: 0.7344\n",
      "Epoch 497/500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4201 - acc: 0.7986 - val_loss: 0.5117 - val_acc: 0.7396\n",
      "Epoch 498/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4200 - acc: 0.7986 - val_loss: 0.5117 - val_acc: 0.7396\n",
      "Epoch 499/500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4199 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7396\n",
      "Epoch 500/500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4198 - acc: 0.7986 - val_loss: 0.5118 - val_acc: 0.7396\n",
      "\n",
      "accuracy is 0.740\n",
      "roc-auc is 0.816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#experimenting with different values\n",
    "\n",
    "#Creating Model with 2 hidden layers, each has 6 nodes and relu activation \n",
    "#The final layers has 1 node and sigmoid activation\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape=(8,),activation=\"relu\"), \n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "]) \n",
    "\n",
    "#This function summarizes the details of the model \n",
    "model_3.summary()\n",
    "\n",
    "#Experimenting with a new learning rate and a different number of epochs\n",
    "#Compiling the model with lr=0.006, training for 500 epochs \n",
    "model_3.compile(SGD(lr = .006), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_3 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500)\n",
    "\n",
    "\n",
    "#plotting values \n",
    "n = len(run_hist_3.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_3.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_3.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_3.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_3.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')\n",
    "\n",
    "y_pred_class_nn_3 = model_3.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_3 = model_3.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_3)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_3)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_3, 'NN-3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/3000\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.7086 - acc: 0.5694 - val_loss: 0.7159 - val_acc: 0.5885\n",
      "Epoch 2/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7067 - acc: 0.5816 - val_loss: 0.7140 - val_acc: 0.5885\n",
      "Epoch 3/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7048 - acc: 0.5903 - val_loss: 0.7122 - val_acc: 0.5938\n",
      "Epoch 4/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7029 - acc: 0.5938 - val_loss: 0.7105 - val_acc: 0.6146\n",
      "Epoch 5/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.7011 - acc: 0.5955 - val_loss: 0.7087 - val_acc: 0.6146\n",
      "Epoch 6/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6993 - acc: 0.5990 - val_loss: 0.7071 - val_acc: 0.6198\n",
      "Epoch 7/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6975 - acc: 0.6007 - val_loss: 0.7054 - val_acc: 0.6198\n",
      "Epoch 8/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6958 - acc: 0.5868 - val_loss: 0.7037 - val_acc: 0.6250\n",
      "Epoch 9/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6941 - acc: 0.5938 - val_loss: 0.7021 - val_acc: 0.6406\n",
      "Epoch 10/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6924 - acc: 0.5990 - val_loss: 0.7005 - val_acc: 0.6406\n",
      "Epoch 11/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6907 - acc: 0.5990 - val_loss: 0.6989 - val_acc: 0.6406\n",
      "Epoch 12/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6891 - acc: 0.6076 - val_loss: 0.6974 - val_acc: 0.6510\n",
      "Epoch 13/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6875 - acc: 0.6163 - val_loss: 0.6959 - val_acc: 0.6458\n",
      "Epoch 14/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6859 - acc: 0.6198 - val_loss: 0.6944 - val_acc: 0.6562\n",
      "Epoch 15/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6844 - acc: 0.6215 - val_loss: 0.6929 - val_acc: 0.6562\n",
      "Epoch 16/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6829 - acc: 0.6267 - val_loss: 0.6914 - val_acc: 0.6562\n",
      "Epoch 17/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6813 - acc: 0.6302 - val_loss: 0.6900 - val_acc: 0.6458\n",
      "Epoch 18/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6798 - acc: 0.6319 - val_loss: 0.6886 - val_acc: 0.6458\n",
      "Epoch 19/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6784 - acc: 0.6337 - val_loss: 0.6872 - val_acc: 0.6458\n",
      "Epoch 20/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6769 - acc: 0.6319 - val_loss: 0.6858 - val_acc: 0.6510\n",
      "Epoch 21/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6755 - acc: 0.6319 - val_loss: 0.6844 - val_acc: 0.6562\n",
      "Epoch 22/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6740 - acc: 0.6372 - val_loss: 0.6831 - val_acc: 0.6510\n",
      "Epoch 23/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6726 - acc: 0.6389 - val_loss: 0.6817 - val_acc: 0.6510\n",
      "Epoch 24/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6713 - acc: 0.6424 - val_loss: 0.6804 - val_acc: 0.6615\n",
      "Epoch 25/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6699 - acc: 0.6458 - val_loss: 0.6791 - val_acc: 0.6615\n",
      "Epoch 26/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6686 - acc: 0.6476 - val_loss: 0.6778 - val_acc: 0.6615\n",
      "Epoch 27/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6672 - acc: 0.6528 - val_loss: 0.6765 - val_acc: 0.6615\n",
      "Epoch 28/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6659 - acc: 0.6562 - val_loss: 0.6752 - val_acc: 0.6667\n",
      "Epoch 29/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6646 - acc: 0.6597 - val_loss: 0.6739 - val_acc: 0.6667\n",
      "Epoch 30/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6633 - acc: 0.6615 - val_loss: 0.6727 - val_acc: 0.6667\n",
      "Epoch 31/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6620 - acc: 0.6684 - val_loss: 0.6715 - val_acc: 0.6667\n",
      "Epoch 32/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6608 - acc: 0.6684 - val_loss: 0.6702 - val_acc: 0.6667\n",
      "Epoch 33/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6596 - acc: 0.6719 - val_loss: 0.6690 - val_acc: 0.6667\n",
      "Epoch 34/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6584 - acc: 0.6736 - val_loss: 0.6678 - val_acc: 0.6667\n",
      "Epoch 35/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6572 - acc: 0.6701 - val_loss: 0.6667 - val_acc: 0.6719\n",
      "Epoch 36/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6560 - acc: 0.6719 - val_loss: 0.6655 - val_acc: 0.6667\n",
      "Epoch 37/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6548 - acc: 0.6719 - val_loss: 0.6643 - val_acc: 0.6667\n",
      "Epoch 38/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6537 - acc: 0.6736 - val_loss: 0.6631 - val_acc: 0.6667\n",
      "Epoch 39/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6526 - acc: 0.6736 - val_loss: 0.6620 - val_acc: 0.6667\n",
      "Epoch 40/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6515 - acc: 0.6771 - val_loss: 0.6609 - val_acc: 0.6667\n",
      "Epoch 41/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6504 - acc: 0.6771 - val_loss: 0.6597 - val_acc: 0.6771\n",
      "Epoch 42/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6492 - acc: 0.6788 - val_loss: 0.6586 - val_acc: 0.6771\n",
      "Epoch 43/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6482 - acc: 0.6788 - val_loss: 0.6575 - val_acc: 0.6771\n",
      "Epoch 44/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6471 - acc: 0.6788 - val_loss: 0.6564 - val_acc: 0.6771\n",
      "Epoch 45/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6461 - acc: 0.6788 - val_loss: 0.6553 - val_acc: 0.6771\n",
      "Epoch 46/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6451 - acc: 0.6823 - val_loss: 0.6542 - val_acc: 0.6719\n",
      "Epoch 47/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6440 - acc: 0.6823 - val_loss: 0.6532 - val_acc: 0.6719\n",
      "Epoch 48/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6430 - acc: 0.6788 - val_loss: 0.6521 - val_acc: 0.6719\n",
      "Epoch 49/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6420 - acc: 0.6823 - val_loss: 0.6511 - val_acc: 0.6719\n",
      "Epoch 50/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6410 - acc: 0.6806 - val_loss: 0.6500 - val_acc: 0.6719\n",
      "Epoch 51/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6400 - acc: 0.6788 - val_loss: 0.6490 - val_acc: 0.6771\n",
      "Epoch 52/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6390 - acc: 0.6788 - val_loss: 0.6480 - val_acc: 0.6771\n",
      "Epoch 53/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6381 - acc: 0.6788 - val_loss: 0.6470 - val_acc: 0.6771\n",
      "Epoch 54/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6371 - acc: 0.6788 - val_loss: 0.6460 - val_acc: 0.6771\n",
      "Epoch 55/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6362 - acc: 0.6771 - val_loss: 0.6449 - val_acc: 0.6771\n",
      "Epoch 56/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6352 - acc: 0.6771 - val_loss: 0.6439 - val_acc: 0.6771\n",
      "Epoch 57/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6342 - acc: 0.6788 - val_loss: 0.6429 - val_acc: 0.6771\n",
      "Epoch 58/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6333 - acc: 0.6788 - val_loss: 0.6419 - val_acc: 0.6771\n",
      "Epoch 59/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6323 - acc: 0.6788 - val_loss: 0.6409 - val_acc: 0.6771\n",
      "Epoch 60/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6314 - acc: 0.6788 - val_loss: 0.6399 - val_acc: 0.6771\n",
      "Epoch 61/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6305 - acc: 0.6823 - val_loss: 0.6389 - val_acc: 0.6771\n",
      "Epoch 62/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6296 - acc: 0.6840 - val_loss: 0.6379 - val_acc: 0.6771\n",
      "Epoch 63/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6287 - acc: 0.6840 - val_loss: 0.6369 - val_acc: 0.6771\n",
      "Epoch 64/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6278 - acc: 0.6858 - val_loss: 0.6359 - val_acc: 0.6823\n",
      "Epoch 65/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6269 - acc: 0.6875 - val_loss: 0.6348 - val_acc: 0.6823\n",
      "Epoch 66/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6260 - acc: 0.6910 - val_loss: 0.6338 - val_acc: 0.6823\n",
      "Epoch 67/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6251 - acc: 0.6927 - val_loss: 0.6328 - val_acc: 0.6875\n",
      "Epoch 68/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6242 - acc: 0.6979 - val_loss: 0.6318 - val_acc: 0.6875\n",
      "Epoch 69/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6233 - acc: 0.6979 - val_loss: 0.6308 - val_acc: 0.6927\n",
      "Epoch 70/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6224 - acc: 0.6962 - val_loss: 0.6298 - val_acc: 0.6927\n",
      "Epoch 71/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6215 - acc: 0.7014 - val_loss: 0.6288 - val_acc: 0.6927\n",
      "Epoch 72/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6206 - acc: 0.7014 - val_loss: 0.6279 - val_acc: 0.6927\n",
      "Epoch 73/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6197 - acc: 0.7014 - val_loss: 0.6269 - val_acc: 0.6927\n",
      "Epoch 74/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6189 - acc: 0.7014 - val_loss: 0.6260 - val_acc: 0.6927\n",
      "Epoch 75/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6180 - acc: 0.6997 - val_loss: 0.6250 - val_acc: 0.6979\n",
      "Epoch 76/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6171 - acc: 0.6997 - val_loss: 0.6241 - val_acc: 0.6979\n",
      "Epoch 77/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6163 - acc: 0.7014 - val_loss: 0.6231 - val_acc: 0.7031\n",
      "Epoch 78/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6154 - acc: 0.7014 - val_loss: 0.6222 - val_acc: 0.7031\n",
      "Epoch 79/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6145 - acc: 0.7031 - val_loss: 0.6212 - val_acc: 0.7031\n",
      "Epoch 80/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6137 - acc: 0.7049 - val_loss: 0.6203 - val_acc: 0.7031\n",
      "Epoch 81/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6128 - acc: 0.7066 - val_loss: 0.6194 - val_acc: 0.7031\n",
      "Epoch 82/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6120 - acc: 0.7049 - val_loss: 0.6184 - val_acc: 0.7083\n",
      "Epoch 83/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6111 - acc: 0.7049 - val_loss: 0.6175 - val_acc: 0.7083\n",
      "Epoch 84/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6102 - acc: 0.7049 - val_loss: 0.6165 - val_acc: 0.7083\n",
      "Epoch 85/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6094 - acc: 0.7049 - val_loss: 0.6156 - val_acc: 0.7083\n",
      "Epoch 86/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6085 - acc: 0.7066 - val_loss: 0.6146 - val_acc: 0.7083\n",
      "Epoch 87/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6077 - acc: 0.7066 - val_loss: 0.6137 - val_acc: 0.7083\n",
      "Epoch 88/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6069 - acc: 0.7049 - val_loss: 0.6128 - val_acc: 0.7083\n",
      "Epoch 89/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6060 - acc: 0.7031 - val_loss: 0.6119 - val_acc: 0.7083\n",
      "Epoch 90/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6052 - acc: 0.6997 - val_loss: 0.6109 - val_acc: 0.7083\n",
      "Epoch 91/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6044 - acc: 0.6997 - val_loss: 0.6100 - val_acc: 0.7083\n",
      "Epoch 92/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6035 - acc: 0.6997 - val_loss: 0.6091 - val_acc: 0.7083\n",
      "Epoch 93/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6027 - acc: 0.6997 - val_loss: 0.6082 - val_acc: 0.7083\n",
      "Epoch 94/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6019 - acc: 0.7014 - val_loss: 0.6073 - val_acc: 0.7083\n",
      "Epoch 95/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6010 - acc: 0.7031 - val_loss: 0.6063 - val_acc: 0.7135\n",
      "Epoch 96/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6002 - acc: 0.7049 - val_loss: 0.6054 - val_acc: 0.7135\n",
      "Epoch 97/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5993 - acc: 0.7066 - val_loss: 0.6045 - val_acc: 0.7135\n",
      "Epoch 98/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5985 - acc: 0.7066 - val_loss: 0.6036 - val_acc: 0.7031\n",
      "Epoch 99/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5977 - acc: 0.7049 - val_loss: 0.6027 - val_acc: 0.7031\n",
      "Epoch 100/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5969 - acc: 0.7101 - val_loss: 0.6018 - val_acc: 0.7083\n",
      "Epoch 101/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5961 - acc: 0.7066 - val_loss: 0.6009 - val_acc: 0.7083\n",
      "Epoch 102/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5953 - acc: 0.7083 - val_loss: 0.6000 - val_acc: 0.7083\n",
      "Epoch 103/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5944 - acc: 0.7101 - val_loss: 0.5992 - val_acc: 0.7031\n",
      "Epoch 104/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5936 - acc: 0.7066 - val_loss: 0.5983 - val_acc: 0.6979\n",
      "Epoch 105/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5928 - acc: 0.7101 - val_loss: 0.5975 - val_acc: 0.6979\n",
      "Epoch 106/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5921 - acc: 0.7118 - val_loss: 0.5966 - val_acc: 0.6979\n",
      "Epoch 107/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5913 - acc: 0.7118 - val_loss: 0.5958 - val_acc: 0.6979\n",
      "Epoch 108/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5905 - acc: 0.7118 - val_loss: 0.5950 - val_acc: 0.6979\n",
      "Epoch 109/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5897 - acc: 0.7135 - val_loss: 0.5941 - val_acc: 0.6979\n",
      "Epoch 110/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5889 - acc: 0.7170 - val_loss: 0.5933 - val_acc: 0.6979\n",
      "Epoch 111/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5882 - acc: 0.7188 - val_loss: 0.5925 - val_acc: 0.7031\n",
      "Epoch 112/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5874 - acc: 0.7188 - val_loss: 0.5917 - val_acc: 0.6979\n",
      "Epoch 113/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5866 - acc: 0.7188 - val_loss: 0.5909 - val_acc: 0.7083\n",
      "Epoch 114/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5859 - acc: 0.7188 - val_loss: 0.5901 - val_acc: 0.7083\n",
      "Epoch 115/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.5852 - acc: 0.7222 - val_loss: 0.5893 - val_acc: 0.7083\n",
      "Epoch 116/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5844 - acc: 0.7222 - val_loss: 0.5885 - val_acc: 0.7135\n",
      "Epoch 117/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5837 - acc: 0.7222 - val_loss: 0.5878 - val_acc: 0.7135\n",
      "Epoch 118/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5830 - acc: 0.7205 - val_loss: 0.5870 - val_acc: 0.7135\n",
      "Epoch 119/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5822 - acc: 0.7222 - val_loss: 0.5863 - val_acc: 0.7135\n",
      "Epoch 120/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5815 - acc: 0.7240 - val_loss: 0.5855 - val_acc: 0.7135\n",
      "Epoch 121/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5808 - acc: 0.7257 - val_loss: 0.5848 - val_acc: 0.7135\n",
      "Epoch 122/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5800 - acc: 0.7292 - val_loss: 0.5840 - val_acc: 0.7135\n",
      "Epoch 123/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5794 - acc: 0.7309 - val_loss: 0.5833 - val_acc: 0.7083\n",
      "Epoch 124/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5786 - acc: 0.7309 - val_loss: 0.5825 - val_acc: 0.7083\n",
      "Epoch 125/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5779 - acc: 0.7309 - val_loss: 0.5818 - val_acc: 0.7135\n",
      "Epoch 126/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5772 - acc: 0.7309 - val_loss: 0.5811 - val_acc: 0.7135\n",
      "Epoch 127/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5765 - acc: 0.7309 - val_loss: 0.5803 - val_acc: 0.7135\n",
      "Epoch 128/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5758 - acc: 0.7326 - val_loss: 0.5796 - val_acc: 0.7135\n",
      "Epoch 129/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5751 - acc: 0.7326 - val_loss: 0.5789 - val_acc: 0.7135\n",
      "Epoch 130/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5744 - acc: 0.7344 - val_loss: 0.5782 - val_acc: 0.7135\n",
      "Epoch 131/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5737 - acc: 0.7344 - val_loss: 0.5775 - val_acc: 0.7135\n",
      "Epoch 132/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5730 - acc: 0.7361 - val_loss: 0.5768 - val_acc: 0.7135\n",
      "Epoch 133/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5723 - acc: 0.7378 - val_loss: 0.5761 - val_acc: 0.7031\n",
      "Epoch 134/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5717 - acc: 0.7378 - val_loss: 0.5754 - val_acc: 0.7031\n",
      "Epoch 135/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5710 - acc: 0.7378 - val_loss: 0.5748 - val_acc: 0.7083\n",
      "Epoch 136/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5703 - acc: 0.7396 - val_loss: 0.5741 - val_acc: 0.7083\n",
      "Epoch 137/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5696 - acc: 0.7378 - val_loss: 0.5734 - val_acc: 0.7083\n",
      "Epoch 138/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5689 - acc: 0.7396 - val_loss: 0.5727 - val_acc: 0.7135\n",
      "Epoch 139/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5683 - acc: 0.7378 - val_loss: 0.5721 - val_acc: 0.7135\n",
      "Epoch 140/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5676 - acc: 0.7378 - val_loss: 0.5714 - val_acc: 0.7135\n",
      "Epoch 141/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5669 - acc: 0.7378 - val_loss: 0.5707 - val_acc: 0.7135\n",
      "Epoch 142/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5662 - acc: 0.7396 - val_loss: 0.5701 - val_acc: 0.7135\n",
      "Epoch 143/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5656 - acc: 0.7396 - val_loss: 0.5694 - val_acc: 0.7135\n",
      "Epoch 144/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5649 - acc: 0.7378 - val_loss: 0.5688 - val_acc: 0.7188\n",
      "Epoch 145/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5642 - acc: 0.7378 - val_loss: 0.5681 - val_acc: 0.7188\n",
      "Epoch 146/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5635 - acc: 0.7378 - val_loss: 0.5674 - val_acc: 0.7240\n",
      "Epoch 147/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5629 - acc: 0.7396 - val_loss: 0.5668 - val_acc: 0.7240\n",
      "Epoch 148/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5622 - acc: 0.7413 - val_loss: 0.5661 - val_acc: 0.7240\n",
      "Epoch 149/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5615 - acc: 0.7413 - val_loss: 0.5655 - val_acc: 0.7292\n",
      "Epoch 150/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5608 - acc: 0.7396 - val_loss: 0.5649 - val_acc: 0.7292\n",
      "Epoch 151/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5601 - acc: 0.7413 - val_loss: 0.5642 - val_acc: 0.7292\n",
      "Epoch 152/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5595 - acc: 0.7413 - val_loss: 0.5636 - val_acc: 0.7292\n",
      "Epoch 153/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5588 - acc: 0.7413 - val_loss: 0.5630 - val_acc: 0.7292\n",
      "Epoch 154/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5581 - acc: 0.7413 - val_loss: 0.5623 - val_acc: 0.7344\n",
      "Epoch 155/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5575 - acc: 0.7413 - val_loss: 0.5617 - val_acc: 0.7344\n",
      "Epoch 156/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5568 - acc: 0.7431 - val_loss: 0.5611 - val_acc: 0.7344\n",
      "Epoch 157/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5562 - acc: 0.7413 - val_loss: 0.5605 - val_acc: 0.7344\n",
      "Epoch 158/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5555 - acc: 0.7413 - val_loss: 0.5599 - val_acc: 0.7344\n",
      "Epoch 159/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5549 - acc: 0.7396 - val_loss: 0.5593 - val_acc: 0.7344\n",
      "Epoch 160/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5542 - acc: 0.7413 - val_loss: 0.5587 - val_acc: 0.7344\n",
      "Epoch 161/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5537 - acc: 0.7413 - val_loss: 0.5581 - val_acc: 0.7344\n",
      "Epoch 162/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5529 - acc: 0.7413 - val_loss: 0.5575 - val_acc: 0.7344\n",
      "Epoch 163/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5524 - acc: 0.7448 - val_loss: 0.5569 - val_acc: 0.7344\n",
      "Epoch 164/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5517 - acc: 0.7448 - val_loss: 0.5563 - val_acc: 0.7396\n",
      "Epoch 165/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5511 - acc: 0.7465 - val_loss: 0.5558 - val_acc: 0.7396\n",
      "Epoch 166/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5506 - acc: 0.7465 - val_loss: 0.5552 - val_acc: 0.7396\n",
      "Epoch 167/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5499 - acc: 0.7483 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 168/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5493 - acc: 0.7465 - val_loss: 0.5541 - val_acc: 0.7396\n",
      "Epoch 169/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5487 - acc: 0.7483 - val_loss: 0.5535 - val_acc: 0.7396\n",
      "Epoch 170/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5481 - acc: 0.7483 - val_loss: 0.5530 - val_acc: 0.7396\n",
      "Epoch 171/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5475 - acc: 0.7483 - val_loss: 0.5524 - val_acc: 0.7448\n",
      "Epoch 172/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5468 - acc: 0.7500 - val_loss: 0.5519 - val_acc: 0.7448\n",
      "Epoch 173/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5462 - acc: 0.7500 - val_loss: 0.5513 - val_acc: 0.7448\n",
      "Epoch 174/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5456 - acc: 0.7500 - val_loss: 0.5508 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5450 - acc: 0.7535 - val_loss: 0.5502 - val_acc: 0.7448\n",
      "Epoch 176/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5444 - acc: 0.7535 - val_loss: 0.5497 - val_acc: 0.7448\n",
      "Epoch 177/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5438 - acc: 0.7517 - val_loss: 0.5492 - val_acc: 0.7448\n",
      "Epoch 178/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5432 - acc: 0.7535 - val_loss: 0.5487 - val_acc: 0.7448\n",
      "Epoch 179/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5426 - acc: 0.7535 - val_loss: 0.5482 - val_acc: 0.7448\n",
      "Epoch 180/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5420 - acc: 0.7535 - val_loss: 0.5476 - val_acc: 0.7500\n",
      "Epoch 181/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5414 - acc: 0.7552 - val_loss: 0.5471 - val_acc: 0.7500\n",
      "Epoch 182/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5408 - acc: 0.7552 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 183/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5402 - acc: 0.7552 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 184/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5396 - acc: 0.7552 - val_loss: 0.5456 - val_acc: 0.7552\n",
      "Epoch 185/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5390 - acc: 0.7552 - val_loss: 0.5451 - val_acc: 0.7552\n",
      "Epoch 186/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5383 - acc: 0.7552 - val_loss: 0.5446 - val_acc: 0.7552\n",
      "Epoch 187/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5378 - acc: 0.7552 - val_loss: 0.5441 - val_acc: 0.7500\n",
      "Epoch 188/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5371 - acc: 0.7552 - val_loss: 0.5436 - val_acc: 0.7500\n",
      "Epoch 189/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5365 - acc: 0.7569 - val_loss: 0.5431 - val_acc: 0.7552\n",
      "Epoch 190/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5359 - acc: 0.7569 - val_loss: 0.5427 - val_acc: 0.7552\n",
      "Epoch 191/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5353 - acc: 0.7587 - val_loss: 0.5422 - val_acc: 0.7552\n",
      "Epoch 192/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5348 - acc: 0.7587 - val_loss: 0.5417 - val_acc: 0.7552\n",
      "Epoch 193/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5342 - acc: 0.7587 - val_loss: 0.5412 - val_acc: 0.7552\n",
      "Epoch 194/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5336 - acc: 0.7569 - val_loss: 0.5408 - val_acc: 0.7604\n",
      "Epoch 195/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5330 - acc: 0.7569 - val_loss: 0.5403 - val_acc: 0.7604\n",
      "Epoch 196/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5325 - acc: 0.7587 - val_loss: 0.5398 - val_acc: 0.7604\n",
      "Epoch 197/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5319 - acc: 0.7604 - val_loss: 0.5394 - val_acc: 0.7604\n",
      "Epoch 198/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5313 - acc: 0.7604 - val_loss: 0.5389 - val_acc: 0.7604\n",
      "Epoch 199/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5308 - acc: 0.7622 - val_loss: 0.5384 - val_acc: 0.7604\n",
      "Epoch 200/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5302 - acc: 0.7639 - val_loss: 0.5380 - val_acc: 0.7604\n",
      "Epoch 201/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5296 - acc: 0.7639 - val_loss: 0.5375 - val_acc: 0.7604\n",
      "Epoch 202/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5291 - acc: 0.7656 - val_loss: 0.5371 - val_acc: 0.7604\n",
      "Epoch 203/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5285 - acc: 0.7656 - val_loss: 0.5366 - val_acc: 0.7604\n",
      "Epoch 204/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5280 - acc: 0.7656 - val_loss: 0.5362 - val_acc: 0.7604\n",
      "Epoch 205/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5274 - acc: 0.7656 - val_loss: 0.5357 - val_acc: 0.7604\n",
      "Epoch 206/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5269 - acc: 0.7674 - val_loss: 0.5353 - val_acc: 0.7552\n",
      "Epoch 207/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5263 - acc: 0.7639 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 208/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5258 - acc: 0.7639 - val_loss: 0.5344 - val_acc: 0.7500\n",
      "Epoch 209/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5252 - acc: 0.7639 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 210/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5247 - acc: 0.7639 - val_loss: 0.5336 - val_acc: 0.7500\n",
      "Epoch 211/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5242 - acc: 0.7656 - val_loss: 0.5332 - val_acc: 0.7500\n",
      "Epoch 212/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5237 - acc: 0.7656 - val_loss: 0.5328 - val_acc: 0.7500\n",
      "Epoch 213/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5232 - acc: 0.7656 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 214/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5226 - acc: 0.7674 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 215/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5221 - acc: 0.7674 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 216/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5216 - acc: 0.7674 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 217/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5211 - acc: 0.7674 - val_loss: 0.5308 - val_acc: 0.7500\n",
      "Epoch 218/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5206 - acc: 0.7674 - val_loss: 0.5304 - val_acc: 0.7500\n",
      "Epoch 219/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5201 - acc: 0.7674 - val_loss: 0.5301 - val_acc: 0.7500\n",
      "Epoch 220/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5197 - acc: 0.7674 - val_loss: 0.5297 - val_acc: 0.7500\n",
      "Epoch 221/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5192 - acc: 0.7674 - val_loss: 0.5293 - val_acc: 0.7500\n",
      "Epoch 222/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5187 - acc: 0.7656 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 223/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5182 - acc: 0.7674 - val_loss: 0.5286 - val_acc: 0.7500\n",
      "Epoch 224/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5177 - acc: 0.7656 - val_loss: 0.5282 - val_acc: 0.7500\n",
      "Epoch 225/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5172 - acc: 0.7656 - val_loss: 0.5279 - val_acc: 0.7500\n",
      "Epoch 226/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5167 - acc: 0.7656 - val_loss: 0.5275 - val_acc: 0.7500\n",
      "Epoch 227/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5162 - acc: 0.7656 - val_loss: 0.5272 - val_acc: 0.7500\n",
      "Epoch 228/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5157 - acc: 0.7656 - val_loss: 0.5268 - val_acc: 0.7500\n",
      "Epoch 229/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5153 - acc: 0.7656 - val_loss: 0.5265 - val_acc: 0.7552\n",
      "Epoch 230/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5148 - acc: 0.7639 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 231/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5143 - acc: 0.7639 - val_loss: 0.5258 - val_acc: 0.7552\n",
      "Epoch 232/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5139 - acc: 0.7656 - val_loss: 0.5255 - val_acc: 0.7552\n",
      "Epoch 233/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5134 - acc: 0.7656 - val_loss: 0.5252 - val_acc: 0.7552\n",
      "Epoch 234/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5130 - acc: 0.7639 - val_loss: 0.5249 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5125 - acc: 0.7639 - val_loss: 0.5245 - val_acc: 0.7552\n",
      "Epoch 236/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5120 - acc: 0.7639 - val_loss: 0.5242 - val_acc: 0.7552\n",
      "Epoch 237/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5116 - acc: 0.7622 - val_loss: 0.5239 - val_acc: 0.7552\n",
      "Epoch 238/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5111 - acc: 0.7622 - val_loss: 0.5236 - val_acc: 0.7552\n",
      "Epoch 239/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5106 - acc: 0.7639 - val_loss: 0.5233 - val_acc: 0.7552\n",
      "Epoch 240/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5102 - acc: 0.7622 - val_loss: 0.5229 - val_acc: 0.7552\n",
      "Epoch 241/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5098 - acc: 0.7622 - val_loss: 0.5226 - val_acc: 0.7552\n",
      "Epoch 242/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5093 - acc: 0.7622 - val_loss: 0.5224 - val_acc: 0.7552\n",
      "Epoch 243/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5089 - acc: 0.7622 - val_loss: 0.5221 - val_acc: 0.7552\n",
      "Epoch 244/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5085 - acc: 0.7622 - val_loss: 0.5218 - val_acc: 0.7604\n",
      "Epoch 245/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5080 - acc: 0.7622 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 246/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5076 - acc: 0.7622 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 247/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5072 - acc: 0.7622 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 248/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5068 - acc: 0.7622 - val_loss: 0.5207 - val_acc: 0.7552\n",
      "Epoch 249/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5063 - acc: 0.7622 - val_loss: 0.5204 - val_acc: 0.7552\n",
      "Epoch 250/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5059 - acc: 0.7622 - val_loss: 0.5201 - val_acc: 0.7552\n",
      "Epoch 251/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5056 - acc: 0.7639 - val_loss: 0.5199 - val_acc: 0.7552\n",
      "Epoch 252/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5051 - acc: 0.7639 - val_loss: 0.5196 - val_acc: 0.7552\n",
      "Epoch 253/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5047 - acc: 0.7639 - val_loss: 0.5193 - val_acc: 0.7552\n",
      "Epoch 254/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5043 - acc: 0.7639 - val_loss: 0.5191 - val_acc: 0.7552\n",
      "Epoch 255/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5039 - acc: 0.7639 - val_loss: 0.5188 - val_acc: 0.7552\n",
      "Epoch 256/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5035 - acc: 0.7639 - val_loss: 0.5186 - val_acc: 0.7604\n",
      "Epoch 257/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5031 - acc: 0.7639 - val_loss: 0.5183 - val_acc: 0.7604\n",
      "Epoch 258/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5027 - acc: 0.7622 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 259/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5023 - acc: 0.7656 - val_loss: 0.5178 - val_acc: 0.7604\n",
      "Epoch 260/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5020 - acc: 0.7656 - val_loss: 0.5176 - val_acc: 0.7604\n",
      "Epoch 261/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5016 - acc: 0.7639 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 262/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5012 - acc: 0.7622 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 263/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5008 - acc: 0.7639 - val_loss: 0.5168 - val_acc: 0.7604\n",
      "Epoch 264/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5005 - acc: 0.7656 - val_loss: 0.5166 - val_acc: 0.7604\n",
      "Epoch 265/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5000 - acc: 0.7622 - val_loss: 0.5163 - val_acc: 0.7604\n",
      "Epoch 266/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4997 - acc: 0.7639 - val_loss: 0.5161 - val_acc: 0.7604\n",
      "Epoch 267/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4993 - acc: 0.7639 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 268/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4989 - acc: 0.7656 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 269/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4986 - acc: 0.7656 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 270/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4982 - acc: 0.7656 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 271/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4978 - acc: 0.7656 - val_loss: 0.5149 - val_acc: 0.7604\n",
      "Epoch 272/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4974 - acc: 0.7639 - val_loss: 0.5147 - val_acc: 0.7604\n",
      "Epoch 273/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4971 - acc: 0.7639 - val_loss: 0.5144 - val_acc: 0.7604\n",
      "Epoch 274/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4967 - acc: 0.7639 - val_loss: 0.5142 - val_acc: 0.7604\n",
      "Epoch 275/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4964 - acc: 0.7639 - val_loss: 0.5140 - val_acc: 0.7604\n",
      "Epoch 276/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4960 - acc: 0.7639 - val_loss: 0.5138 - val_acc: 0.7604\n",
      "Epoch 277/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4957 - acc: 0.7639 - val_loss: 0.5135 - val_acc: 0.7604\n",
      "Epoch 278/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4953 - acc: 0.7639 - val_loss: 0.5133 - val_acc: 0.7604\n",
      "Epoch 279/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4949 - acc: 0.7639 - val_loss: 0.5131 - val_acc: 0.7604\n",
      "Epoch 280/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4946 - acc: 0.7639 - val_loss: 0.5129 - val_acc: 0.7604\n",
      "Epoch 281/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4943 - acc: 0.7639 - val_loss: 0.5127 - val_acc: 0.7604\n",
      "Epoch 282/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4939 - acc: 0.7639 - val_loss: 0.5125 - val_acc: 0.7604\n",
      "Epoch 283/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4936 - acc: 0.7639 - val_loss: 0.5123 - val_acc: 0.7604\n",
      "Epoch 284/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4932 - acc: 0.7639 - val_loss: 0.5121 - val_acc: 0.7604\n",
      "Epoch 285/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4929 - acc: 0.7639 - val_loss: 0.5119 - val_acc: 0.7604\n",
      "Epoch 286/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4926 - acc: 0.7639 - val_loss: 0.5117 - val_acc: 0.7604\n",
      "Epoch 287/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4922 - acc: 0.7639 - val_loss: 0.5115 - val_acc: 0.7604\n",
      "Epoch 288/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4919 - acc: 0.7639 - val_loss: 0.5113 - val_acc: 0.7604\n",
      "Epoch 289/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4916 - acc: 0.7639 - val_loss: 0.5111 - val_acc: 0.7604\n",
      "Epoch 290/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4912 - acc: 0.7639 - val_loss: 0.5109 - val_acc: 0.7604\n",
      "Epoch 291/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4909 - acc: 0.7639 - val_loss: 0.5107 - val_acc: 0.7604\n",
      "Epoch 292/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4907 - acc: 0.7604 - val_loss: 0.5106 - val_acc: 0.7604\n",
      "Epoch 293/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4904 - acc: 0.7604 - val_loss: 0.5104 - val_acc: 0.7604\n",
      "Epoch 294/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4900 - acc: 0.7604 - val_loss: 0.5102 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4898 - acc: 0.7604 - val_loss: 0.5101 - val_acc: 0.7604\n",
      "Epoch 296/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4895 - acc: 0.7604 - val_loss: 0.5099 - val_acc: 0.7604\n",
      "Epoch 297/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4892 - acc: 0.7604 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 298/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4889 - acc: 0.7604 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 299/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4886 - acc: 0.7604 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 300/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4883 - acc: 0.7604 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 301/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4880 - acc: 0.7604 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 302/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4877 - acc: 0.7604 - val_loss: 0.5090 - val_acc: 0.7604\n",
      "Epoch 303/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4874 - acc: 0.7604 - val_loss: 0.5088 - val_acc: 0.7604\n",
      "Epoch 304/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4871 - acc: 0.7604 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 305/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4868 - acc: 0.7604 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 306/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4865 - acc: 0.7604 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 307/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4863 - acc: 0.7604 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 308/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4860 - acc: 0.7604 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 309/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4857 - acc: 0.7604 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 310/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4854 - acc: 0.7604 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 311/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4851 - acc: 0.7604 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 312/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4773 - acc: 0.718 - 0s 48us/step - loss: 0.4849 - acc: 0.7604 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 313/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4846 - acc: 0.7604 - val_loss: 0.5074 - val_acc: 0.7604\n",
      "Epoch 314/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4843 - acc: 0.7604 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 315/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4840 - acc: 0.7604 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 316/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4839 - acc: 0.7622 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 317/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4836 - acc: 0.7622 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 318/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4833 - acc: 0.7639 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 319/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4831 - acc: 0.7639 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 320/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4828 - acc: 0.7639 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 321/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4826 - acc: 0.7639 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 322/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4823 - acc: 0.7639 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 323/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4821 - acc: 0.7639 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 324/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4818 - acc: 0.7639 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 325/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4816 - acc: 0.7639 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 326/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4813 - acc: 0.7639 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 327/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4811 - acc: 0.7639 - val_loss: 0.5057 - val_acc: 0.7604\n",
      "Epoch 328/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4809 - acc: 0.7639 - val_loss: 0.5056 - val_acc: 0.7604\n",
      "Epoch 329/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4806 - acc: 0.7639 - val_loss: 0.5055 - val_acc: 0.7604\n",
      "Epoch 330/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4804 - acc: 0.7639 - val_loss: 0.5054 - val_acc: 0.7604\n",
      "Epoch 331/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4802 - acc: 0.7639 - val_loss: 0.5053 - val_acc: 0.7604\n",
      "Epoch 332/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4799 - acc: 0.7674 - val_loss: 0.5052 - val_acc: 0.7604\n",
      "Epoch 333/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4798 - acc: 0.7639 - val_loss: 0.5051 - val_acc: 0.7604\n",
      "Epoch 334/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4795 - acc: 0.7639 - val_loss: 0.5051 - val_acc: 0.7604\n",
      "Epoch 335/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4793 - acc: 0.7656 - val_loss: 0.5050 - val_acc: 0.7604\n",
      "Epoch 336/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4791 - acc: 0.7691 - val_loss: 0.5049 - val_acc: 0.7604\n",
      "Epoch 337/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4789 - acc: 0.7674 - val_loss: 0.5048 - val_acc: 0.7604\n",
      "Epoch 338/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4786 - acc: 0.7674 - val_loss: 0.5047 - val_acc: 0.7604\n",
      "Epoch 339/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4784 - acc: 0.7674 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 340/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4782 - acc: 0.7691 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 341/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4780 - acc: 0.7708 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 342/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4778 - acc: 0.7691 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 343/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4776 - acc: 0.7691 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 344/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4774 - acc: 0.7708 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 345/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4772 - acc: 0.7726 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 346/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4770 - acc: 0.7726 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 347/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4768 - acc: 0.7708 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 348/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4766 - acc: 0.7708 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 349/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4764 - acc: 0.7726 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 350/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4762 - acc: 0.7726 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 351/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4372 - acc: 0.718 - 0s 42us/step - loss: 0.4761 - acc: 0.7708 - val_loss: 0.5038 - val_acc: 0.7604\n",
      "Epoch 352/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4759 - acc: 0.7726 - val_loss: 0.5038 - val_acc: 0.7604\n",
      "Epoch 353/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4757 - acc: 0.7708 - val_loss: 0.5037 - val_acc: 0.7604\n",
      "Epoch 354/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4755 - acc: 0.7708 - val_loss: 0.5037 - val_acc: 0.7604\n",
      "Epoch 355/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4753 - acc: 0.7726 - val_loss: 0.5036 - val_acc: 0.7604\n",
      "Epoch 356/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4751 - acc: 0.7708 - val_loss: 0.5036 - val_acc: 0.7604\n",
      "Epoch 357/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4749 - acc: 0.7708 - val_loss: 0.5035 - val_acc: 0.7604\n",
      "Epoch 358/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4747 - acc: 0.7708 - val_loss: 0.5035 - val_acc: 0.7604\n",
      "Epoch 359/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4745 - acc: 0.7691 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 360/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4743 - acc: 0.7708 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 361/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4742 - acc: 0.7691 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 362/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4740 - acc: 0.7691 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 363/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4738 - acc: 0.7691 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 364/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4736 - acc: 0.7691 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 365/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4735 - acc: 0.7708 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 366/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4733 - acc: 0.7708 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 367/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4731 - acc: 0.7691 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 368/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4730 - acc: 0.7708 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 369/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4728 - acc: 0.7708 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 370/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4726 - acc: 0.7708 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 371/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4724 - acc: 0.7708 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 372/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4723 - acc: 0.7708 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 373/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4721 - acc: 0.7708 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 374/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4720 - acc: 0.7708 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 375/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4718 - acc: 0.7708 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 376/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4716 - acc: 0.7708 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 377/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4714 - acc: 0.7708 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 378/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4713 - acc: 0.7726 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 379/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4712 - acc: 0.7708 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 380/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4710 - acc: 0.7708 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 381/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4708 - acc: 0.7708 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 382/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4707 - acc: 0.7708 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 383/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4705 - acc: 0.7708 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 384/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4704 - acc: 0.7726 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 385/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4701 - acc: 0.7726 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 386/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4700 - acc: 0.7726 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 387/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4698 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 388/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4697 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 389/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4696 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7604\n",
      "Epoch 390/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4694 - acc: 0.7726 - val_loss: 0.5026 - val_acc: 0.7604\n",
      "Epoch 391/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4692 - acc: 0.7726 - val_loss: 0.5025 - val_acc: 0.7604\n",
      "Epoch 392/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4691 - acc: 0.7726 - val_loss: 0.5025 - val_acc: 0.7604\n",
      "Epoch 393/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4689 - acc: 0.7726 - val_loss: 0.5025 - val_acc: 0.7604\n",
      "Epoch 394/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4687 - acc: 0.7726 - val_loss: 0.5025 - val_acc: 0.7604\n",
      "Epoch 395/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4686 - acc: 0.7743 - val_loss: 0.5024 - val_acc: 0.7604\n",
      "Epoch 396/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4684 - acc: 0.7760 - val_loss: 0.5024 - val_acc: 0.7604\n",
      "Epoch 397/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4682 - acc: 0.7760 - val_loss: 0.5024 - val_acc: 0.7604\n",
      "Epoch 398/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4681 - acc: 0.7760 - val_loss: 0.5024 - val_acc: 0.7604\n",
      "Epoch 399/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4680 - acc: 0.7760 - val_loss: 0.5023 - val_acc: 0.7604\n",
      "Epoch 400/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4678 - acc: 0.7760 - val_loss: 0.5023 - val_acc: 0.7604\n",
      "Epoch 401/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4677 - acc: 0.7760 - val_loss: 0.5023 - val_acc: 0.7604\n",
      "Epoch 402/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4675 - acc: 0.7760 - val_loss: 0.5023 - val_acc: 0.7604\n",
      "Epoch 403/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4674 - acc: 0.7778 - val_loss: 0.5023 - val_acc: 0.7604\n",
      "Epoch 404/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4672 - acc: 0.7743 - val_loss: 0.5022 - val_acc: 0.7604\n",
      "Epoch 405/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4671 - acc: 0.7760 - val_loss: 0.5022 - val_acc: 0.7604\n",
      "Epoch 406/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4670 - acc: 0.7743 - val_loss: 0.5022 - val_acc: 0.7604\n",
      "Epoch 407/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4668 - acc: 0.7743 - val_loss: 0.5022 - val_acc: 0.7604\n",
      "Epoch 408/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 409/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 410/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4664 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 411/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4662 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 412/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 413/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4660 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4659 - acc: 0.7743 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 415/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4657 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 416/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4656 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 417/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4655 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 418/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4653 - acc: 0.7760 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 419/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4652 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 420/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4650 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 421/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4649 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 422/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4648 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 423/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4647 - acc: 0.7760 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 424/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4645 - acc: 0.7743 - val_loss: 0.5020 - val_acc: 0.7604\n",
      "Epoch 425/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4644 - acc: 0.7743 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 426/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4643 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 427/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4641 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 428/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4640 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 429/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4639 - acc: 0.7778 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 430/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4638 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 431/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4637 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 432/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4635 - acc: 0.7778 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 433/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4634 - acc: 0.7760 - val_loss: 0.5019 - val_acc: 0.7604\n",
      "Epoch 434/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4632 - acc: 0.7778 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 435/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4632 - acc: 0.7778 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 436/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4630 - acc: 0.7778 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 437/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4630 - acc: 0.7778 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 438/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4628 - acc: 0.7795 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 439/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4627 - acc: 0.7760 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 440/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4626 - acc: 0.7778 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 441/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4625 - acc: 0.7760 - val_loss: 0.5018 - val_acc: 0.7604\n",
      "Epoch 442/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4623 - acc: 0.7760 - val_loss: 0.5017 - val_acc: 0.7604\n",
      "Epoch 443/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4622 - acc: 0.7778 - val_loss: 0.5017 - val_acc: 0.7604\n",
      "Epoch 444/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4620 - acc: 0.7778 - val_loss: 0.5017 - val_acc: 0.7656\n",
      "Epoch 445/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4619 - acc: 0.7778 - val_loss: 0.5017 - val_acc: 0.7656\n",
      "Epoch 446/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4618 - acc: 0.7760 - val_loss: 0.5017 - val_acc: 0.7604\n",
      "Epoch 447/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4617 - acc: 0.7760 - val_loss: 0.5017 - val_acc: 0.7604\n",
      "Epoch 448/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4616 - acc: 0.7778 - val_loss: 0.5016 - val_acc: 0.7604\n",
      "Epoch 449/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4615 - acc: 0.7778 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 450/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4614 - acc: 0.7795 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 451/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4612 - acc: 0.7795 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 452/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4611 - acc: 0.7812 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 453/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4610 - acc: 0.7795 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 454/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4609 - acc: 0.7812 - val_loss: 0.5015 - val_acc: 0.7656\n",
      "Epoch 455/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4607 - acc: 0.7830 - val_loss: 0.5015 - val_acc: 0.7656\n",
      "Epoch 456/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4606 - acc: 0.7795 - val_loss: 0.5015 - val_acc: 0.7656\n",
      "Epoch 457/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4605 - acc: 0.7795 - val_loss: 0.5015 - val_acc: 0.7604\n",
      "Epoch 458/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4604 - acc: 0.7830 - val_loss: 0.5015 - val_acc: 0.7604\n",
      "Epoch 459/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4603 - acc: 0.7830 - val_loss: 0.5015 - val_acc: 0.7604\n",
      "Epoch 460/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4601 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 461/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4601 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 462/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4599 - acc: 0.7847 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 463/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4598 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 464/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4597 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 465/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4596 - acc: 0.7812 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 466/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4595 - acc: 0.7865 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 467/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4594 - acc: 0.7830 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 468/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4593 - acc: 0.7847 - val_loss: 0.5014 - val_acc: 0.7604\n",
      "Epoch 469/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4591 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 470/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4591 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 471/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4589 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 472/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 473/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4587 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4586 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 475/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4585 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 476/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4585 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 477/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4583 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 478/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4582 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 479/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4581 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 480/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4580 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 481/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4579 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 482/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4578 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 483/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4578 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 484/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4576 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 485/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4575 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 486/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4574 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 487/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4573 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 488/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4573 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 489/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4572 - acc: 0.7847 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 490/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4570 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 491/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4569 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 492/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4569 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 493/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4568 - acc: 0.7865 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 494/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4567 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 495/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 496/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 497/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 498/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4563 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 499/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4563 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 500/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4561 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 501/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4560 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 502/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4559 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 503/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4558 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 504/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4558 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 505/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4557 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 506/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4556 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 507/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4555 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 508/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4554 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 509/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4553 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 510/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4552 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 511/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4551 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 512/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4550 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 513/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4550 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 514/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4550 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 515/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4548 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 516/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4547 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 517/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4547 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 518/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4545 - acc: 0.7882 - val_loss: 0.5010 - val_acc: 0.7552\n",
      "Epoch 519/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4545 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 520/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4544 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 521/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4543 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 522/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4542 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 523/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4541 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 524/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4541 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 525/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4540 - acc: 0.7865 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 526/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4539 - acc: 0.7865 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 527/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4539 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 528/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4537 - acc: 0.7899 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 529/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4536 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 530/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4536 - acc: 0.7865 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 531/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4535 - acc: 0.7899 - val_loss: 0.5009 - val_acc: 0.7552\n",
      "Epoch 532/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4534 - acc: 0.7899 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 533/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4534 - acc: 0.7882 - val_loss: 0.5009 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4533 - acc: 0.7899 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 535/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4532 - acc: 0.7899 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 536/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4531 - acc: 0.7917 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 537/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4530 - acc: 0.7899 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 538/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4530 - acc: 0.7899 - val_loss: 0.5008 - val_acc: 0.7552\n",
      "Epoch 539/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4530 - acc: 0.7882 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 540/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4529 - acc: 0.7882 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 541/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4528 - acc: 0.7882 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 542/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4527 - acc: 0.7917 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 543/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4526 - acc: 0.7917 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 544/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4526 - acc: 0.7934 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 545/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4525 - acc: 0.7899 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 546/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4524 - acc: 0.7882 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 547/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4524 - acc: 0.7882 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 548/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4523 - acc: 0.7899 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 549/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4522 - acc: 0.7882 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 550/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4521 - acc: 0.7917 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 551/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4521 - acc: 0.7882 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 552/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4520 - acc: 0.7917 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 553/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4520 - acc: 0.7882 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 554/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4519 - acc: 0.7899 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 555/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4518 - acc: 0.7882 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 556/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4517 - acc: 0.7865 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 557/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4516 - acc: 0.7865 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 558/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4516 - acc: 0.7865 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 559/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4516 - acc: 0.7882 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 560/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4515 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 561/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4515 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 562/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4513 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 563/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4513 - acc: 0.7865 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 564/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4513 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 565/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4512 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 566/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4511 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 567/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4510 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 568/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4510 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 569/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4509 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 570/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4508 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 571/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4508 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 572/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4507 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 573/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4507 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 574/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4506 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 575/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4505 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 576/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4504 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 577/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4504 - acc: 0.7830 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 578/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4503 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 579/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4503 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 580/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4502 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 581/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4502 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 582/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4501 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 583/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4500 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 584/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4500 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 585/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4499 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 586/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4498 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 587/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4498 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 588/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4497 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 589/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4497 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 590/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4496 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 591/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4496 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 592/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4495 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 593/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4494 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4494 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 595/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4493 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 596/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4493 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 597/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4492 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 598/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4492 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 599/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4491 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 600/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4491 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 601/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4490 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 602/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4490 - acc: 0.7830 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 603/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4489 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 604/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4489 - acc: 0.7847 - val_loss: 0.5006 - val_acc: 0.7500\n",
      "Epoch 605/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4488 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 606/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4488 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 607/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4487 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 608/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4486 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 609/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4486 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 610/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4486 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 611/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4485 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 612/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4485 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 613/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4485 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 614/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4484 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 615/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4483 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 616/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4483 - acc: 0.7847 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 617/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4481 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 618/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4482 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 619/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4481 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 620/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4480 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 621/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4480 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 622/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4480 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 623/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - acc: 0.7847 - val_loss: 0.5008 - val_acc: 0.7500\n",
      "Epoch 624/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4478 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 625/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4478 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 626/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 627/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 628/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 629/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4476 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 630/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4475 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 631/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4475 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 632/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4474 - acc: 0.7847 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 633/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4474 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 634/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4474 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 635/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4474 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 636/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4473 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 637/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4472 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 638/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4471 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 639/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4471 - acc: 0.7865 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 640/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4470 - acc: 0.7865 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 641/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4470 - acc: 0.7847 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 642/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4470 - acc: 0.7847 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 643/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4470 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 644/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4469 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 645/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4469 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 646/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4469 - acc: 0.7847 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 647/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4467 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 648/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4468 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 649/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4467 - acc: 0.7882 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 650/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4467 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 651/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4466 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 652/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4466 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 653/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4466 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 654/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4464 - acc: 0.7865 - val_loss: 0.5011 - val_acc: 0.7500\n",
      "Epoch 655/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4465 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 656/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4463 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 657/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4463 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 658/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4462 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 659/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4462 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 660/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4462 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 661/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4462 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 662/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4461 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 663/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4460 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 664/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4460 - acc: 0.7865 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 665/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4460 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 666/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4460 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 667/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4459 - acc: 0.7882 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 668/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4459 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 669/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4458 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 670/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4458 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 671/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4457 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 672/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4457 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 673/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4457 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 674/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4456 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 675/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4456 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 676/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4456 - acc: 0.7899 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 677/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4455 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 678/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4454 - acc: 0.7882 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 679/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4455 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 680/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4454 - acc: 0.7899 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 681/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4454 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 682/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4454 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 683/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4453 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 684/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4453 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 685/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4452 - acc: 0.7882 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 686/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 687/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4451 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 688/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4451 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 689/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4451 - acc: 0.7899 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 690/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4451 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 691/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4450 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 692/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4449 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 693/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4449 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 694/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4449 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 695/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4448 - acc: 0.7899 - val_loss: 0.5015 - val_acc: 0.7500\n",
      "Epoch 696/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4448 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 697/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4448 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 698/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4447 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 699/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4447 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 700/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 701/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4446 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 702/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4446 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 703/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4446 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 704/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4445 - acc: 0.7899 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 705/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4445 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 706/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4444 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 707/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 708/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4444 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 709/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4444 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 710/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4443 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 711/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4442 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 712/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4443 - acc: 0.7899 - val_loss: 0.5017 - val_acc: 0.7500\n",
      "Epoch 713/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4442 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4443 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 715/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4442 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 716/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4441 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 717/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4441 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 718/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4440 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 719/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4440 - acc: 0.7899 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 720/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4439 - acc: 0.7899 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 721/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4439 - acc: 0.7899 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 722/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4439 - acc: 0.7899 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 723/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4439 - acc: 0.7899 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 724/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4439 - acc: 0.7882 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 725/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4438 - acc: 0.7882 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 726/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4438 - acc: 0.7899 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 727/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4438 - acc: 0.7899 - val_loss: 0.5020 - val_acc: 0.7500\n",
      "Epoch 728/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4437 - acc: 0.7882 - val_loss: 0.5020 - val_acc: 0.7500\n",
      "Epoch 729/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4437 - acc: 0.7899 - val_loss: 0.5020 - val_acc: 0.7500\n",
      "Epoch 730/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4437 - acc: 0.7882 - val_loss: 0.5020 - val_acc: 0.7500\n",
      "Epoch 731/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4437 - acc: 0.7882 - val_loss: 0.5020 - val_acc: 0.7500\n",
      "Epoch 732/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4436 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 733/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4436 - acc: 0.7899 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 734/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4435 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 735/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4435 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 736/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4435 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 737/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4434 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 738/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4434 - acc: 0.7882 - val_loss: 0.5021 - val_acc: 0.7500\n",
      "Epoch 739/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4434 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 740/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4433 - acc: 0.7899 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 741/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4433 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 742/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4433 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 743/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4432 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 744/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4433 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 745/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4432 - acc: 0.7882 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 746/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4432 - acc: 0.7882 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 747/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4431 - acc: 0.7882 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 748/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4431 - acc: 0.7882 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 749/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4431 - acc: 0.7882 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 750/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4431 - acc: 0.7882 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 751/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4430 - acc: 0.7899 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 752/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4429 - acc: 0.7882 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 753/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4429 - acc: 0.7899 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 754/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4429 - acc: 0.7882 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 755/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4429 - acc: 0.7899 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 756/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4428 - acc: 0.7899 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 757/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4428 - acc: 0.7882 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 758/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4428 - acc: 0.7899 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 759/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4428 - acc: 0.7882 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 760/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4427 - acc: 0.7899 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 761/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4427 - acc: 0.7882 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 762/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4427 - acc: 0.7882 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 763/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4426 - acc: 0.7882 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 764/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4425 - acc: 0.7899 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 765/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4426 - acc: 0.7882 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 766/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4425 - acc: 0.7899 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 767/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4425 - acc: 0.7882 - val_loss: 0.5026 - val_acc: 0.7500\n",
      "Epoch 768/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7882 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 769/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4424 - acc: 0.7899 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 770/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4424 - acc: 0.7899 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 771/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4424 - acc: 0.7899 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 772/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4424 - acc: 0.7882 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 773/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4423 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 775/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 776/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4423 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 777/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4422 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 778/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4422 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 779/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4422 - acc: 0.7882 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 780/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4421 - acc: 0.7882 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 781/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4421 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 782/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4421 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 783/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4420 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 784/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4421 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 785/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4420 - acc: 0.7882 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 786/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4420 - acc: 0.7882 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 787/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4419 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 788/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4419 - acc: 0.7865 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 789/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4419 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 790/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4419 - acc: 0.7882 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 791/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4418 - acc: 0.7882 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 792/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4418 - acc: 0.7882 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 793/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 794/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4417 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 795/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4417 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 796/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 797/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4416 - acc: 0.7899 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "Epoch 798/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4416 - acc: 0.7882 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 799/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4416 - acc: 0.7899 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 800/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4416 - acc: 0.7899 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 801/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4415 - acc: 0.7865 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 802/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4414 - acc: 0.7882 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 803/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4414 - acc: 0.7899 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 804/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4414 - acc: 0.7899 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 805/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4414 - acc: 0.7865 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 806/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4414 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 807/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4414 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 808/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4413 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 809/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4413 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 810/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4412 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 811/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4412 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 812/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4412 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 813/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4411 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7448\n",
      "Epoch 814/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4411 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 815/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4411 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 816/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4411 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 817/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 818/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 819/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7448\n",
      "Epoch 820/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4410 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 821/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 822/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4409 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 823/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 824/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4409 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 825/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4408 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 826/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4408 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 827/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4408 - acc: 0.7847 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 828/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4407 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 829/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4407 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 830/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4407 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7448\n",
      "Epoch 831/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 832/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4406 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 833/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4406 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4406 - acc: 0.7847 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 835/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4405 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 836/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4405 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 837/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4405 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 838/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4405 - acc: 0.7917 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 839/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4405 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 840/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4404 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 841/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4404 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 842/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 843/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4404 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 844/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4403 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 845/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4403 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 846/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4404 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 847/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4403 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7448\n",
      "Epoch 848/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4402 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 849/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4402 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 850/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4402 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 851/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4402 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 852/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4402 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 853/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4401 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 854/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4401 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 855/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4401 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 856/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4401 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 857/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4400 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7448\n",
      "Epoch 858/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4400 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 859/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4400 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 860/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4400 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 861/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4399 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 862/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4399 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 863/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4398 - acc: 0.7899 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 864/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 865/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7448\n",
      "Epoch 866/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 867/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 868/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 869/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 870/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4397 - acc: 0.7899 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 871/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 872/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 873/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 874/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 875/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7448\n",
      "Epoch 876/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 877/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 878/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 879/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4395 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 880/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 881/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4394 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 882/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4395 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 883/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4394 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 884/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4394 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 885/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 886/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4394 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 887/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4393 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 888/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 889/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4393 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 890/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 891/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 892/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 893/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 895/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 896/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4391 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 897/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 898/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 899/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 900/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 901/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 902/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 903/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 904/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 905/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 906/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 907/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 908/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 909/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 910/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 911/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 912/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 913/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 914/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 915/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 916/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 917/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 918/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 919/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 920/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 921/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 922/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 923/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 924/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 925/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 926/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 927/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 928/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 929/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 930/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 931/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 932/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 933/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 934/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 935/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 936/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 937/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 938/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 939/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 940/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 941/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 942/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 943/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 944/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 945/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 946/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 947/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 948/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7448\n",
      "Epoch 949/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 950/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 951/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 952/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 953/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 955/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 956/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 957/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 958/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 959/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 960/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 961/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 962/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 963/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 964/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 965/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 966/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 967/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 968/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 969/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 970/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 971/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 972/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 973/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 974/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 975/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 976/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 977/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 978/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 979/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7448\n",
      "Epoch 980/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 981/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 982/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 983/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 984/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 985/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 986/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 987/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 988/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 989/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 990/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 991/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 992/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 993/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 994/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 995/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 996/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 997/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 998/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 999/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 1000/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7899 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 1001/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 1002/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4367 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 1003/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4368 - acc: 0.7882 - val_loss: 0.5038 - val_acc: 0.7500\n",
      "Epoch 1004/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1005/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1006/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1007/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1008/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1009/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7899 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1010/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7899 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1011/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4367 - acc: 0.7899 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1012/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7500\n",
      "Epoch 1013/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1014/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4366 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1015/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1016/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4365 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1017/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4365 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1018/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4364 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1019/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4365 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1020/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4364 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1021/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4364 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1022/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4364 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1023/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4363 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1024/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4364 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1025/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4363 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1026/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4364 - acc: 0.7882 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1027/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4363 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1028/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4363 - acc: 0.7899 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1029/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4363 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1030/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4363 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1031/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4362 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1032/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4362 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1033/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4362 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1034/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4362 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1035/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4362 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1036/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4361 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1037/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4361 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1038/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4361 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1039/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4361 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1040/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4361 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1041/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4360 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1042/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4360 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1043/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4360 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1044/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1045/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1046/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1047/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4360 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1048/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1049/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4359 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1050/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4359 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1051/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1052/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4359 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1053/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1054/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1055/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1056/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1057/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4358 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1058/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4358 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1059/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4358 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1060/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4357 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1061/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4357 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1062/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1063/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4357 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1064/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4356 - acc: 0.7899 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1065/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1066/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1067/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4357 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1068/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1069/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4355 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1070/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4356 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1071/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4356 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1072/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4355 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1073/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4355 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1074/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4354 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1075/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1076/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1077/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1078/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1079/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1080/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4354 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1081/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4354 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1082/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4354 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1083/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1084/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1085/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1086/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1087/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4353 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1088/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4353 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1089/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4353 - acc: 0.7899 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1090/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1091/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1092/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1093/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4352 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1094/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1095/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1096/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1097/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1098/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1099/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1100/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1101/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1102/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5032 - val_acc: 0.7604\n",
      "Epoch 1103/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1104/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1105/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1106/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4350 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1107/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4350 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1108/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4349 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1109/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1110/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4349 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1111/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1112/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7882 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1113/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1114/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1115/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4349 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1116/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 1117/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1118/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4348 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 1119/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5033 - val_acc: 0.7604\n",
      "Epoch 1120/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 1121/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4348 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7604\n",
      "Epoch 1122/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1123/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1124/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1125/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1126/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1127/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4347 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1128/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - acc: 0.7847 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1129/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1130/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1131/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1132/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1133/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1134/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1135/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1136/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1137/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4346 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1138/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1139/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1140/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1141/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1142/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1143/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4345 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1144/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1145/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1146/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1147/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1148/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4344 - acc: 0.7882 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1149/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1150/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1151/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1152/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4344 - acc: 0.7882 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1153/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1154/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4344 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1155/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1156/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1157/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1158/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1159/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4343 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1160/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1161/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1162/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1163/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1164/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1165/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4342 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1166/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1167/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1168/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1169/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1170/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1171/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4340 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1172/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1173/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1174/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1175/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1176/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4340 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1177/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1178/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1179/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1180/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1181/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1182/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1183/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1184/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4338 - acc: 0.7882 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1185/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1186/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1187/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1188/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1189/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1190/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4337 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1191/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4337 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1192/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4337 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1193/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4337 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1194/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4337 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1195/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1196/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1197/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1198/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4336 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1199/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1200/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1201/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1202/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1203/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1204/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1205/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1206/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1207/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1208/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1209/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1210/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1211/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1212/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - acc: 0.7899 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1213/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4334 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1214/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4334 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1215/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4333 - acc: 0.7899 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1216/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4333 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1217/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4333 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1218/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4333 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1219/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4332 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1220/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4332 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1221/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4333 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1222/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4332 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1223/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4332 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1224/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1225/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1226/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1227/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1228/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4331 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1229/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1230/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4331 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1231/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4330 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1232/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1233/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4329 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1234/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4330 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1235/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1236/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4330 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1237/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4329 - acc: 0.7882 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1238/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4330 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1239/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4329 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1240/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4329 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1241/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4329 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1242/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4328 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1243/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1244/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1245/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4328 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1246/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1247/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4328 - acc: 0.7882 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1248/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1249/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1250/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.4327 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1251/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4327 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1252/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4327 - acc: 0.7882 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1253/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1254/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1255/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1256/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4326 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1257/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1258/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.7917 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1259/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1260/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1261/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1262/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4324 - acc: 0.7917 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1263/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4325 - acc: 0.7917 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1264/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4324 - acc: 0.7917 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1265/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1266/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1267/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - acc: 0.7917 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1268/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1269/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1270/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1271/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1272/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1273/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1274/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1275/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1276/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4323 - acc: 0.7917 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1277/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4322 - acc: 0.7917 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1278/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4322 - acc: 0.7917 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1279/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4321 - acc: 0.7917 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1280/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - acc: 0.7917 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1281/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4321 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1282/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4321 - acc: 0.7934 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1283/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4321 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1284/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4321 - acc: 0.7934 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1285/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4321 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1286/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4320 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1287/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4320 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1288/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4320 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1289/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4320 - acc: 0.7917 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1290/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4320 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1291/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4320 - acc: 0.7934 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1292/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4319 - acc: 0.7917 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1293/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4319 - acc: 0.7934 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1294/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.7934 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1295/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4318 - acc: 0.7934 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1296/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4319 - acc: 0.7934 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1297/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4318 - acc: 0.7934 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1298/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4319 - acc: 0.7951 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1299/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.7934 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1300/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4317 - acc: 0.7934 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1301/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.7917 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1302/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4318 - acc: 0.7934 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1303/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4317 - acc: 0.7917 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1304/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4317 - acc: 0.7934 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1305/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4317 - acc: 0.7917 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1306/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4317 - acc: 0.7934 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1307/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4317 - acc: 0.7934 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1308/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4316 - acc: 0.7934 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1309/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4317 - acc: 0.7917 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1310/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4316 - acc: 0.7917 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1311/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4316 - acc: 0.7934 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1312/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4316 - acc: 0.7899 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1313/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4315 - acc: 0.7934 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1314/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4316 - acc: 0.7917 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1315/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4315 - acc: 0.7934 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1316/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4315 - acc: 0.7934 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1317/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4315 - acc: 0.7934 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1318/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4315 - acc: 0.7917 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1319/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - acc: 0.7934 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1320/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4315 - acc: 0.7934 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1321/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4314 - acc: 0.7934 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1322/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4314 - acc: 0.7917 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1323/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4314 - acc: 0.7934 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1324/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1325/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1326/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1327/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4313 - acc: 0.7917 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1328/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1329/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1330/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4313 - acc: 0.7899 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1331/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4312 - acc: 0.7917 - val_loss: 0.5060 - val_acc: 0.7500\n",
      "Epoch 1332/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.5060 - val_acc: 0.7500\n",
      "Epoch 1333/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4312 - acc: 0.7917 - val_loss: 0.5060 - val_acc: 0.7500\n",
      "Epoch 1334/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4312 - acc: 0.7934 - val_loss: 0.5061 - val_acc: 0.7500\n",
      "Epoch 1335/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4312 - acc: 0.7934 - val_loss: 0.5061 - val_acc: 0.7500\n",
      "Epoch 1336/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4312 - acc: 0.7951 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 1337/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4311 - acc: 0.7934 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 1338/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4311 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 1339/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4311 - acc: 0.7934 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 1340/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4311 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 1341/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4311 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 1342/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4311 - acc: 0.7934 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 1343/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4311 - acc: 0.7917 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 1344/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4310 - acc: 0.7917 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 1345/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4311 - acc: 0.7951 - val_loss: 0.5064 - val_acc: 0.7500\n",
      "Epoch 1346/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.5064 - val_acc: 0.7500\n",
      "Epoch 1347/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.5065 - val_acc: 0.7500\n",
      "Epoch 1348/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4311 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7500\n",
      "Epoch 1349/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.5065 - val_acc: 0.7500\n",
      "Epoch 1350/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.5065 - val_acc: 0.7500\n",
      "Epoch 1351/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 1352/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4309 - acc: 0.7934 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 1353/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4309 - acc: 0.7934 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 1354/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4309 - acc: 0.7969 - val_loss: 0.5066 - val_acc: 0.7500\n",
      "Epoch 1355/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4308 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7500\n",
      "Epoch 1356/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4308 - acc: 0.7899 - val_loss: 0.5067 - val_acc: 0.7500\n",
      "Epoch 1357/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4308 - acc: 0.7899 - val_loss: 0.5068 - val_acc: 0.7500\n",
      "Epoch 1358/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4309 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7500\n",
      "Epoch 1359/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4308 - acc: 0.7934 - val_loss: 0.5068 - val_acc: 0.7500\n",
      "Epoch 1360/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4308 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7500\n",
      "Epoch 1361/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4308 - acc: 0.7899 - val_loss: 0.5069 - val_acc: 0.7500\n",
      "Epoch 1362/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4307 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7500\n",
      "Epoch 1363/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4307 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7500\n",
      "Epoch 1364/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4307 - acc: 0.7934 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 1365/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4307 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 1366/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4307 - acc: 0.7969 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 1367/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4307 - acc: 0.7934 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 1368/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 50us/step - loss: 0.4307 - acc: 0.7951 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 1369/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4306 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 1370/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4306 - acc: 0.7951 - val_loss: 0.5072 - val_acc: 0.7500\n",
      "Epoch 1371/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - acc: 0.7951 - val_loss: 0.5072 - val_acc: 0.7500\n",
      "Epoch 1372/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4305 - acc: 0.7986 - val_loss: 0.5073 - val_acc: 0.7500\n",
      "Epoch 1373/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4305 - acc: 0.7917 - val_loss: 0.5073 - val_acc: 0.7500\n",
      "Epoch 1374/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - acc: 0.8003 - val_loss: 0.5073 - val_acc: 0.7500\n",
      "Epoch 1375/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4305 - acc: 0.7969 - val_loss: 0.5073 - val_acc: 0.7500\n",
      "Epoch 1376/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4305 - acc: 0.7986 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 1377/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4305 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 1378/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4305 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 1379/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4304 - acc: 0.7986 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 1380/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4304 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 1381/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4305 - acc: 0.7986 - val_loss: 0.5075 - val_acc: 0.7500\n",
      "Epoch 1382/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4304 - acc: 0.8003 - val_loss: 0.5075 - val_acc: 0.7500\n",
      "Epoch 1383/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4304 - acc: 0.8003 - val_loss: 0.5075 - val_acc: 0.7500\n",
      "Epoch 1384/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4304 - acc: 0.7986 - val_loss: 0.5075 - val_acc: 0.7500\n",
      "Epoch 1385/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4304 - acc: 0.7986 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 1386/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4303 - acc: 0.7986 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 1387/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4303 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 1388/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4303 - acc: 0.8003 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 1389/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4303 - acc: 0.7986 - val_loss: 0.5077 - val_acc: 0.7500\n",
      "Epoch 1390/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4302 - acc: 0.8003 - val_loss: 0.5077 - val_acc: 0.7500\n",
      "Epoch 1391/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4303 - acc: 0.7986 - val_loss: 0.5078 - val_acc: 0.7500\n",
      "Epoch 1392/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4303 - acc: 0.8003 - val_loss: 0.5077 - val_acc: 0.7500\n",
      "Epoch 1393/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4302 - acc: 0.8003 - val_loss: 0.5078 - val_acc: 0.7500\n",
      "Epoch 1394/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4303 - acc: 0.7969 - val_loss: 0.5078 - val_acc: 0.7500\n",
      "Epoch 1395/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4302 - acc: 0.7986 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 1396/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4301 - acc: 0.8003 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 1397/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4301 - acc: 0.8003 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 1398/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4301 - acc: 0.7986 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 1399/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4302 - acc: 0.7986 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 1400/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4302 - acc: 0.8003 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 1401/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4301 - acc: 0.7986 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 1402/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4301 - acc: 0.7986 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 1403/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4301 - acc: 0.8003 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 1404/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4301 - acc: 0.7986 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 1405/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 1406/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4301 - acc: 0.8003 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 1407/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 1408/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 1409/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 1410/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 1411/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4300 - acc: 0.8003 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 1412/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4300 - acc: 0.7986 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 1413/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4299 - acc: 0.8003 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 1414/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4299 - acc: 0.7986 - val_loss: 0.5084 - val_acc: 0.7500\n",
      "Epoch 1415/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4299 - acc: 0.8003 - val_loss: 0.5084 - val_acc: 0.7500\n",
      "Epoch 1416/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4299 - acc: 0.8003 - val_loss: 0.5084 - val_acc: 0.7500\n",
      "Epoch 1417/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4299 - acc: 0.8021 - val_loss: 0.5084 - val_acc: 0.7500\n",
      "Epoch 1418/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4299 - acc: 0.8003 - val_loss: 0.5084 - val_acc: 0.7500\n",
      "Epoch 1419/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4298 - acc: 0.8003 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 1420/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4298 - acc: 0.8003 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 1421/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4297 - acc: 0.8003 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 1422/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4298 - acc: 0.8003 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 1423/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4297 - acc: 0.7986 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 1424/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4297 - acc: 0.8003 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 1425/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4297 - acc: 0.7969 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 1426/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4297 - acc: 0.7986 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 1427/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4297 - acc: 0.7969 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 1428/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 1429/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4297 - acc: 0.8003 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 1430/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4296 - acc: 0.7986 - val_loss: 0.5087 - val_acc: 0.7500\n",
      "Epoch 1431/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 1432/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 1433/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 1434/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 1435/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 1436/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.7986 - val_loss: 0.5089 - val_acc: 0.7500\n",
      "Epoch 1437/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - acc: 0.7986 - val_loss: 0.5089 - val_acc: 0.7500\n",
      "Epoch 1438/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - acc: 0.7986 - val_loss: 0.5090 - val_acc: 0.7500\n",
      "Epoch 1439/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - acc: 0.8003 - val_loss: 0.5090 - val_acc: 0.7500\n",
      "Epoch 1440/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4296 - acc: 0.8003 - val_loss: 0.5090 - val_acc: 0.7500\n",
      "Epoch 1441/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - acc: 0.8003 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1442/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4295 - acc: 0.7986 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1443/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - acc: 0.7986 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1444/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4294 - acc: 0.8003 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1445/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4294 - acc: 0.8003 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1446/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4295 - acc: 0.7986 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1447/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.8003 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1448/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4294 - acc: 0.7986 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 1449/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4294 - acc: 0.7986 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 1450/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 1451/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1452/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4293 - acc: 0.8003 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1453/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1454/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4294 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1455/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1456/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4294 - acc: 0.8003 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1457/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1458/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4293 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1459/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4292 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1460/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4292 - acc: 0.8003 - val_loss: 0.5094 - val_acc: 0.7500\n",
      "Epoch 1461/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4292 - acc: 0.8003 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1462/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4292 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 1463/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4292 - acc: 0.7986 - val_loss: 0.5094 - val_acc: 0.7500\n",
      "Epoch 1464/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5094 - val_acc: 0.7500\n",
      "Epoch 1465/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1466/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4292 - acc: 0.7986 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1467/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4292 - acc: 0.7986 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1468/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1469/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1470/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5096 - val_acc: 0.7500\n",
      "Epoch 1471/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4290 - acc: 0.7969 - val_loss: 0.5096 - val_acc: 0.7500\n",
      "Epoch 1472/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5096 - val_acc: 0.7500\n",
      "Epoch 1473/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1474/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1475/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1476/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1477/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1478/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 1479/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1480/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1481/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1482/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1483/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1484/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1485/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1486/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1487/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1488/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1489/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1490/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1491/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1492/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1493/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5100 - val_acc: 0.7500\n",
      "Epoch 1494/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4288 - acc: 0.8003 - val_loss: 0.5100 - val_acc: 0.7500\n",
      "Epoch 1495/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.5100 - val_acc: 0.7500\n",
      "Epoch 1496/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5100 - val_acc: 0.7500\n",
      "Epoch 1497/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4287 - acc: 0.7986 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 1498/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 1499/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4287 - acc: 0.7986 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 1500/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 1501/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4287 - acc: 0.7986 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1502/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4286 - acc: 0.8003 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1503/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4287 - acc: 0.8003 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1504/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8003 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1505/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4286 - acc: 0.7969 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1506/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 1507/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 1508/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 1509/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8003 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 1510/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 1511/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5104 - val_acc: 0.7500\n",
      "Epoch 1512/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5104 - val_acc: 0.7500\n",
      "Epoch 1513/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5104 - val_acc: 0.7500\n",
      "Epoch 1514/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4284 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1515/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1516/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1517/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4285 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1518/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4284 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1519/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4284 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1520/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4284 - acc: 0.8003 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 1521/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4284 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1522/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1523/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1524/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1525/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1526/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 1527/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 1528/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 1529/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 1530/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1531/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 1532/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 1533/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1534/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1535/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1536/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1537/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5109 - val_acc: 0.7500\n",
      "Epoch 1538/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5109 - val_acc: 0.7500\n",
      "Epoch 1539/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4282 - acc: 0.8003 - val_loss: 0.5109 - val_acc: 0.7500\n",
      "Epoch 1540/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5109 - val_acc: 0.7500\n",
      "Epoch 1541/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4281 - acc: 0.8021 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1542/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1543/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1544/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1545/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1546/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 1547/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1548/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4281 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1549/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 1550/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 1551/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 1552/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4279 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 1553/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1554/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1555/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1556/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1557/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4279 - acc: 0.8003 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1558/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 1559/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1560/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1561/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1562/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1563/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1564/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1565/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1566/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1567/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1568/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1569/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1570/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1571/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1572/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1573/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1574/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1575/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1576/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1577/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1578/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1579/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 1580/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 1581/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 1582/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5116 - val_acc: 0.7500\n",
      "Epoch 1583/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5116 - val_acc: 0.7500\n",
      "Epoch 1584/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5116 - val_acc: 0.7500\n",
      "Epoch 1585/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5116 - val_acc: 0.7500\n",
      "Epoch 1586/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1587/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1588/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1589/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1590/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1591/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1592/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1593/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1594/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1595/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1596/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1597/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1598/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1599/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1600/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1601/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1602/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1603/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1604/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 48us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1605/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1606/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1607/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1608/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1609/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1610/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1611/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1612/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1613/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1614/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1615/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1616/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1617/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1618/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1619/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1620/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1621/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1622/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1623/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1624/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1625/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1626/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1627/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1628/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4268 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1629/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1630/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1631/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1632/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1633/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4268 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1634/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4267 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1635/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4266 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1636/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4266 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1637/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4267 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1638/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4266 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1639/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4266 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1640/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4266 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1641/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4265 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1642/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4266 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1643/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4265 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 1644/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4264 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1645/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1646/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4265 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1647/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4264 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1648/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4264 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1649/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4264 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1650/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1651/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1652/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1653/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4263 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1654/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4263 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1655/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4262 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1656/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4262 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1657/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4262 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1658/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1659/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1660/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1661/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1662/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4262 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1663/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1664/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1665/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1666/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1667/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1668/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4260 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1669/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4259 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1670/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4259 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1671/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4260 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1672/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4259 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1673/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4259 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1674/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4258 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1675/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4259 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1676/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4258 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1677/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4258 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1678/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4258 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1679/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4257 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1680/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4257 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1681/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4257 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1682/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4257 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1683/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4256 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1684/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4256 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1685/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4257 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1686/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1687/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1688/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1689/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1690/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1691/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1692/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4254 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1693/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1694/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4254 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1695/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4253 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1696/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4255 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1697/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4253 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1698/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4253 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1699/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4254 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1700/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4253 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1701/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4252 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1702/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4252 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1703/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4252 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1704/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4252 - acc: 0.8003 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 1705/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4252 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1706/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4251 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1707/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4251 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1708/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4250 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1709/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4250 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1710/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4250 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 1711/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4250 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1712/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1713/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1714/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1715/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1716/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 1717/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1718/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4248 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1719/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4248 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1720/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1721/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4247 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1722/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1723/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1724/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4246 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1725/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1726/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1727/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4245 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1728/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4245 - acc: 0.8003 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1729/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 1730/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1731/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1732/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1733/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1734/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - acc: 0.7986 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1735/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4243 - acc: 0.8021 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1736/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1737/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1738/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5119 - val_acc: 0.7448\n",
      "Epoch 1739/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1740/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1741/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1742/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4242 - acc: 0.7986 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1743/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1744/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1745/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4239 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1746/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1747/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4240 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1748/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4239 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1749/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1750/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1751/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1752/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1753/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1754/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1755/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1756/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4236 - acc: 0.7986 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1757/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1758/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4234 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1759/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1760/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1761/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1762/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1763/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4232 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1764/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1765/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1766/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1767/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1768/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1769/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1770/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1771/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1772/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1773/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1774/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1775/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1776/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1777/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1778/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 1779/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1780/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1781/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1782/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1783/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4221 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1784/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 1785/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1786/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1787/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1788/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4218 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1789/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1790/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4217 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1791/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1792/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 1793/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1794/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4215 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1795/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1796/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4215 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1797/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4214 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 1798/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4214 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1799/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4214 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1800/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4213 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1801/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4212 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1802/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4212 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1803/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4211 - acc: 0.8021 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1804/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4211 - acc: 0.8021 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1805/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4211 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1806/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4211 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1807/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4211 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1808/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4210 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1809/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4209 - acc: 0.8003 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1810/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4209 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1811/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4208 - acc: 0.7986 - val_loss: 0.5121 - val_acc: 0.7396\n",
      "Epoch 1812/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4208 - acc: 0.8003 - val_loss: 0.5120 - val_acc: 0.7396\n",
      "Epoch 1813/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.5122 - val_acc: 0.7396\n",
      "Epoch 1814/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.5122 - val_acc: 0.7396\n",
      "Epoch 1815/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.5122 - val_acc: 0.7396\n",
      "Epoch 1816/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4206 - acc: 0.7986 - val_loss: 0.5123 - val_acc: 0.7396\n",
      "Epoch 1817/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4206 - acc: 0.7986 - val_loss: 0.5122 - val_acc: 0.7396\n",
      "Epoch 1818/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4206 - acc: 0.8003 - val_loss: 0.5123 - val_acc: 0.7396\n",
      "Epoch 1819/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5123 - val_acc: 0.7396\n",
      "Epoch 1820/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5124 - val_acc: 0.7396\n",
      "Epoch 1821/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5123 - val_acc: 0.7396\n",
      "Epoch 1822/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4204 - acc: 0.7969 - val_loss: 0.5125 - val_acc: 0.7396\n",
      "Epoch 1823/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.5125 - val_acc: 0.7396\n",
      "Epoch 1824/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4204 - acc: 0.7986 - val_loss: 0.5125 - val_acc: 0.7396\n",
      "Epoch 1825/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.5125 - val_acc: 0.7396\n",
      "Epoch 1826/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.5125 - val_acc: 0.7396\n",
      "Epoch 1827/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 1828/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 1829/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4203 - acc: 0.7969 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 1830/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4203 - acc: 0.8003 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 1831/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4202 - acc: 0.8003 - val_loss: 0.5127 - val_acc: 0.7396\n",
      "Epoch 1832/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4201 - acc: 0.8021 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 1833/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4201 - acc: 0.8021 - val_loss: 0.5125 - val_acc: 0.7448\n",
      "Epoch 1834/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4201 - acc: 0.7969 - val_loss: 0.5126 - val_acc: 0.7448\n",
      "Epoch 1835/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4201 - acc: 0.7969 - val_loss: 0.5127 - val_acc: 0.7448\n",
      "Epoch 1836/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4200 - acc: 0.7951 - val_loss: 0.5127 - val_acc: 0.7396\n",
      "Epoch 1837/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4199 - acc: 0.8003 - val_loss: 0.5127 - val_acc: 0.7448\n",
      "Epoch 1838/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4199 - acc: 0.8021 - val_loss: 0.5127 - val_acc: 0.7448\n",
      "Epoch 1839/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4200 - acc: 0.7969 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 1840/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.4200 - acc: 0.7969 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 1841/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4199 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 1842/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - acc: 0.7969 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 1843/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4198 - acc: 0.7969 - val_loss: 0.5129 - val_acc: 0.7448\n",
      "Epoch 1844/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4198 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7448\n",
      "Epoch 1845/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4197 - acc: 0.7969 - val_loss: 0.5130 - val_acc: 0.7448\n",
      "Epoch 1846/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4197 - acc: 0.7969 - val_loss: 0.5131 - val_acc: 0.7448\n",
      "Epoch 1847/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4197 - acc: 0.8003 - val_loss: 0.5132 - val_acc: 0.7448\n",
      "Epoch 1848/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4197 - acc: 0.7951 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 1849/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4196 - acc: 0.8003 - val_loss: 0.5132 - val_acc: 0.7448\n",
      "Epoch 1850/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4196 - acc: 0.8003 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 1851/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4195 - acc: 0.7986 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 1852/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4195 - acc: 0.8003 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 1853/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4195 - acc: 0.8003 - val_loss: 0.5134 - val_acc: 0.7448\n",
      "Epoch 1854/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4195 - acc: 0.8003 - val_loss: 0.5134 - val_acc: 0.7448\n",
      "Epoch 1855/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4194 - acc: 0.8003 - val_loss: 0.5134 - val_acc: 0.7448\n",
      "Epoch 1856/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4194 - acc: 0.8003 - val_loss: 0.5134 - val_acc: 0.7448\n",
      "Epoch 1857/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4194 - acc: 0.8003 - val_loss: 0.5135 - val_acc: 0.7448\n",
      "Epoch 1858/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4193 - acc: 0.8003 - val_loss: 0.5135 - val_acc: 0.7448\n",
      "Epoch 1859/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.5135 - val_acc: 0.7500\n",
      "Epoch 1860/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4193 - acc: 0.7986 - val_loss: 0.5136 - val_acc: 0.7500\n",
      "Epoch 1861/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4193 - acc: 0.7969 - val_loss: 0.5137 - val_acc: 0.7500\n",
      "Epoch 1862/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.5138 - val_acc: 0.7552\n",
      "Epoch 1863/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4193 - acc: 0.7986 - val_loss: 0.5138 - val_acc: 0.7552\n",
      "Epoch 1864/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4193 - acc: 0.8003 - val_loss: 0.5139 - val_acc: 0.7552\n",
      "Epoch 1865/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4192 - acc: 0.7986 - val_loss: 0.5138 - val_acc: 0.7552\n",
      "Epoch 1866/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4191 - acc: 0.7986 - val_loss: 0.5139 - val_acc: 0.7552\n",
      "Epoch 1867/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4191 - acc: 0.7986 - val_loss: 0.5140 - val_acc: 0.7552\n",
      "Epoch 1868/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4191 - acc: 0.7986 - val_loss: 0.5140 - val_acc: 0.7552\n",
      "Epoch 1869/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.5140 - val_acc: 0.7552\n",
      "Epoch 1870/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.5141 - val_acc: 0.7552\n",
      "Epoch 1871/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.5140 - val_acc: 0.7552\n",
      "Epoch 1872/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4190 - acc: 0.7969 - val_loss: 0.5140 - val_acc: 0.7552\n",
      "Epoch 1873/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.5141 - val_acc: 0.7552\n",
      "Epoch 1874/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4189 - acc: 0.7986 - val_loss: 0.5141 - val_acc: 0.7552\n",
      "Epoch 1875/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4189 - acc: 0.8003 - val_loss: 0.5142 - val_acc: 0.7552\n",
      "Epoch 1876/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4188 - acc: 0.7986 - val_loss: 0.5143 - val_acc: 0.7552\n",
      "Epoch 1877/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4188 - acc: 0.7986 - val_loss: 0.5142 - val_acc: 0.7552\n",
      "Epoch 1878/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4188 - acc: 0.7969 - val_loss: 0.5143 - val_acc: 0.7552\n",
      "Epoch 1879/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4188 - acc: 0.8003 - val_loss: 0.5143 - val_acc: 0.7552\n",
      "Epoch 1880/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - acc: 0.7986 - val_loss: 0.5144 - val_acc: 0.7552\n",
      "Epoch 1881/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4187 - acc: 0.7986 - val_loss: 0.5144 - val_acc: 0.7552\n",
      "Epoch 1882/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4186 - acc: 0.7986 - val_loss: 0.5145 - val_acc: 0.7552\n",
      "Epoch 1883/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4186 - acc: 0.7986 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 1884/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4186 - acc: 0.7986 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 1885/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4186 - acc: 0.8003 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 1886/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - acc: 0.7986 - val_loss: 0.5147 - val_acc: 0.7604\n",
      "Epoch 1887/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - acc: 0.7986 - val_loss: 0.5147 - val_acc: 0.7604\n",
      "Epoch 1888/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4185 - acc: 0.7986 - val_loss: 0.5148 - val_acc: 0.7604\n",
      "Epoch 1889/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - acc: 0.7986 - val_loss: 0.5148 - val_acc: 0.7604\n",
      "Epoch 1890/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4184 - acc: 0.7986 - val_loss: 0.5148 - val_acc: 0.7604\n",
      "Epoch 1891/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4184 - acc: 0.8003 - val_loss: 0.5149 - val_acc: 0.7604\n",
      "Epoch 1892/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4183 - acc: 0.7986 - val_loss: 0.5149 - val_acc: 0.7604\n",
      "Epoch 1893/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - acc: 0.7986 - val_loss: 0.5150 - val_acc: 0.7604\n",
      "Epoch 1894/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - acc: 0.7986 - val_loss: 0.5151 - val_acc: 0.7604\n",
      "Epoch 1895/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4183 - acc: 0.7986 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 1896/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 1897/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4182 - acc: 0.8021 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 1898/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4182 - acc: 0.8021 - val_loss: 0.5152 - val_acc: 0.7604\n",
      "Epoch 1899/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 1900/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4181 - acc: 0.8021 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 1901/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.5153 - val_acc: 0.7604\n",
      "Epoch 1902/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4180 - acc: 0.8003 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 1903/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4180 - acc: 0.8003 - val_loss: 0.5154 - val_acc: 0.7604\n",
      "Epoch 1904/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4180 - acc: 0.8038 - val_loss: 0.5155 - val_acc: 0.7604\n",
      "Epoch 1905/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4180 - acc: 0.8003 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 1906/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4179 - acc: 0.8021 - val_loss: 0.5156 - val_acc: 0.7604\n",
      "Epoch 1907/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4179 - acc: 0.8021 - val_loss: 0.5157 - val_acc: 0.7604\n",
      "Epoch 1908/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4179 - acc: 0.8021 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 1909/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4178 - acc: 0.8021 - val_loss: 0.5158 - val_acc: 0.7604\n",
      "Epoch 1910/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4179 - acc: 0.8021 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 1911/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 1912/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 1913/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4178 - acc: 0.8021 - val_loss: 0.5159 - val_acc: 0.7604\n",
      "Epoch 1914/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4177 - acc: 0.8021 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 1915/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 1916/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.5160 - val_acc: 0.7604\n",
      "Epoch 1917/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4177 - acc: 0.8056 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 1918/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 1919/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 1920/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 1921/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4175 - acc: 0.8021 - val_loss: 0.5162 - val_acc: 0.7604\n",
      "Epoch 1922/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4176 - acc: 0.8038 - val_loss: 0.5163 - val_acc: 0.7604\n",
      "Epoch 1923/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4175 - acc: 0.8038 - val_loss: 0.5164 - val_acc: 0.7604\n",
      "Epoch 1924/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4175 - acc: 0.8021 - val_loss: 0.5163 - val_acc: 0.7604\n",
      "Epoch 1925/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4174 - acc: 0.8021 - val_loss: 0.5164 - val_acc: 0.7604\n",
      "Epoch 1926/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4174 - acc: 0.8021 - val_loss: 0.5164 - val_acc: 0.7604\n",
      "Epoch 1927/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4174 - acc: 0.8038 - val_loss: 0.5165 - val_acc: 0.7604\n",
      "Epoch 1928/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4174 - acc: 0.8038 - val_loss: 0.5166 - val_acc: 0.7604\n",
      "Epoch 1929/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4173 - acc: 0.8038 - val_loss: 0.5167 - val_acc: 0.7604\n",
      "Epoch 1930/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - acc: 0.8038 - val_loss: 0.5166 - val_acc: 0.7604\n",
      "Epoch 1931/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4174 - acc: 0.8038 - val_loss: 0.5166 - val_acc: 0.7604\n",
      "Epoch 1932/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4172 - acc: 0.8021 - val_loss: 0.5167 - val_acc: 0.7604\n",
      "Epoch 1933/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4172 - acc: 0.8038 - val_loss: 0.5167 - val_acc: 0.7604\n",
      "Epoch 1934/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4172 - acc: 0.8038 - val_loss: 0.5168 - val_acc: 0.7604\n",
      "Epoch 1935/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4171 - acc: 0.8038 - val_loss: 0.5169 - val_acc: 0.7604\n",
      "Epoch 1936/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4171 - acc: 0.8038 - val_loss: 0.5169 - val_acc: 0.7604\n",
      "Epoch 1937/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4172 - acc: 0.8038 - val_loss: 0.5170 - val_acc: 0.7604\n",
      "Epoch 1938/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4171 - acc: 0.8021 - val_loss: 0.5169 - val_acc: 0.7604\n",
      "Epoch 1939/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - acc: 0.8038 - val_loss: 0.5170 - val_acc: 0.7604\n",
      "Epoch 1940/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4170 - acc: 0.8038 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1941/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - acc: 0.8056 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1942/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4169 - acc: 0.8056 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1943/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - acc: 0.8038 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1944/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - acc: 0.8056 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1945/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4169 - acc: 0.8056 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1946/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - acc: 0.8021 - val_loss: 0.5171 - val_acc: 0.7656\n",
      "Epoch 1947/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4169 - acc: 0.8038 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1948/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4169 - acc: 0.8056 - val_loss: 0.5170 - val_acc: 0.7604\n",
      "Epoch 1949/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4168 - acc: 0.8021 - val_loss: 0.5171 - val_acc: 0.7604\n",
      "Epoch 1950/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4168 - acc: 0.8021 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1951/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - acc: 0.8021 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1952/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4167 - acc: 0.8056 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1953/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4167 - acc: 0.8056 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1954/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4166 - acc: 0.8038 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1955/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4167 - acc: 0.8021 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1956/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4166 - acc: 0.8038 - val_loss: 0.5172 - val_acc: 0.7604\n",
      "Epoch 1957/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4166 - acc: 0.8038 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 1958/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 50us/step - loss: 0.4166 - acc: 0.8021 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 1959/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4165 - acc: 0.8038 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 1960/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - acc: 0.8021 - val_loss: 0.5173 - val_acc: 0.7604\n",
      "Epoch 1961/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4164 - acc: 0.8021 - val_loss: 0.5174 - val_acc: 0.7604\n",
      "Epoch 1962/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4164 - acc: 0.8038 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1963/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8056 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1964/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - acc: 0.8038 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1965/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - acc: 0.8056 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1966/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4163 - acc: 0.8056 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1967/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8038 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1968/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8038 - val_loss: 0.5175 - val_acc: 0.7604\n",
      "Epoch 1969/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4162 - acc: 0.8021 - val_loss: 0.5176 - val_acc: 0.7604\n",
      "Epoch 1970/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8021 - val_loss: 0.5176 - val_acc: 0.7604\n",
      "Epoch 1971/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4162 - acc: 0.8038 - val_loss: 0.5176 - val_acc: 0.7604\n",
      "Epoch 1972/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - acc: 0.8021 - val_loss: 0.5177 - val_acc: 0.7604\n",
      "Epoch 1973/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4162 - acc: 0.8038 - val_loss: 0.5177 - val_acc: 0.7604\n",
      "Epoch 1974/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4161 - acc: 0.8021 - val_loss: 0.5177 - val_acc: 0.7604\n",
      "Epoch 1975/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4161 - acc: 0.8038 - val_loss: 0.5177 - val_acc: 0.7604\n",
      "Epoch 1976/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4161 - acc: 0.8038 - val_loss: 0.5178 - val_acc: 0.7604\n",
      "Epoch 1977/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4161 - acc: 0.8038 - val_loss: 0.5179 - val_acc: 0.7604\n",
      "Epoch 1978/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4161 - acc: 0.8021 - val_loss: 0.5179 - val_acc: 0.7604\n",
      "Epoch 1979/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4160 - acc: 0.8021 - val_loss: 0.5180 - val_acc: 0.7604\n",
      "Epoch 1980/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4160 - acc: 0.8038 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 1981/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4160 - acc: 0.8038 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 1982/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4160 - acc: 0.8038 - val_loss: 0.5180 - val_acc: 0.7604\n",
      "Epoch 1983/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4160 - acc: 0.8038 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 1984/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4160 - acc: 0.8038 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 1985/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - acc: 0.8038 - val_loss: 0.5181 - val_acc: 0.7604\n",
      "Epoch 1986/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4159 - acc: 0.8038 - val_loss: 0.5182 - val_acc: 0.7604\n",
      "Epoch 1987/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - acc: 0.8038 - val_loss: 0.5183 - val_acc: 0.7604\n",
      "Epoch 1988/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4159 - acc: 0.8038 - val_loss: 0.5183 - val_acc: 0.7604\n",
      "Epoch 1989/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5183 - val_acc: 0.7604\n",
      "Epoch 1990/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5184 - val_acc: 0.7604\n",
      "Epoch 1991/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5185 - val_acc: 0.7604\n",
      "Epoch 1992/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5186 - val_acc: 0.7604\n",
      "Epoch 1993/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5186 - val_acc: 0.7604\n",
      "Epoch 1994/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5186 - val_acc: 0.7604\n",
      "Epoch 1995/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4156 - acc: 0.8038 - val_loss: 0.5187 - val_acc: 0.7604\n",
      "Epoch 1996/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4156 - acc: 0.8038 - val_loss: 0.5187 - val_acc: 0.7604\n",
      "Epoch 1997/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - acc: 0.8038 - val_loss: 0.5187 - val_acc: 0.7604\n",
      "Epoch 1998/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4157 - acc: 0.8038 - val_loss: 0.5187 - val_acc: 0.7604\n",
      "Epoch 1999/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - acc: 0.8056 - val_loss: 0.5187 - val_acc: 0.7604\n",
      "Epoch 2000/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - acc: 0.8038 - val_loss: 0.5188 - val_acc: 0.7604\n",
      "Epoch 2001/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - acc: 0.8056 - val_loss: 0.5189 - val_acc: 0.7604\n",
      "Epoch 2002/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4154 - acc: 0.8038 - val_loss: 0.5189 - val_acc: 0.7604\n",
      "Epoch 2003/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4155 - acc: 0.8056 - val_loss: 0.5190 - val_acc: 0.7604\n",
      "Epoch 2004/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4154 - acc: 0.8021 - val_loss: 0.5191 - val_acc: 0.7604\n",
      "Epoch 2005/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4155 - acc: 0.8021 - val_loss: 0.5191 - val_acc: 0.7604\n",
      "Epoch 2006/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4154 - acc: 0.8038 - val_loss: 0.5192 - val_acc: 0.7604\n",
      "Epoch 2007/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4154 - acc: 0.8056 - val_loss: 0.5192 - val_acc: 0.7604\n",
      "Epoch 2008/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4153 - acc: 0.8038 - val_loss: 0.5192 - val_acc: 0.7604\n",
      "Epoch 2009/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4153 - acc: 0.8056 - val_loss: 0.5193 - val_acc: 0.7604\n",
      "Epoch 2010/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4153 - acc: 0.8038 - val_loss: 0.5192 - val_acc: 0.7604\n",
      "Epoch 2011/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4153 - acc: 0.8038 - val_loss: 0.5193 - val_acc: 0.7604\n",
      "Epoch 2012/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4153 - acc: 0.8056 - val_loss: 0.5193 - val_acc: 0.7604\n",
      "Epoch 2013/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4153 - acc: 0.8056 - val_loss: 0.5194 - val_acc: 0.7604\n",
      "Epoch 2014/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - acc: 0.8021 - val_loss: 0.5193 - val_acc: 0.7604\n",
      "Epoch 2015/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - acc: 0.8021 - val_loss: 0.5194 - val_acc: 0.7604\n",
      "Epoch 2016/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - acc: 0.8038 - val_loss: 0.5193 - val_acc: 0.7604\n",
      "Epoch 2017/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4151 - acc: 0.8021 - val_loss: 0.5194 - val_acc: 0.7604\n",
      "Epoch 2018/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - acc: 0.8038 - val_loss: 0.5195 - val_acc: 0.7604\n",
      "Epoch 2019/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4152 - acc: 0.8056 - val_loss: 0.5195 - val_acc: 0.7604\n",
      "Epoch 2020/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - acc: 0.8056 - val_loss: 0.5196 - val_acc: 0.7604\n",
      "Epoch 2021/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - acc: 0.8056 - val_loss: 0.5196 - val_acc: 0.7604\n",
      "Epoch 2022/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - acc: 0.8056 - val_loss: 0.5197 - val_acc: 0.7604\n",
      "Epoch 2023/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - acc: 0.8056 - val_loss: 0.5197 - val_acc: 0.7604\n",
      "Epoch 2024/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - acc: 0.8038 - val_loss: 0.5198 - val_acc: 0.7604\n",
      "Epoch 2025/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4151 - acc: 0.8021 - val_loss: 0.5198 - val_acc: 0.7604\n",
      "Epoch 2026/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4150 - acc: 0.8038 - val_loss: 0.5198 - val_acc: 0.7604\n",
      "Epoch 2027/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - acc: 0.8038 - val_loss: 0.5198 - val_acc: 0.7604\n",
      "Epoch 2028/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4150 - acc: 0.8056 - val_loss: 0.5199 - val_acc: 0.7604\n",
      "Epoch 2029/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - acc: 0.8038 - val_loss: 0.5199 - val_acc: 0.7604\n",
      "Epoch 2030/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5200 - val_acc: 0.7604\n",
      "Epoch 2031/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5200 - val_acc: 0.7604\n",
      "Epoch 2032/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5201 - val_acc: 0.7604\n",
      "Epoch 2033/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5202 - val_acc: 0.7604\n",
      "Epoch 2034/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5201 - val_acc: 0.7604\n",
      "Epoch 2035/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4149 - acc: 0.8056 - val_loss: 0.5202 - val_acc: 0.7604\n",
      "Epoch 2036/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4148 - acc: 0.8056 - val_loss: 0.5203 - val_acc: 0.7604\n",
      "Epoch 2037/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - acc: 0.8038 - val_loss: 0.5202 - val_acc: 0.7604\n",
      "Epoch 2038/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4148 - acc: 0.8038 - val_loss: 0.5203 - val_acc: 0.7604\n",
      "Epoch 2039/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - acc: 0.8056 - val_loss: 0.5203 - val_acc: 0.7604\n",
      "Epoch 2040/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4148 - acc: 0.8056 - val_loss: 0.5204 - val_acc: 0.7604\n",
      "Epoch 2041/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - acc: 0.8056 - val_loss: 0.5205 - val_acc: 0.7604\n",
      "Epoch 2042/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5205 - val_acc: 0.7604\n",
      "Epoch 2043/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - acc: 0.8056 - val_loss: 0.5205 - val_acc: 0.7604\n",
      "Epoch 2044/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5206 - val_acc: 0.7604\n",
      "Epoch 2045/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5207 - val_acc: 0.7604\n",
      "Epoch 2046/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5207 - val_acc: 0.7604\n",
      "Epoch 2047/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5208 - val_acc: 0.7604\n",
      "Epoch 2048/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5208 - val_acc: 0.7604\n",
      "Epoch 2049/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4147 - acc: 0.8056 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2050/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - acc: 0.8038 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2051/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - acc: 0.8056 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2052/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4146 - acc: 0.8038 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2053/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - acc: 0.8038 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2054/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4145 - acc: 0.8056 - val_loss: 0.5209 - val_acc: 0.7604\n",
      "Epoch 2055/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - acc: 0.8038 - val_loss: 0.5210 - val_acc: 0.7604\n",
      "Epoch 2056/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4144 - acc: 0.8056 - val_loss: 0.5211 - val_acc: 0.7604\n",
      "Epoch 2057/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4145 - acc: 0.8056 - val_loss: 0.5211 - val_acc: 0.7604\n",
      "Epoch 2058/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4145 - acc: 0.8056 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 2059/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4144 - acc: 0.8038 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 2060/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4145 - acc: 0.8038 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 2061/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4144 - acc: 0.8056 - val_loss: 0.5213 - val_acc: 0.7604\n",
      "Epoch 2062/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4146 - acc: 0.8038 - val_loss: 0.5213 - val_acc: 0.7604\n",
      "Epoch 2063/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - acc: 0.8021 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 2064/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - acc: 0.8056 - val_loss: 0.5212 - val_acc: 0.7604\n",
      "Epoch 2065/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - acc: 0.8038 - val_loss: 0.5213 - val_acc: 0.7604\n",
      "Epoch 2066/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - acc: 0.8038 - val_loss: 0.5214 - val_acc: 0.7604\n",
      "Epoch 2067/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - acc: 0.8056 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 2068/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4143 - acc: 0.8038 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 2069/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4143 - acc: 0.8056 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 2070/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4144 - acc: 0.8038 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 2071/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4143 - acc: 0.8038 - val_loss: 0.5215 - val_acc: 0.7604\n",
      "Epoch 2072/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4142 - acc: 0.8038 - val_loss: 0.5216 - val_acc: 0.7604\n",
      "Epoch 2073/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4142 - acc: 0.8056 - val_loss: 0.5217 - val_acc: 0.7604\n",
      "Epoch 2074/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4142 - acc: 0.8038 - val_loss: 0.5216 - val_acc: 0.7604\n",
      "Epoch 2075/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4141 - acc: 0.8056 - val_loss: 0.5216 - val_acc: 0.7604\n",
      "Epoch 2076/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.4142 - acc: 0.8056 - val_loss: 0.5217 - val_acc: 0.7604\n",
      "Epoch 2077/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5218 - val_acc: 0.7604\n",
      "Epoch 2078/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5218 - val_acc: 0.7604\n",
      "Epoch 2079/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5219 - val_acc: 0.7604\n",
      "Epoch 2080/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5219 - val_acc: 0.7604\n",
      "Epoch 2081/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5219 - val_acc: 0.7604\n",
      "Epoch 2082/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5218 - val_acc: 0.7604\n",
      "Epoch 2083/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4140 - acc: 0.8056 - val_loss: 0.5219 - val_acc: 0.7604\n",
      "Epoch 2084/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4140 - acc: 0.8056 - val_loss: 0.5220 - val_acc: 0.7604\n",
      "Epoch 2085/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4140 - acc: 0.8056 - val_loss: 0.5220 - val_acc: 0.7604\n",
      "Epoch 2086/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4140 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7604\n",
      "Epoch 2087/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4140 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7604\n",
      "Epoch 2088/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4140 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7604\n",
      "Epoch 2089/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7604\n",
      "Epoch 2090/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5223 - val_acc: 0.7604\n",
      "Epoch 2091/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5223 - val_acc: 0.7604\n",
      "Epoch 2092/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5224 - val_acc: 0.7604\n",
      "Epoch 2093/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5224 - val_acc: 0.7604\n",
      "Epoch 2094/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4138 - acc: 0.8038 - val_loss: 0.5224 - val_acc: 0.7604\n",
      "Epoch 2095/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4139 - acc: 0.8038 - val_loss: 0.5225 - val_acc: 0.7604\n",
      "Epoch 2096/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4138 - acc: 0.8038 - val_loss: 0.5224 - val_acc: 0.7604\n",
      "Epoch 2097/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4138 - acc: 0.8038 - val_loss: 0.5224 - val_acc: 0.7604\n",
      "Epoch 2098/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4137 - acc: 0.8038 - val_loss: 0.5225 - val_acc: 0.7604\n",
      "Epoch 2099/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4137 - acc: 0.8038 - val_loss: 0.5225 - val_acc: 0.7604\n",
      "Epoch 2100/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4137 - acc: 0.8038 - val_loss: 0.5226 - val_acc: 0.7604\n",
      "Epoch 2101/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4137 - acc: 0.8038 - val_loss: 0.5226 - val_acc: 0.7604\n",
      "Epoch 2102/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4137 - acc: 0.8038 - val_loss: 0.5227 - val_acc: 0.7552\n",
      "Epoch 2103/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4136 - acc: 0.8038 - val_loss: 0.5227 - val_acc: 0.7552\n",
      "Epoch 2104/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4136 - acc: 0.8038 - val_loss: 0.5227 - val_acc: 0.7604\n",
      "Epoch 2105/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4136 - acc: 0.8038 - val_loss: 0.5228 - val_acc: 0.7552\n",
      "Epoch 2106/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4136 - acc: 0.8038 - val_loss: 0.5228 - val_acc: 0.7552\n",
      "Epoch 2107/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5228 - val_acc: 0.7552\n",
      "Epoch 2108/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4136 - acc: 0.8056 - val_loss: 0.5229 - val_acc: 0.7552\n",
      "Epoch 2109/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5229 - val_acc: 0.7552\n",
      "Epoch 2110/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5229 - val_acc: 0.7552\n",
      "Epoch 2111/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5229 - val_acc: 0.7552\n",
      "Epoch 2112/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4134 - acc: 0.8038 - val_loss: 0.5230 - val_acc: 0.7552\n",
      "Epoch 2113/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4134 - acc: 0.8038 - val_loss: 0.5231 - val_acc: 0.7552\n",
      "Epoch 2114/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5231 - val_acc: 0.7552\n",
      "Epoch 2115/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.5231 - val_acc: 0.7604\n",
      "Epoch 2116/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4134 - acc: 0.8038 - val_loss: 0.5232 - val_acc: 0.7604\n",
      "Epoch 2117/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4134 - acc: 0.8038 - val_loss: 0.5233 - val_acc: 0.7552\n",
      "Epoch 2118/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4134 - acc: 0.8038 - val_loss: 0.5232 - val_acc: 0.7552\n",
      "Epoch 2119/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4133 - acc: 0.8021 - val_loss: 0.5233 - val_acc: 0.7552\n",
      "Epoch 2120/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4133 - acc: 0.8038 - val_loss: 0.5234 - val_acc: 0.7552\n",
      "Epoch 2121/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4133 - acc: 0.8038 - val_loss: 0.5234 - val_acc: 0.7552\n",
      "Epoch 2122/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4133 - acc: 0.8038 - val_loss: 0.5234 - val_acc: 0.7552\n",
      "Epoch 2123/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4133 - acc: 0.8021 - val_loss: 0.5235 - val_acc: 0.7552\n",
      "Epoch 2124/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4133 - acc: 0.8038 - val_loss: 0.5236 - val_acc: 0.7552\n",
      "Epoch 2125/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4132 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7552\n",
      "Epoch 2126/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4132 - acc: 0.8021 - val_loss: 0.5236 - val_acc: 0.7552\n",
      "Epoch 2127/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4132 - acc: 0.8021 - val_loss: 0.5238 - val_acc: 0.7552\n",
      "Epoch 2128/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7552\n",
      "Epoch 2129/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7552\n",
      "Epoch 2130/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4132 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7552\n",
      "Epoch 2131/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5240 - val_acc: 0.7552\n",
      "Epoch 2132/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2133/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4131 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2134/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2135/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4130 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2136/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4130 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2137/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4130 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2138/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4130 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7552\n",
      "Epoch 2139/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4129 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7552\n",
      "Epoch 2140/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4129 - acc: 0.8038 - val_loss: 0.5243 - val_acc: 0.7552\n",
      "Epoch 2141/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4129 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7552\n",
      "Epoch 2142/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4129 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7552\n",
      "Epoch 2143/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4129 - acc: 0.8038 - val_loss: 0.5244 - val_acc: 0.7552\n",
      "Epoch 2144/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4128 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7552\n",
      "Epoch 2145/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4128 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7552\n",
      "Epoch 2146/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4128 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7552\n",
      "Epoch 2147/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4128 - acc: 0.8021 - val_loss: 0.5247 - val_acc: 0.7552\n",
      "Epoch 2148/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4128 - acc: 0.8038 - val_loss: 0.5248 - val_acc: 0.7552\n",
      "Epoch 2149/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4127 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7552\n",
      "Epoch 2150/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4127 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7552\n",
      "Epoch 2151/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4127 - acc: 0.8003 - val_loss: 0.5247 - val_acc: 0.7552\n",
      "Epoch 2152/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4127 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7552\n",
      "Epoch 2153/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5249 - val_acc: 0.7552\n",
      "Epoch 2154/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4126 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7552\n",
      "Epoch 2155/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4125 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7552\n",
      "Epoch 2156/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4126 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7552\n",
      "Epoch 2157/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5251 - val_acc: 0.7552\n",
      "Epoch 2158/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5251 - val_acc: 0.7552\n",
      "Epoch 2159/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5252 - val_acc: 0.7552\n",
      "Epoch 2160/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5252 - val_acc: 0.7552\n",
      "Epoch 2161/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4125 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7552\n",
      "Epoch 2162/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5253 - val_acc: 0.7552\n",
      "Epoch 2163/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5254 - val_acc: 0.7552\n",
      "Epoch 2164/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5254 - val_acc: 0.7552\n",
      "Epoch 2165/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5255 - val_acc: 0.7552\n",
      "Epoch 2166/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5255 - val_acc: 0.7552\n",
      "Epoch 2167/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5255 - val_acc: 0.7552\n",
      "Epoch 2168/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5256 - val_acc: 0.7552\n",
      "Epoch 2169/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5256 - val_acc: 0.7552\n",
      "Epoch 2170/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5256 - val_acc: 0.7552\n",
      "Epoch 2171/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5257 - val_acc: 0.7552\n",
      "Epoch 2172/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5257 - val_acc: 0.7552\n",
      "Epoch 2173/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5258 - val_acc: 0.7552\n",
      "Epoch 2174/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5258 - val_acc: 0.7552\n",
      "Epoch 2175/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5258 - val_acc: 0.7552\n",
      "Epoch 2176/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5259 - val_acc: 0.7552\n",
      "Epoch 2177/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5259 - val_acc: 0.7552\n",
      "Epoch 2178/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5260 - val_acc: 0.7552\n",
      "Epoch 2179/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5260 - val_acc: 0.7552\n",
      "Epoch 2180/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5259 - val_acc: 0.7552\n",
      "Epoch 2181/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5260 - val_acc: 0.7552\n",
      "Epoch 2182/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7552\n",
      "Epoch 2183/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4119 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7552\n",
      "Epoch 2184/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4119 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 2185/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 2186/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7552\n",
      "Epoch 2187/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7552\n",
      "Epoch 2188/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7552\n",
      "Epoch 2189/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7552\n",
      "Epoch 2190/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7552\n",
      "Epoch 2191/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4117 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7552\n",
      "Epoch 2192/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4117 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7552\n",
      "Epoch 2193/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4118 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7552\n",
      "Epoch 2194/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4117 - acc: 0.7986 - val_loss: 0.5267 - val_acc: 0.7552\n",
      "Epoch 2195/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4117 - acc: 0.7986 - val_loss: 0.5268 - val_acc: 0.7552\n",
      "Epoch 2196/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4117 - acc: 0.8003 - val_loss: 0.5268 - val_acc: 0.7552\n",
      "Epoch 2197/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5269 - val_acc: 0.7552\n",
      "Epoch 2198/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4117 - acc: 0.8003 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 2199/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4116 - acc: 0.8003 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 2200/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4116 - acc: 0.7986 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 2201/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4115 - acc: 0.8003 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 2202/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4116 - acc: 0.7986 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 2203/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4115 - acc: 0.8003 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 2204/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 2205/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4114 - acc: 0.7986 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 2206/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4115 - acc: 0.7986 - val_loss: 0.5273 - val_acc: 0.7552\n",
      "Epoch 2207/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4114 - acc: 0.7986 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 2208/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 2209/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 2210/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4113 - acc: 0.8003 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 2211/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4113 - acc: 0.7986 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 2212/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4112 - acc: 0.8003 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 2213/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 2214/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 2215/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4112 - acc: 0.8003 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 2216/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4112 - acc: 0.7969 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 2217/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 2218/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4111 - acc: 0.7986 - val_loss: 0.5279 - val_acc: 0.7552\n",
      "Epoch 2219/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4112 - acc: 0.8003 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 2220/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4111 - acc: 0.7986 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 2221/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4110 - acc: 0.7986 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 2222/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4110 - acc: 0.7986 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 2223/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4110 - acc: 0.8003 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 2224/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4110 - acc: 0.7986 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 2225/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4111 - acc: 0.7986 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 2226/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 2227/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 2228/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4109 - acc: 0.7986 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 2229/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4110 - acc: 0.7986 - val_loss: 0.5284 - val_acc: 0.7552\n",
      "Epoch 2230/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4109 - acc: 0.7986 - val_loss: 0.5285 - val_acc: 0.7552\n",
      "Epoch 2231/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4108 - acc: 0.7969 - val_loss: 0.5285 - val_acc: 0.7552\n",
      "Epoch 2232/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4108 - acc: 0.7969 - val_loss: 0.5286 - val_acc: 0.7552\n",
      "Epoch 2233/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4108 - acc: 0.7986 - val_loss: 0.5286 - val_acc: 0.7552\n",
      "Epoch 2234/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4107 - acc: 0.7986 - val_loss: 0.5287 - val_acc: 0.7552\n",
      "Epoch 2235/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4107 - acc: 0.7986 - val_loss: 0.5287 - val_acc: 0.7552\n",
      "Epoch 2236/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4108 - acc: 0.7969 - val_loss: 0.5288 - val_acc: 0.7552\n",
      "Epoch 2237/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4107 - acc: 0.7969 - val_loss: 0.5288 - val_acc: 0.7552\n",
      "Epoch 2238/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4107 - acc: 0.7986 - val_loss: 0.5288 - val_acc: 0.7552\n",
      "Epoch 2239/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4106 - acc: 0.7986 - val_loss: 0.5288 - val_acc: 0.7552\n",
      "Epoch 2240/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4106 - acc: 0.7969 - val_loss: 0.5288 - val_acc: 0.7552\n",
      "Epoch 2241/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4106 - acc: 0.7969 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 2242/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4106 - acc: 0.7986 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 2243/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4106 - acc: 0.7986 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 2244/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4106 - acc: 0.7969 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 2245/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4105 - acc: 0.7969 - val_loss: 0.5290 - val_acc: 0.7552\n",
      "Epoch 2246/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.5291 - val_acc: 0.7552\n",
      "Epoch 2247/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4105 - acc: 0.7986 - val_loss: 0.5291 - val_acc: 0.7552\n",
      "Epoch 2248/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.5291 - val_acc: 0.7552\n",
      "Epoch 2249/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.5292 - val_acc: 0.7552\n",
      "Epoch 2250/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.5292 - val_acc: 0.7552\n",
      "Epoch 2251/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.5292 - val_acc: 0.7552\n",
      "Epoch 2252/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4103 - acc: 0.7986 - val_loss: 0.5293 - val_acc: 0.7552\n",
      "Epoch 2253/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4103 - acc: 0.7986 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 2254/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 2255/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4102 - acc: 0.7986 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 2256/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4102 - acc: 0.7986 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 2257/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 2258/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4102 - acc: 0.7986 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 2259/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4102 - acc: 0.7986 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 2260/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 2261/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4101 - acc: 0.7986 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 2262/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4101 - acc: 0.7986 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 2263/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4100 - acc: 0.7969 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 2264/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 2265/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.5300 - val_acc: 0.7552\n",
      "Epoch 2266/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4101 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2267/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2268/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4099 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2269/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4099 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2270/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2271/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 2272/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 2273/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 2274/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 2275/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4098 - acc: 0.8003 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 2276/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5306 - val_acc: 0.7552\n",
      "Epoch 2277/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4098 - acc: 0.8003 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 2278/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5306 - val_acc: 0.7552\n",
      "Epoch 2279/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 2280/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 2281/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4096 - acc: 0.8003 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 2282/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4096 - acc: 0.8003 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 2283/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4095 - acc: 0.8021 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 2284/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4095 - acc: 0.8038 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 2285/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4095 - acc: 0.8021 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 2286/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4094 - acc: 0.8003 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 2287/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4094 - acc: 0.7986 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 2288/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4094 - acc: 0.8003 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 2289/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4095 - acc: 0.8003 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 2290/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4093 - acc: 0.8021 - val_loss: 0.5310 - val_acc: 0.7552\n",
      "Epoch 2291/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4093 - acc: 0.8021 - val_loss: 0.5311 - val_acc: 0.7552\n",
      "Epoch 2292/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4093 - acc: 0.8021 - val_loss: 0.5311 - val_acc: 0.7552\n",
      "Epoch 2293/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4092 - acc: 0.8021 - val_loss: 0.5311 - val_acc: 0.7552\n",
      "Epoch 2294/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4092 - acc: 0.8021 - val_loss: 0.5312 - val_acc: 0.7552\n",
      "Epoch 2295/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4092 - acc: 0.8021 - val_loss: 0.5313 - val_acc: 0.7552\n",
      "Epoch 2296/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4091 - acc: 0.8021 - val_loss: 0.5313 - val_acc: 0.7552\n",
      "Epoch 2297/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4091 - acc: 0.8021 - val_loss: 0.5314 - val_acc: 0.7552\n",
      "Epoch 2298/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4091 - acc: 0.8021 - val_loss: 0.5314 - val_acc: 0.7552\n",
      "Epoch 2299/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4091 - acc: 0.8003 - val_loss: 0.5315 - val_acc: 0.7552\n",
      "Epoch 2300/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4090 - acc: 0.8038 - val_loss: 0.5314 - val_acc: 0.7552\n",
      "Epoch 2301/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4090 - acc: 0.8021 - val_loss: 0.5315 - val_acc: 0.7552\n",
      "Epoch 2302/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4090 - acc: 0.8021 - val_loss: 0.5315 - val_acc: 0.7552\n",
      "Epoch 2303/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4090 - acc: 0.8021 - val_loss: 0.5315 - val_acc: 0.7552\n",
      "Epoch 2304/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4089 - acc: 0.8021 - val_loss: 0.5315 - val_acc: 0.7552\n",
      "Epoch 2305/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4089 - acc: 0.8021 - val_loss: 0.5316 - val_acc: 0.7552\n",
      "Epoch 2306/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4089 - acc: 0.8021 - val_loss: 0.5316 - val_acc: 0.7552\n",
      "Epoch 2307/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4089 - acc: 0.8021 - val_loss: 0.5317 - val_acc: 0.7552\n",
      "Epoch 2308/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4089 - acc: 0.8003 - val_loss: 0.5318 - val_acc: 0.7552\n",
      "Epoch 2309/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4088 - acc: 0.8021 - val_loss: 0.5319 - val_acc: 0.7552\n",
      "Epoch 2310/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4088 - acc: 0.8038 - val_loss: 0.5319 - val_acc: 0.7552\n",
      "Epoch 2311/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4088 - acc: 0.8021 - val_loss: 0.5320 - val_acc: 0.7552\n",
      "Epoch 2312/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4087 - acc: 0.8021 - val_loss: 0.5319 - val_acc: 0.7552\n",
      "Epoch 2313/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4087 - acc: 0.8003 - val_loss: 0.5318 - val_acc: 0.7552\n",
      "Epoch 2314/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4087 - acc: 0.8021 - val_loss: 0.5320 - val_acc: 0.7552\n",
      "Epoch 2315/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4087 - acc: 0.8021 - val_loss: 0.5320 - val_acc: 0.7552\n",
      "Epoch 2316/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4087 - acc: 0.8021 - val_loss: 0.5321 - val_acc: 0.7552\n",
      "Epoch 2317/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4087 - acc: 0.8003 - val_loss: 0.5322 - val_acc: 0.7552\n",
      "Epoch 2318/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4087 - acc: 0.8021 - val_loss: 0.5322 - val_acc: 0.7552\n",
      "Epoch 2319/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4086 - acc: 0.8021 - val_loss: 0.5322 - val_acc: 0.7552\n",
      "Epoch 2320/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4085 - acc: 0.8021 - val_loss: 0.5323 - val_acc: 0.7552\n",
      "Epoch 2321/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4086 - acc: 0.8021 - val_loss: 0.5322 - val_acc: 0.7552\n",
      "Epoch 2322/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4085 - acc: 0.8038 - val_loss: 0.5323 - val_acc: 0.7552\n",
      "Epoch 2323/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4085 - acc: 0.8003 - val_loss: 0.5324 - val_acc: 0.7552\n",
      "Epoch 2324/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4085 - acc: 0.8021 - val_loss: 0.5324 - val_acc: 0.7552\n",
      "Epoch 2325/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4084 - acc: 0.8021 - val_loss: 0.5325 - val_acc: 0.7552\n",
      "Epoch 2326/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4084 - acc: 0.8038 - val_loss: 0.5326 - val_acc: 0.7552\n",
      "Epoch 2327/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4084 - acc: 0.8038 - val_loss: 0.5326 - val_acc: 0.7552\n",
      "Epoch 2328/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4083 - acc: 0.8021 - val_loss: 0.5326 - val_acc: 0.7552\n",
      "Epoch 2329/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4084 - acc: 0.8003 - val_loss: 0.5327 - val_acc: 0.7552\n",
      "Epoch 2330/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4083 - acc: 0.8021 - val_loss: 0.5328 - val_acc: 0.7552\n",
      "Epoch 2331/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4083 - acc: 0.7986 - val_loss: 0.5327 - val_acc: 0.7552\n",
      "Epoch 2332/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4082 - acc: 0.8021 - val_loss: 0.5328 - val_acc: 0.7552\n",
      "Epoch 2333/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4082 - acc: 0.8003 - val_loss: 0.5328 - val_acc: 0.7552\n",
      "Epoch 2334/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4082 - acc: 0.8021 - val_loss: 0.5328 - val_acc: 0.7552\n",
      "Epoch 2335/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4082 - acc: 0.8021 - val_loss: 0.5328 - val_acc: 0.7552\n",
      "Epoch 2336/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4082 - acc: 0.8021 - val_loss: 0.5329 - val_acc: 0.7552\n",
      "Epoch 2337/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4082 - acc: 0.8021 - val_loss: 0.5330 - val_acc: 0.7552\n",
      "Epoch 2338/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5330 - val_acc: 0.7552\n",
      "Epoch 2339/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4082 - acc: 0.8003 - val_loss: 0.5330 - val_acc: 0.7552\n",
      "Epoch 2340/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4081 - acc: 0.8003 - val_loss: 0.5330 - val_acc: 0.7552\n",
      "Epoch 2341/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4081 - acc: 0.8021 - val_loss: 0.5331 - val_acc: 0.7552\n",
      "Epoch 2342/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5332 - val_acc: 0.7552\n",
      "Epoch 2343/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4081 - acc: 0.8003 - val_loss: 0.5332 - val_acc: 0.7552\n",
      "Epoch 2344/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4081 - acc: 0.7986 - val_loss: 0.5333 - val_acc: 0.7552\n",
      "Epoch 2345/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4080 - acc: 0.8021 - val_loss: 0.5333 - val_acc: 0.7552\n",
      "Epoch 2346/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4080 - acc: 0.8021 - val_loss: 0.5334 - val_acc: 0.7552\n",
      "Epoch 2347/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4081 - acc: 0.8003 - val_loss: 0.5334 - val_acc: 0.7552\n",
      "Epoch 2348/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4079 - acc: 0.8003 - val_loss: 0.5333 - val_acc: 0.7552\n",
      "Epoch 2349/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4079 - acc: 0.8003 - val_loss: 0.5334 - val_acc: 0.7552\n",
      "Epoch 2350/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5334 - val_acc: 0.7552\n",
      "Epoch 2351/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5333 - val_acc: 0.7552\n",
      "Epoch 2352/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4079 - acc: 0.8003 - val_loss: 0.5334 - val_acc: 0.7552\n",
      "Epoch 2353/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4078 - acc: 0.8003 - val_loss: 0.5335 - val_acc: 0.7552\n",
      "Epoch 2354/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4078 - acc: 0.8003 - val_loss: 0.5335 - val_acc: 0.7552\n",
      "Epoch 2355/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4078 - acc: 0.8003 - val_loss: 0.5336 - val_acc: 0.7552\n",
      "Epoch 2356/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5335 - val_acc: 0.7552\n",
      "Epoch 2357/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4078 - acc: 0.8003 - val_loss: 0.5337 - val_acc: 0.7552\n",
      "Epoch 2358/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4078 - acc: 0.7986 - val_loss: 0.5339 - val_acc: 0.7552\n",
      "Epoch 2359/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4077 - acc: 0.8021 - val_loss: 0.5339 - val_acc: 0.7552\n",
      "Epoch 2360/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4077 - acc: 0.8003 - val_loss: 0.5340 - val_acc: 0.7552\n",
      "Epoch 2361/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4079 - acc: 0.8003 - val_loss: 0.5341 - val_acc: 0.7552\n",
      "Epoch 2362/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4077 - acc: 0.8021 - val_loss: 0.5342 - val_acc: 0.7552\n",
      "Epoch 2363/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4077 - acc: 0.8003 - val_loss: 0.5342 - val_acc: 0.7552\n",
      "Epoch 2364/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4076 - acc: 0.8003 - val_loss: 0.5343 - val_acc: 0.7552\n",
      "Epoch 2365/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4076 - acc: 0.7986 - val_loss: 0.5344 - val_acc: 0.7552\n",
      "Epoch 2366/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5345 - val_acc: 0.7552\n",
      "Epoch 2367/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4076 - acc: 0.7986 - val_loss: 0.5345 - val_acc: 0.7552\n",
      "Epoch 2368/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5344 - val_acc: 0.7552\n",
      "Epoch 2369/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4076 - acc: 0.8003 - val_loss: 0.5343 - val_acc: 0.7552\n",
      "Epoch 2370/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4076 - acc: 0.8003 - val_loss: 0.5344 - val_acc: 0.7552\n",
      "Epoch 2371/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4075 - acc: 0.8003 - val_loss: 0.5345 - val_acc: 0.7552\n",
      "Epoch 2372/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4075 - acc: 0.8003 - val_loss: 0.5345 - val_acc: 0.7552\n",
      "Epoch 2373/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4075 - acc: 0.8003 - val_loss: 0.5345 - val_acc: 0.7552\n",
      "Epoch 2374/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4074 - acc: 0.8003 - val_loss: 0.5346 - val_acc: 0.7552\n",
      "Epoch 2375/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4075 - acc: 0.8003 - val_loss: 0.5348 - val_acc: 0.7552\n",
      "Epoch 2376/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4075 - acc: 0.7986 - val_loss: 0.5349 - val_acc: 0.7552\n",
      "Epoch 2377/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4073 - acc: 0.8003 - val_loss: 0.5348 - val_acc: 0.7552\n",
      "Epoch 2378/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4074 - acc: 0.8003 - val_loss: 0.5348 - val_acc: 0.7552\n",
      "Epoch 2379/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4073 - acc: 0.8021 - val_loss: 0.5349 - val_acc: 0.7552\n",
      "Epoch 2380/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4074 - acc: 0.8003 - val_loss: 0.5348 - val_acc: 0.7552\n",
      "Epoch 2381/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4073 - acc: 0.8003 - val_loss: 0.5350 - val_acc: 0.7552\n",
      "Epoch 2382/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4073 - acc: 0.8003 - val_loss: 0.5350 - val_acc: 0.7552\n",
      "Epoch 2383/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4072 - acc: 0.7986 - val_loss: 0.5350 - val_acc: 0.7552\n",
      "Epoch 2384/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4073 - acc: 0.8003 - val_loss: 0.5349 - val_acc: 0.7552\n",
      "Epoch 2385/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4072 - acc: 0.8003 - val_loss: 0.5349 - val_acc: 0.7552\n",
      "Epoch 2386/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4072 - acc: 0.8003 - val_loss: 0.5350 - val_acc: 0.7552\n",
      "Epoch 2387/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4071 - acc: 0.8003 - val_loss: 0.5351 - val_acc: 0.7552\n",
      "Epoch 2388/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4073 - acc: 0.7986 - val_loss: 0.5351 - val_acc: 0.7552\n",
      "Epoch 2389/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4073 - acc: 0.8038 - val_loss: 0.5354 - val_acc: 0.7552\n",
      "Epoch 2390/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4072 - acc: 0.8003 - val_loss: 0.5354 - val_acc: 0.7552\n",
      "Epoch 2391/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4071 - acc: 0.8003 - val_loss: 0.5355 - val_acc: 0.7552\n",
      "Epoch 2392/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4071 - acc: 0.8003 - val_loss: 0.5354 - val_acc: 0.7552\n",
      "Epoch 2393/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4071 - acc: 0.8003 - val_loss: 0.5355 - val_acc: 0.7552\n",
      "Epoch 2394/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4071 - acc: 0.8003 - val_loss: 0.5356 - val_acc: 0.7552\n",
      "Epoch 2395/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4072 - acc: 0.8003 - val_loss: 0.5356 - val_acc: 0.7552\n",
      "Epoch 2396/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4070 - acc: 0.8003 - val_loss: 0.5358 - val_acc: 0.7552\n",
      "Epoch 2397/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4071 - acc: 0.7986 - val_loss: 0.5357 - val_acc: 0.7552\n",
      "Epoch 2398/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4071 - acc: 0.7986 - val_loss: 0.5357 - val_acc: 0.7552\n",
      "Epoch 2399/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4070 - acc: 0.8021 - val_loss: 0.5359 - val_acc: 0.7552\n",
      "Epoch 2400/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4070 - acc: 0.7986 - val_loss: 0.5359 - val_acc: 0.7552\n",
      "Epoch 2401/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4069 - acc: 0.8003 - val_loss: 0.5360 - val_acc: 0.7552\n",
      "Epoch 2402/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4070 - acc: 0.8003 - val_loss: 0.5359 - val_acc: 0.7552\n",
      "Epoch 2403/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4068 - acc: 0.8003 - val_loss: 0.5361 - val_acc: 0.7552\n",
      "Epoch 2404/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4069 - acc: 0.8003 - val_loss: 0.5362 - val_acc: 0.7552\n",
      "Epoch 2405/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4069 - acc: 0.8003 - val_loss: 0.5362 - val_acc: 0.7552\n",
      "Epoch 2406/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4069 - acc: 0.8021 - val_loss: 0.5363 - val_acc: 0.7552\n",
      "Epoch 2407/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4068 - acc: 0.7986 - val_loss: 0.5361 - val_acc: 0.7552\n",
      "Epoch 2408/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4068 - acc: 0.8003 - val_loss: 0.5362 - val_acc: 0.7552\n",
      "Epoch 2409/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4068 - acc: 0.8003 - val_loss: 0.5362 - val_acc: 0.7552\n",
      "Epoch 2410/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4068 - acc: 0.8003 - val_loss: 0.5362 - val_acc: 0.7552\n",
      "Epoch 2411/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4068 - acc: 0.7986 - val_loss: 0.5363 - val_acc: 0.7552\n",
      "Epoch 2412/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4068 - acc: 0.8021 - val_loss: 0.5363 - val_acc: 0.7552\n",
      "Epoch 2413/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4067 - acc: 0.8003 - val_loss: 0.5364 - val_acc: 0.7552\n",
      "Epoch 2414/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4067 - acc: 0.8021 - val_loss: 0.5363 - val_acc: 0.7552\n",
      "Epoch 2415/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4067 - acc: 0.8038 - val_loss: 0.5364 - val_acc: 0.7552\n",
      "Epoch 2416/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4067 - acc: 0.8021 - val_loss: 0.5365 - val_acc: 0.7552\n",
      "Epoch 2417/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4066 - acc: 0.8003 - val_loss: 0.5365 - val_acc: 0.7552\n",
      "Epoch 2418/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4066 - acc: 0.8021 - val_loss: 0.5367 - val_acc: 0.7552\n",
      "Epoch 2419/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4067 - acc: 0.7969 - val_loss: 0.5367 - val_acc: 0.7552\n",
      "Epoch 2420/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4066 - acc: 0.8021 - val_loss: 0.5367 - val_acc: 0.7552\n",
      "Epoch 2421/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4066 - acc: 0.8021 - val_loss: 0.5369 - val_acc: 0.7552\n",
      "Epoch 2422/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4066 - acc: 0.8003 - val_loss: 0.5369 - val_acc: 0.7552\n",
      "Epoch 2423/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4066 - acc: 0.8021 - val_loss: 0.5370 - val_acc: 0.7552\n",
      "Epoch 2424/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4065 - acc: 0.8021 - val_loss: 0.5372 - val_acc: 0.7552\n",
      "Epoch 2425/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4065 - acc: 0.8021 - val_loss: 0.5372 - val_acc: 0.7552\n",
      "Epoch 2426/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4065 - acc: 0.8021 - val_loss: 0.5374 - val_acc: 0.7552\n",
      "Epoch 2427/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4064 - acc: 0.8021 - val_loss: 0.5373 - val_acc: 0.7552\n",
      "Epoch 2428/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4064 - acc: 0.8003 - val_loss: 0.5374 - val_acc: 0.7552\n",
      "Epoch 2429/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4064 - acc: 0.8003 - val_loss: 0.5375 - val_acc: 0.7552\n",
      "Epoch 2430/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 45us/step - loss: 0.4065 - acc: 0.8003 - val_loss: 0.5375 - val_acc: 0.7552\n",
      "Epoch 2431/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4064 - acc: 0.8021 - val_loss: 0.5376 - val_acc: 0.7552\n",
      "Epoch 2432/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4064 - acc: 0.8003 - val_loss: 0.5376 - val_acc: 0.7552\n",
      "Epoch 2433/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4064 - acc: 0.7986 - val_loss: 0.5376 - val_acc: 0.7552\n",
      "Epoch 2434/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - acc: 0.8003 - val_loss: 0.5376 - val_acc: 0.7552\n",
      "Epoch 2435/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4064 - acc: 0.8021 - val_loss: 0.5378 - val_acc: 0.7552\n",
      "Epoch 2436/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4063 - acc: 0.8021 - val_loss: 0.5379 - val_acc: 0.7500\n",
      "Epoch 2437/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4063 - acc: 0.8003 - val_loss: 0.5378 - val_acc: 0.7500\n",
      "Epoch 2438/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4063 - acc: 0.8003 - val_loss: 0.5378 - val_acc: 0.7500\n",
      "Epoch 2439/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4062 - acc: 0.8003 - val_loss: 0.5379 - val_acc: 0.7500\n",
      "Epoch 2440/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4063 - acc: 0.8021 - val_loss: 0.5379 - val_acc: 0.7500\n",
      "Epoch 2441/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4062 - acc: 0.8021 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 2442/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4062 - acc: 0.8003 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 2443/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4062 - acc: 0.8003 - val_loss: 0.5382 - val_acc: 0.7500\n",
      "Epoch 2444/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4062 - acc: 0.8021 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 2445/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4061 - acc: 0.7986 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 2446/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4061 - acc: 0.8038 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 2447/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4062 - acc: 0.8003 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 2448/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4061 - acc: 0.8003 - val_loss: 0.5384 - val_acc: 0.7500\n",
      "Epoch 2449/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4060 - acc: 0.8003 - val_loss: 0.5385 - val_acc: 0.7500\n",
      "Epoch 2450/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4060 - acc: 0.8021 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2451/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4061 - acc: 0.8003 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2452/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4060 - acc: 0.8003 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2453/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4060 - acc: 0.8021 - val_loss: 0.5385 - val_acc: 0.7500\n",
      "Epoch 2454/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4060 - acc: 0.8021 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2455/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4059 - acc: 0.8021 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2456/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4059 - acc: 0.8003 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2457/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4058 - acc: 0.8003 - val_loss: 0.5387 - val_acc: 0.7500\n",
      "Epoch 2458/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4059 - acc: 0.7986 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 2459/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4059 - acc: 0.8021 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 2460/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.7986 - val_loss: 0.5390 - val_acc: 0.7500\n",
      "Epoch 2461/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4059 - acc: 0.8003 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 2462/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.8021 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 2463/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.8021 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 2464/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4059 - acc: 0.8003 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 2465/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.7986 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 2466/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4057 - acc: 0.8003 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 2467/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4058 - acc: 0.8003 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 2468/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4057 - acc: 0.8021 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 2469/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4058 - acc: 0.7986 - val_loss: 0.5392 - val_acc: 0.7500\n",
      "Epoch 2470/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4057 - acc: 0.8003 - val_loss: 0.5394 - val_acc: 0.7500\n",
      "Epoch 2471/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4057 - acc: 0.8003 - val_loss: 0.5392 - val_acc: 0.7500\n",
      "Epoch 2472/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4056 - acc: 0.8021 - val_loss: 0.5394 - val_acc: 0.7500\n",
      "Epoch 2473/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4056 - acc: 0.7986 - val_loss: 0.5395 - val_acc: 0.7500\n",
      "Epoch 2474/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4056 - acc: 0.8003 - val_loss: 0.5395 - val_acc: 0.7500\n",
      "Epoch 2475/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4055 - acc: 0.8003 - val_loss: 0.5395 - val_acc: 0.7500\n",
      "Epoch 2476/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4056 - acc: 0.8003 - val_loss: 0.5396 - val_acc: 0.7500\n",
      "Epoch 2477/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4055 - acc: 0.7986 - val_loss: 0.5397 - val_acc: 0.7500\n",
      "Epoch 2478/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4055 - acc: 0.8021 - val_loss: 0.5399 - val_acc: 0.7500\n",
      "Epoch 2479/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4056 - acc: 0.8003 - val_loss: 0.5399 - val_acc: 0.7500\n",
      "Epoch 2480/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4055 - acc: 0.7986 - val_loss: 0.5399 - val_acc: 0.7500\n",
      "Epoch 2481/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5400 - val_acc: 0.7500\n",
      "Epoch 2482/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5400 - val_acc: 0.7500\n",
      "Epoch 2483/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4054 - acc: 0.8003 - val_loss: 0.5401 - val_acc: 0.7500\n",
      "Epoch 2484/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4055 - acc: 0.7986 - val_loss: 0.5400 - val_acc: 0.7500\n",
      "Epoch 2485/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5400 - val_acc: 0.7500\n",
      "Epoch 2486/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5401 - val_acc: 0.7500\n",
      "Epoch 2487/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5402 - val_acc: 0.7500\n",
      "Epoch 2488/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4054 - acc: 0.7986 - val_loss: 0.5402 - val_acc: 0.7500\n",
      "Epoch 2489/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4053 - acc: 0.7986 - val_loss: 0.5402 - val_acc: 0.7500\n",
      "Epoch 2490/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4053 - acc: 0.8003 - val_loss: 0.5404 - val_acc: 0.7500\n",
      "Epoch 2491/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4053 - acc: 0.7986 - val_loss: 0.5404 - val_acc: 0.7500\n",
      "Epoch 2492/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4053 - acc: 0.8003 - val_loss: 0.5404 - val_acc: 0.7500\n",
      "Epoch 2493/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4053 - acc: 0.7986 - val_loss: 0.5404 - val_acc: 0.7500\n",
      "Epoch 2494/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4052 - acc: 0.8003 - val_loss: 0.5405 - val_acc: 0.7500\n",
      "Epoch 2495/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4053 - acc: 0.8003 - val_loss: 0.5406 - val_acc: 0.7500\n",
      "Epoch 2496/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4052 - acc: 0.7986 - val_loss: 0.5406 - val_acc: 0.7500\n",
      "Epoch 2497/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4053 - acc: 0.8003 - val_loss: 0.5405 - val_acc: 0.7500\n",
      "Epoch 2498/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4052 - acc: 0.7986 - val_loss: 0.5405 - val_acc: 0.7500\n",
      "Epoch 2499/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4051 - acc: 0.7986 - val_loss: 0.5406 - val_acc: 0.7500\n",
      "Epoch 2500/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4052 - acc: 0.7986 - val_loss: 0.5406 - val_acc: 0.7500\n",
      "Epoch 2501/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4051 - acc: 0.7986 - val_loss: 0.5407 - val_acc: 0.7500\n",
      "Epoch 2502/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4051 - acc: 0.7986 - val_loss: 0.5407 - val_acc: 0.7448\n",
      "Epoch 2503/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4051 - acc: 0.7986 - val_loss: 0.5408 - val_acc: 0.7448\n",
      "Epoch 2504/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4050 - acc: 0.7986 - val_loss: 0.5407 - val_acc: 0.7448\n",
      "Epoch 2505/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4051 - acc: 0.8003 - val_loss: 0.5408 - val_acc: 0.7448\n",
      "Epoch 2506/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4051 - acc: 0.7986 - val_loss: 0.5409 - val_acc: 0.7448\n",
      "Epoch 2507/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4050 - acc: 0.7986 - val_loss: 0.5409 - val_acc: 0.7448\n",
      "Epoch 2508/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4050 - acc: 0.7986 - val_loss: 0.5410 - val_acc: 0.7448\n",
      "Epoch 2509/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4049 - acc: 0.7986 - val_loss: 0.5411 - val_acc: 0.7448\n",
      "Epoch 2510/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4050 - acc: 0.7986 - val_loss: 0.5411 - val_acc: 0.7448\n",
      "Epoch 2511/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4050 - acc: 0.7986 - val_loss: 0.5410 - val_acc: 0.7448\n",
      "Epoch 2512/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5411 - val_acc: 0.7448\n",
      "Epoch 2513/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4049 - acc: 0.7986 - val_loss: 0.5413 - val_acc: 0.7448\n",
      "Epoch 2514/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4049 - acc: 0.7986 - val_loss: 0.5413 - val_acc: 0.7448\n",
      "Epoch 2515/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4049 - acc: 0.7986 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 2516/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 2517/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 2518/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4048 - acc: 0.8003 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 2519/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 2520/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 2521/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 2522/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4048 - acc: 0.7986 - val_loss: 0.5416 - val_acc: 0.7448\n",
      "Epoch 2523/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5417 - val_acc: 0.7448\n",
      "Epoch 2524/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4047 - acc: 0.8003 - val_loss: 0.5417 - val_acc: 0.7448\n",
      "Epoch 2525/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5417 - val_acc: 0.7448\n",
      "Epoch 2526/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4046 - acc: 0.7986 - val_loss: 0.5418 - val_acc: 0.7448\n",
      "Epoch 2527/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5418 - val_acc: 0.7448\n",
      "Epoch 2528/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5418 - val_acc: 0.7448\n",
      "Epoch 2529/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 2530/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 2531/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4046 - acc: 0.7986 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 2532/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.5420 - val_acc: 0.7448\n",
      "Epoch 2533/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4046 - acc: 0.7986 - val_loss: 0.5421 - val_acc: 0.7448\n",
      "Epoch 2534/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4046 - acc: 0.7986 - val_loss: 0.5421 - val_acc: 0.7448\n",
      "Epoch 2535/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4045 - acc: 0.7986 - val_loss: 0.5421 - val_acc: 0.7448\n",
      "Epoch 2536/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4045 - acc: 0.7969 - val_loss: 0.5422 - val_acc: 0.7448\n",
      "Epoch 2537/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4045 - acc: 0.8003 - val_loss: 0.5423 - val_acc: 0.7448\n",
      "Epoch 2538/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4046 - acc: 0.7986 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 2539/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4045 - acc: 0.7969 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 2540/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4045 - acc: 0.7986 - val_loss: 0.5425 - val_acc: 0.7448\n",
      "Epoch 2541/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4045 - acc: 0.7969 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 2542/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4045 - acc: 0.7986 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 2543/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4045 - acc: 0.7986 - val_loss: 0.5425 - val_acc: 0.7448\n",
      "Epoch 2544/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4044 - acc: 0.8003 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 2545/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4046 - acc: 0.8003 - val_loss: 0.5425 - val_acc: 0.7448\n",
      "Epoch 2546/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4044 - acc: 0.8003 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 2547/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4044 - acc: 0.7986 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 2548/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.4044 - acc: 0.8003 - val_loss: 0.5427 - val_acc: 0.7448\n",
      "Epoch 2549/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4043 - acc: 0.7986 - val_loss: 0.5428 - val_acc: 0.7448\n",
      "Epoch 2550/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4044 - acc: 0.7986 - val_loss: 0.5428 - val_acc: 0.7448\n",
      "Epoch 2551/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4043 - acc: 0.7986 - val_loss: 0.5428 - val_acc: 0.7448\n",
      "Epoch 2552/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4043 - acc: 0.7969 - val_loss: 0.5430 - val_acc: 0.7448\n",
      "Epoch 2553/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4043 - acc: 0.7969 - val_loss: 0.5429 - val_acc: 0.7448\n",
      "Epoch 2554/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4043 - acc: 0.7969 - val_loss: 0.5430 - val_acc: 0.7448\n",
      "Epoch 2555/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4043 - acc: 0.7969 - val_loss: 0.5429 - val_acc: 0.7448\n",
      "Epoch 2556/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4043 - acc: 0.7986 - val_loss: 0.5430 - val_acc: 0.7448\n",
      "Epoch 2557/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4043 - acc: 0.7986 - val_loss: 0.5431 - val_acc: 0.7448\n",
      "Epoch 2558/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4042 - acc: 0.8003 - val_loss: 0.5432 - val_acc: 0.7448\n",
      "Epoch 2559/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4042 - acc: 0.8003 - val_loss: 0.5433 - val_acc: 0.7448\n",
      "Epoch 2560/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4041 - acc: 0.7969 - val_loss: 0.5431 - val_acc: 0.7448\n",
      "Epoch 2561/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4042 - acc: 0.7986 - val_loss: 0.5432 - val_acc: 0.7448\n",
      "Epoch 2562/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4042 - acc: 0.7986 - val_loss: 0.5433 - val_acc: 0.7448\n",
      "Epoch 2563/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4042 - acc: 0.7986 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 2564/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4041 - acc: 0.7969 - val_loss: 0.5433 - val_acc: 0.7448\n",
      "Epoch 2565/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4041 - acc: 0.7969 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 2566/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4041 - acc: 0.7969 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 2567/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4041 - acc: 0.7969 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 2568/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4041 - acc: 0.7986 - val_loss: 0.5432 - val_acc: 0.7448\n",
      "Epoch 2569/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5433 - val_acc: 0.7448\n",
      "Epoch 2570/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5435 - val_acc: 0.7448\n",
      "Epoch 2571/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5436 - val_acc: 0.7448\n",
      "Epoch 2572/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7969 - val_loss: 0.5436 - val_acc: 0.7448\n",
      "Epoch 2573/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5434 - val_acc: 0.7448\n",
      "Epoch 2574/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5436 - val_acc: 0.7448\n",
      "Epoch 2575/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.5436 - val_acc: 0.7448\n",
      "Epoch 2576/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4039 - acc: 0.7969 - val_loss: 0.5438 - val_acc: 0.7448\n",
      "Epoch 2577/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5437 - val_acc: 0.7448\n",
      "Epoch 2578/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2579/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4040 - acc: 0.7969 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2580/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - acc: 0.8003 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2581/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2582/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - acc: 0.8003 - val_loss: 0.5440 - val_acc: 0.7448\n",
      "Epoch 2583/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - acc: 0.8003 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2584/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5439 - val_acc: 0.7448\n",
      "Epoch 2585/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5440 - val_acc: 0.7448\n",
      "Epoch 2586/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - acc: 0.7986 - val_loss: 0.5441 - val_acc: 0.7448\n",
      "Epoch 2587/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5442 - val_acc: 0.7448\n",
      "Epoch 2588/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - acc: 0.7969 - val_loss: 0.5440 - val_acc: 0.7448\n",
      "Epoch 2589/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5441 - val_acc: 0.7448\n",
      "Epoch 2590/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4037 - acc: 0.8003 - val_loss: 0.5441 - val_acc: 0.7448\n",
      "Epoch 2591/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5442 - val_acc: 0.7448\n",
      "Epoch 2592/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5443 - val_acc: 0.7448\n",
      "Epoch 2593/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4037 - acc: 0.8003 - val_loss: 0.5443 - val_acc: 0.7448\n",
      "Epoch 2594/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5443 - val_acc: 0.7448\n",
      "Epoch 2595/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4037 - acc: 0.7986 - val_loss: 0.5441 - val_acc: 0.7448\n",
      "Epoch 2596/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4038 - acc: 0.8003 - val_loss: 0.5442 - val_acc: 0.7448\n",
      "Epoch 2597/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4036 - acc: 0.7986 - val_loss: 0.5442 - val_acc: 0.7448\n",
      "Epoch 2598/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4036 - acc: 0.8003 - val_loss: 0.5441 - val_acc: 0.7448\n",
      "Epoch 2599/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4036 - acc: 0.7986 - val_loss: 0.5442 - val_acc: 0.7448\n",
      "Epoch 2600/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4036 - acc: 0.7986 - val_loss: 0.5443 - val_acc: 0.7448\n",
      "Epoch 2601/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.5443 - val_acc: 0.7448\n",
      "Epoch 2602/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4036 - acc: 0.8003 - val_loss: 0.5444 - val_acc: 0.7448\n",
      "Epoch 2603/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5446 - val_acc: 0.7448\n",
      "Epoch 2604/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5445 - val_acc: 0.7448\n",
      "Epoch 2605/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5445 - val_acc: 0.7448\n",
      "Epoch 2606/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 2607/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5448 - val_acc: 0.7448\n",
      "Epoch 2608/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 2609/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4035 - acc: 0.7986 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 2610/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 2611/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4034 - acc: 0.7986 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 2612/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4034 - acc: 0.7986 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 2613/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 2614/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 2615/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5452 - val_acc: 0.7448\n",
      "Epoch 2616/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4034 - acc: 0.7986 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 2617/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4034 - acc: 0.7986 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 2618/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5452 - val_acc: 0.7448\n",
      "Epoch 2619/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2620/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 2621/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2622/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4033 - acc: 0.7986 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2623/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.7986 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2624/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.7986 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 2625/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4032 - acc: 0.8003 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 2626/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4033 - acc: 0.8003 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 2627/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.8003 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2628/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.8003 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2629/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.7986 - val_loss: 0.5452 - val_acc: 0.7448\n",
      "Epoch 2630/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.8003 - val_loss: 0.5453 - val_acc: 0.7448\n",
      "Epoch 2631/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4031 - acc: 0.8003 - val_loss: 0.5454 - val_acc: 0.7448\n",
      "Epoch 2632/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4031 - acc: 0.8003 - val_loss: 0.5455 - val_acc: 0.7448\n",
      "Epoch 2633/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4031 - acc: 0.7986 - val_loss: 0.5456 - val_acc: 0.7448\n",
      "Epoch 2634/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4031 - acc: 0.8021 - val_loss: 0.5455 - val_acc: 0.7448\n",
      "Epoch 2635/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4032 - acc: 0.8003 - val_loss: 0.5457 - val_acc: 0.7448\n",
      "Epoch 2636/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5457 - val_acc: 0.7448\n",
      "Epoch 2637/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5458 - val_acc: 0.7448\n",
      "Epoch 2638/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5456 - val_acc: 0.7448\n",
      "Epoch 2639/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5459 - val_acc: 0.7448\n",
      "Epoch 2640/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4030 - acc: 0.8003 - val_loss: 0.5459 - val_acc: 0.7448\n",
      "Epoch 2641/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5461 - val_acc: 0.7448\n",
      "Epoch 2642/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4031 - acc: 0.7986 - val_loss: 0.5462 - val_acc: 0.7448\n",
      "Epoch 2643/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4029 - acc: 0.8003 - val_loss: 0.5462 - val_acc: 0.7448\n",
      "Epoch 2644/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4029 - acc: 0.7986 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2645/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4030 - acc: 0.7986 - val_loss: 0.5462 - val_acc: 0.7448\n",
      "Epoch 2646/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4028 - acc: 0.8003 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2647/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4029 - acc: 0.7986 - val_loss: 0.5462 - val_acc: 0.7448\n",
      "Epoch 2648/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4028 - acc: 0.8003 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2649/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4028 - acc: 0.7986 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2650/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4028 - acc: 0.7986 - val_loss: 0.5464 - val_acc: 0.7448\n",
      "Epoch 2651/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4028 - acc: 0.7986 - val_loss: 0.5464 - val_acc: 0.7448\n",
      "Epoch 2652/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4028 - acc: 0.7986 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2653/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4028 - acc: 0.7986 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2654/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4028 - acc: 0.7969 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2655/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4028 - acc: 0.8021 - val_loss: 0.5463 - val_acc: 0.7448\n",
      "Epoch 2656/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4027 - acc: 0.7986 - val_loss: 0.5464 - val_acc: 0.7448\n",
      "Epoch 2657/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.7986 - val_loss: 0.5465 - val_acc: 0.7448\n",
      "Epoch 2658/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4027 - acc: 0.7986 - val_loss: 0.5465 - val_acc: 0.7448\n",
      "Epoch 2659/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4027 - acc: 0.7969 - val_loss: 0.5466 - val_acc: 0.7448\n",
      "Epoch 2660/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.8003 - val_loss: 0.5467 - val_acc: 0.7448\n",
      "Epoch 2661/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4027 - acc: 0.8003 - val_loss: 0.5466 - val_acc: 0.7448\n",
      "Epoch 2662/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4026 - acc: 0.7986 - val_loss: 0.5465 - val_acc: 0.7448\n",
      "Epoch 2663/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4025 - acc: 0.7986 - val_loss: 0.5465 - val_acc: 0.7448\n",
      "Epoch 2664/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4026 - acc: 0.7986 - val_loss: 0.5467 - val_acc: 0.7448\n",
      "Epoch 2665/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4025 - acc: 0.8003 - val_loss: 0.5467 - val_acc: 0.7448\n",
      "Epoch 2666/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.4025 - acc: 0.8003 - val_loss: 0.5467 - val_acc: 0.7448\n",
      "Epoch 2667/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4025 - acc: 0.8003 - val_loss: 0.5466 - val_acc: 0.7448\n",
      "Epoch 2668/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4024 - acc: 0.7986 - val_loss: 0.5467 - val_acc: 0.7448\n",
      "Epoch 2669/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4024 - acc: 0.7986 - val_loss: 0.5468 - val_acc: 0.7448\n",
      "Epoch 2670/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4024 - acc: 0.8003 - val_loss: 0.5468 - val_acc: 0.7448\n",
      "Epoch 2671/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4024 - acc: 0.7969 - val_loss: 0.5469 - val_acc: 0.7448\n",
      "Epoch 2672/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4023 - acc: 0.7986 - val_loss: 0.5469 - val_acc: 0.7448\n",
      "Epoch 2673/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4024 - acc: 0.7986 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 2674/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4023 - acc: 0.7986 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 2675/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4024 - acc: 0.7969 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 2676/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4024 - acc: 0.8003 - val_loss: 0.5474 - val_acc: 0.7396\n",
      "Epoch 2677/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4023 - acc: 0.7969 - val_loss: 0.5474 - val_acc: 0.7396\n",
      "Epoch 2678/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4023 - acc: 0.7969 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 2679/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4022 - acc: 0.7986 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 2680/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4023 - acc: 0.8003 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 2681/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4023 - acc: 0.7986 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 2682/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4022 - acc: 0.7986 - val_loss: 0.5475 - val_acc: 0.7396\n",
      "Epoch 2683/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4022 - acc: 0.7969 - val_loss: 0.5477 - val_acc: 0.7396\n",
      "Epoch 2684/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4022 - acc: 0.7986 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 2685/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4022 - acc: 0.7969 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 2686/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4021 - acc: 0.8003 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 2687/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4021 - acc: 0.8003 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 2688/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4021 - acc: 0.7986 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 2689/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4021 - acc: 0.7986 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 2690/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4021 - acc: 0.8003 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 2691/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4020 - acc: 0.7986 - val_loss: 0.5480 - val_acc: 0.7396\n",
      "Epoch 2692/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4022 - acc: 0.7969 - val_loss: 0.5482 - val_acc: 0.7396\n",
      "Epoch 2693/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4020 - acc: 0.7969 - val_loss: 0.5483 - val_acc: 0.7396\n",
      "Epoch 2694/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4020 - acc: 0.7986 - val_loss: 0.5482 - val_acc: 0.7396\n",
      "Epoch 2695/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4019 - acc: 0.8003 - val_loss: 0.5483 - val_acc: 0.7396\n",
      "Epoch 2696/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4019 - acc: 0.8003 - val_loss: 0.5483 - val_acc: 0.7396\n",
      "Epoch 2697/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4020 - acc: 0.8003 - val_loss: 0.5483 - val_acc: 0.7396\n",
      "Epoch 2698/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4019 - acc: 0.8003 - val_loss: 0.5483 - val_acc: 0.7396\n",
      "Epoch 2699/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4018 - acc: 0.8003 - val_loss: 0.5484 - val_acc: 0.7396\n",
      "Epoch 2700/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4019 - acc: 0.8003 - val_loss: 0.5484 - val_acc: 0.7396\n",
      "Epoch 2701/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4019 - acc: 0.8003 - val_loss: 0.5484 - val_acc: 0.7396\n",
      "Epoch 2702/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4018 - acc: 0.8003 - val_loss: 0.5485 - val_acc: 0.7396\n",
      "Epoch 2703/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4018 - acc: 0.7986 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 2704/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4018 - acc: 0.7986 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 2705/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4017 - acc: 0.7969 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 2706/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4017 - acc: 0.8003 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 2707/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5487 - val_acc: 0.7396\n",
      "Epoch 2708/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4017 - acc: 0.7986 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 2709/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5488 - val_acc: 0.7396\n",
      "Epoch 2710/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4017 - acc: 0.7969 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 2711/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 2712/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 2713/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 2714/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4015 - acc: 0.8003 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 2715/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 2716/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 2717/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4015 - acc: 0.8003 - val_loss: 0.5491 - val_acc: 0.7396\n",
      "Epoch 2718/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4015 - acc: 0.7986 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 2719/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4014 - acc: 0.7986 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 2720/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4014 - acc: 0.8003 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 2721/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4014 - acc: 0.8003 - val_loss: 0.5490 - val_acc: 0.7396\n",
      "Epoch 2722/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4013 - acc: 0.8003 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 2723/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4014 - acc: 0.7986 - val_loss: 0.5494 - val_acc: 0.7396\n",
      "Epoch 2724/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - acc: 0.8003 - val_loss: 0.5494 - val_acc: 0.7396\n",
      "Epoch 2725/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - acc: 0.7969 - val_loss: 0.5495 - val_acc: 0.7396\n",
      "Epoch 2726/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4013 - acc: 0.8003 - val_loss: 0.5494 - val_acc: 0.7396\n",
      "Epoch 2727/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4012 - acc: 0.7986 - val_loss: 0.5495 - val_acc: 0.7396\n",
      "Epoch 2728/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4012 - acc: 0.8003 - val_loss: 0.5495 - val_acc: 0.7396\n",
      "Epoch 2729/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4011 - acc: 0.7969 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2730/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4011 - acc: 0.8003 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2731/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4011 - acc: 0.8003 - val_loss: 0.5499 - val_acc: 0.7396\n",
      "Epoch 2732/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4010 - acc: 0.8021 - val_loss: 0.5495 - val_acc: 0.7396\n",
      "Epoch 2733/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4011 - acc: 0.7986 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2734/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4011 - acc: 0.8003 - val_loss: 0.5496 - val_acc: 0.7396\n",
      "Epoch 2735/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4010 - acc: 0.8003 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2736/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4010 - acc: 0.8003 - val_loss: 0.5498 - val_acc: 0.7396\n",
      "Epoch 2737/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4009 - acc: 0.8021 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2738/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4009 - acc: 0.8021 - val_loss: 0.5497 - val_acc: 0.7396\n",
      "Epoch 2739/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4009 - acc: 0.8003 - val_loss: 0.5499 - val_acc: 0.7396\n",
      "Epoch 2740/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4008 - acc: 0.8003 - val_loss: 0.5501 - val_acc: 0.7396\n",
      "Epoch 2741/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4009 - acc: 0.8003 - val_loss: 0.5501 - val_acc: 0.7396\n",
      "Epoch 2742/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4008 - acc: 0.8003 - val_loss: 0.5503 - val_acc: 0.7396\n",
      "Epoch 2743/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4008 - acc: 0.8003 - val_loss: 0.5502 - val_acc: 0.7396\n",
      "Epoch 2744/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4007 - acc: 0.8021 - val_loss: 0.5500 - val_acc: 0.7396\n",
      "Epoch 2745/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4008 - acc: 0.8003 - val_loss: 0.5500 - val_acc: 0.7396\n",
      "Epoch 2746/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4007 - acc: 0.7986 - val_loss: 0.5502 - val_acc: 0.7396\n",
      "Epoch 2747/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4007 - acc: 0.8003 - val_loss: 0.5503 - val_acc: 0.7396\n",
      "Epoch 2748/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4008 - acc: 0.7986 - val_loss: 0.5505 - val_acc: 0.7396\n",
      "Epoch 2749/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4007 - acc: 0.8003 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 2750/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4006 - acc: 0.8003 - val_loss: 0.5506 - val_acc: 0.7396\n",
      "Epoch 2751/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4006 - acc: 0.8021 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 2752/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4006 - acc: 0.7986 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 2753/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.5507 - val_acc: 0.7396\n",
      "Epoch 2754/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.5509 - val_acc: 0.7396\n",
      "Epoch 2755/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 2756/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 2757/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4004 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 2758/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4004 - acc: 0.8003 - val_loss: 0.5508 - val_acc: 0.7396\n",
      "Epoch 2759/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4004 - acc: 0.8003 - val_loss: 0.5510 - val_acc: 0.7396\n",
      "Epoch 2760/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4004 - acc: 0.7986 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 2761/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4003 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7396\n",
      "Epoch 2762/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4004 - acc: 0.8003 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 2763/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4004 - acc: 0.7969 - val_loss: 0.5513 - val_acc: 0.7396\n",
      "Epoch 2764/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4003 - acc: 0.8003 - val_loss: 0.5512 - val_acc: 0.7396\n",
      "Epoch 2765/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4003 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7396\n",
      "Epoch 2766/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4003 - acc: 0.7986 - val_loss: 0.5515 - val_acc: 0.7396\n",
      "Epoch 2767/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4002 - acc: 0.8003 - val_loss: 0.5515 - val_acc: 0.7396\n",
      "Epoch 2768/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4003 - acc: 0.8003 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2769/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4002 - acc: 0.8003 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2770/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4002 - acc: 0.8003 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2771/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4001 - acc: 0.8003 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2772/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4001 - acc: 0.7986 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2773/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4001 - acc: 0.8003 - val_loss: 0.5516 - val_acc: 0.7396\n",
      "Epoch 2774/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4001 - acc: 0.7986 - val_loss: 0.5519 - val_acc: 0.7396\n",
      "Epoch 2775/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4001 - acc: 0.8003 - val_loss: 0.5517 - val_acc: 0.7396\n",
      "Epoch 2776/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4000 - acc: 0.8003 - val_loss: 0.5518 - val_acc: 0.7396\n",
      "Epoch 2777/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4001 - acc: 0.8003 - val_loss: 0.5518 - val_acc: 0.7396\n",
      "Epoch 2778/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3999 - acc: 0.8003 - val_loss: 0.5517 - val_acc: 0.7396\n",
      "Epoch 2779/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4000 - acc: 0.7986 - val_loss: 0.5518 - val_acc: 0.7396\n",
      "Epoch 2780/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3999 - acc: 0.7986 - val_loss: 0.5520 - val_acc: 0.7396\n",
      "Epoch 2781/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3999 - acc: 0.7969 - val_loss: 0.5522 - val_acc: 0.7396\n",
      "Epoch 2782/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3999 - acc: 0.7986 - val_loss: 0.5523 - val_acc: 0.7396\n",
      "Epoch 2783/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3999 - acc: 0.7986 - val_loss: 0.5524 - val_acc: 0.7396\n",
      "Epoch 2784/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.3999 - acc: 0.8003 - val_loss: 0.5525 - val_acc: 0.7396\n",
      "Epoch 2785/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3999 - acc: 0.7969 - val_loss: 0.5524 - val_acc: 0.7396\n",
      "Epoch 2786/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5523 - val_acc: 0.7396\n",
      "Epoch 2787/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3998 - acc: 0.7969 - val_loss: 0.5525 - val_acc: 0.7396\n",
      "Epoch 2788/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5526 - val_acc: 0.7396\n",
      "Epoch 2789/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5528 - val_acc: 0.7396\n",
      "Epoch 2790/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5527 - val_acc: 0.7396\n",
      "Epoch 2791/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5526 - val_acc: 0.7396\n",
      "Epoch 2792/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3997 - acc: 0.7986 - val_loss: 0.5527 - val_acc: 0.7396\n",
      "Epoch 2793/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3997 - acc: 0.8003 - val_loss: 0.5529 - val_acc: 0.7396\n",
      "Epoch 2794/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3997 - acc: 0.7986 - val_loss: 0.5528 - val_acc: 0.7396\n",
      "Epoch 2795/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3998 - acc: 0.8003 - val_loss: 0.5528 - val_acc: 0.7396\n",
      "Epoch 2796/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3996 - acc: 0.8021 - val_loss: 0.5528 - val_acc: 0.7396\n",
      "Epoch 2797/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3996 - acc: 0.8021 - val_loss: 0.5530 - val_acc: 0.7396\n",
      "Epoch 2798/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3997 - acc: 0.8003 - val_loss: 0.5529 - val_acc: 0.7396\n",
      "Epoch 2799/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3995 - acc: 0.8021 - val_loss: 0.5531 - val_acc: 0.7396\n",
      "Epoch 2800/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3996 - acc: 0.8003 - val_loss: 0.5529 - val_acc: 0.7396\n",
      "Epoch 2801/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3995 - acc: 0.8003 - val_loss: 0.5529 - val_acc: 0.7396\n",
      "Epoch 2802/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3995 - acc: 0.8003 - val_loss: 0.5530 - val_acc: 0.7396\n",
      "Epoch 2803/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3995 - acc: 0.8003 - val_loss: 0.5532 - val_acc: 0.7396\n",
      "Epoch 2804/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3994 - acc: 0.7986 - val_loss: 0.5531 - val_acc: 0.7396\n",
      "Epoch 2805/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3994 - acc: 0.8003 - val_loss: 0.5533 - val_acc: 0.7396\n",
      "Epoch 2806/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3994 - acc: 0.8003 - val_loss: 0.5532 - val_acc: 0.7396\n",
      "Epoch 2807/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3994 - acc: 0.7986 - val_loss: 0.5534 - val_acc: 0.7396\n",
      "Epoch 2808/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3994 - acc: 0.8003 - val_loss: 0.5534 - val_acc: 0.7396\n",
      "Epoch 2809/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - acc: 0.8003 - val_loss: 0.5536 - val_acc: 0.7396\n",
      "Epoch 2810/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3993 - acc: 0.8021 - val_loss: 0.5535 - val_acc: 0.7396\n",
      "Epoch 2811/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - acc: 0.8021 - val_loss: 0.5536 - val_acc: 0.7396\n",
      "Epoch 2812/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3994 - acc: 0.7969 - val_loss: 0.5536 - val_acc: 0.7396\n",
      "Epoch 2813/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - acc: 0.8021 - val_loss: 0.5538 - val_acc: 0.7396\n",
      "Epoch 2814/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3992 - acc: 0.8021 - val_loss: 0.5536 - val_acc: 0.7396\n",
      "Epoch 2815/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - acc: 0.7986 - val_loss: 0.5537 - val_acc: 0.7396\n",
      "Epoch 2816/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3993 - acc: 0.8003 - val_loss: 0.5537 - val_acc: 0.7396\n",
      "Epoch 2817/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3992 - acc: 0.8021 - val_loss: 0.5537 - val_acc: 0.7396\n",
      "Epoch 2818/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3992 - acc: 0.7986 - val_loss: 0.5538 - val_acc: 0.7396\n",
      "Epoch 2819/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3992 - acc: 0.7969 - val_loss: 0.5539 - val_acc: 0.7396\n",
      "Epoch 2820/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3991 - acc: 0.8021 - val_loss: 0.5540 - val_acc: 0.7396\n",
      "Epoch 2821/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3991 - acc: 0.8003 - val_loss: 0.5540 - val_acc: 0.7396\n",
      "Epoch 2822/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3991 - acc: 0.8003 - val_loss: 0.5542 - val_acc: 0.7396\n",
      "Epoch 2823/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3991 - acc: 0.8003 - val_loss: 0.5541 - val_acc: 0.7396\n",
      "Epoch 2824/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3991 - acc: 0.8003 - val_loss: 0.5541 - val_acc: 0.7396\n",
      "Epoch 2825/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3991 - acc: 0.7986 - val_loss: 0.5542 - val_acc: 0.7396\n",
      "Epoch 2826/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3990 - acc: 0.8003 - val_loss: 0.5543 - val_acc: 0.7396\n",
      "Epoch 2827/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3991 - acc: 0.8003 - val_loss: 0.5543 - val_acc: 0.7396\n",
      "Epoch 2828/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3990 - acc: 0.7986 - val_loss: 0.5544 - val_acc: 0.7396\n",
      "Epoch 2829/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3990 - acc: 0.8003 - val_loss: 0.5545 - val_acc: 0.7396\n",
      "Epoch 2830/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.8021 - val_loss: 0.5545 - val_acc: 0.7396\n",
      "Epoch 2831/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.8021 - val_loss: 0.5546 - val_acc: 0.7396\n",
      "Epoch 2832/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3990 - acc: 0.7986 - val_loss: 0.5548 - val_acc: 0.7396\n",
      "Epoch 2833/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3989 - acc: 0.7986 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2834/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.7986 - val_loss: 0.5545 - val_acc: 0.7396\n",
      "Epoch 2835/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3989 - acc: 0.8003 - val_loss: 0.5548 - val_acc: 0.7396\n",
      "Epoch 2836/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3988 - acc: 0.8003 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2837/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3988 - acc: 0.8003 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2838/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3987 - acc: 0.7986 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2839/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3988 - acc: 0.7986 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2840/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3988 - acc: 0.8003 - val_loss: 0.5548 - val_acc: 0.7396\n",
      "Epoch 2841/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3987 - acc: 0.8003 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 2842/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3986 - acc: 0.8021 - val_loss: 0.5546 - val_acc: 0.7396\n",
      "Epoch 2843/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3987 - acc: 0.8021 - val_loss: 0.5550 - val_acc: 0.7396\n",
      "Epoch 2844/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3986 - acc: 0.8021 - val_loss: 0.5549 - val_acc: 0.7396\n",
      "Epoch 2845/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3987 - acc: 0.8021 - val_loss: 0.5548 - val_acc: 0.7396\n",
      "Epoch 2846/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3988 - acc: 0.8003 - val_loss: 0.5551 - val_acc: 0.7396\n",
      "Epoch 2847/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3986 - acc: 0.8021 - val_loss: 0.5550 - val_acc: 0.7396\n",
      "Epoch 2848/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3985 - acc: 0.8003 - val_loss: 0.5551 - val_acc: 0.7396\n",
      "Epoch 2849/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3985 - acc: 0.8003 - val_loss: 0.5553 - val_acc: 0.7396\n",
      "Epoch 2850/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8021 - val_loss: 0.5554 - val_acc: 0.7396\n",
      "Epoch 2851/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.7986 - val_loss: 0.5553 - val_acc: 0.7396\n",
      "Epoch 2852/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3986 - acc: 0.7986 - val_loss: 0.5553 - val_acc: 0.7396\n",
      "Epoch 2853/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3985 - acc: 0.8021 - val_loss: 0.5556 - val_acc: 0.7396\n",
      "Epoch 2854/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8021 - val_loss: 0.5555 - val_acc: 0.7396\n",
      "Epoch 2855/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8021 - val_loss: 0.5555 - val_acc: 0.7396\n",
      "Epoch 2856/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3984 - acc: 0.8003 - val_loss: 0.5555 - val_acc: 0.7396\n",
      "Epoch 2857/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3985 - acc: 0.8003 - val_loss: 0.5552 - val_acc: 0.7396\n",
      "Epoch 2858/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3985 - acc: 0.8021 - val_loss: 0.5555 - val_acc: 0.7396\n",
      "Epoch 2859/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3984 - acc: 0.8021 - val_loss: 0.5557 - val_acc: 0.7396\n",
      "Epoch 2860/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3984 - acc: 0.8003 - val_loss: 0.5557 - val_acc: 0.7396\n",
      "Epoch 2861/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.7986 - val_loss: 0.5557 - val_acc: 0.7396\n",
      "Epoch 2862/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3984 - acc: 0.8021 - val_loss: 0.5559 - val_acc: 0.7396\n",
      "Epoch 2863/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8003 - val_loss: 0.5557 - val_acc: 0.7396\n",
      "Epoch 2864/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3983 - acc: 0.8021 - val_loss: 0.5558 - val_acc: 0.7396\n",
      "Epoch 2865/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3982 - acc: 0.7986 - val_loss: 0.5557 - val_acc: 0.7396\n",
      "Epoch 2866/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3982 - acc: 0.8003 - val_loss: 0.5559 - val_acc: 0.7396\n",
      "Epoch 2867/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3982 - acc: 0.8021 - val_loss: 0.5559 - val_acc: 0.7396\n",
      "Epoch 2868/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3982 - acc: 0.8003 - val_loss: 0.5559 - val_acc: 0.7396\n",
      "Epoch 2869/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3982 - acc: 0.8021 - val_loss: 0.5561 - val_acc: 0.7396\n",
      "Epoch 2870/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8003 - val_loss: 0.5561 - val_acc: 0.7396\n",
      "Epoch 2871/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8021 - val_loss: 0.5563 - val_acc: 0.7396\n",
      "Epoch 2872/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8021 - val_loss: 0.5564 - val_acc: 0.7396\n",
      "Epoch 2873/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8003 - val_loss: 0.5560 - val_acc: 0.7396\n",
      "Epoch 2874/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3981 - acc: 0.8021 - val_loss: 0.5561 - val_acc: 0.7396\n",
      "Epoch 2875/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3981 - acc: 0.8021 - val_loss: 0.5561 - val_acc: 0.7396\n",
      "Epoch 2876/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8003 - val_loss: 0.5562 - val_acc: 0.7396\n",
      "Epoch 2877/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3981 - acc: 0.8003 - val_loss: 0.5563 - val_acc: 0.7396\n",
      "Epoch 2878/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3980 - acc: 0.8021 - val_loss: 0.5563 - val_acc: 0.7396\n",
      "Epoch 2879/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3980 - acc: 0.8003 - val_loss: 0.5565 - val_acc: 0.7396\n",
      "Epoch 2880/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3981 - acc: 0.8021 - val_loss: 0.5568 - val_acc: 0.7396\n",
      "Epoch 2881/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3979 - acc: 0.8003 - val_loss: 0.5565 - val_acc: 0.7396\n",
      "Epoch 2882/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3979 - acc: 0.8021 - val_loss: 0.5567 - val_acc: 0.7396\n",
      "Epoch 2883/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3980 - acc: 0.8003 - val_loss: 0.5569 - val_acc: 0.7396\n",
      "Epoch 2884/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3980 - acc: 0.8021 - val_loss: 0.5569 - val_acc: 0.7396\n",
      "Epoch 2885/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3979 - acc: 0.8021 - val_loss: 0.5568 - val_acc: 0.7396\n",
      "Epoch 2886/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3979 - acc: 0.8021 - val_loss: 0.5568 - val_acc: 0.7396\n",
      "Epoch 2887/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3979 - acc: 0.8021 - val_loss: 0.5569 - val_acc: 0.7396\n",
      "Epoch 2888/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3978 - acc: 0.8021 - val_loss: 0.5569 - val_acc: 0.7396\n",
      "Epoch 2889/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3978 - acc: 0.8003 - val_loss: 0.5572 - val_acc: 0.7396\n",
      "Epoch 2890/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3979 - acc: 0.8038 - val_loss: 0.5570 - val_acc: 0.7396\n",
      "Epoch 2891/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3977 - acc: 0.8021 - val_loss: 0.5572 - val_acc: 0.7396\n",
      "Epoch 2892/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8003 - val_loss: 0.5572 - val_acc: 0.7396\n",
      "Epoch 2893/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3977 - acc: 0.8038 - val_loss: 0.5571 - val_acc: 0.7396\n",
      "Epoch 2894/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5575 - val_acc: 0.7396\n",
      "Epoch 2895/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5574 - val_acc: 0.7396\n",
      "Epoch 2896/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8003 - val_loss: 0.5574 - val_acc: 0.7396\n",
      "Epoch 2897/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5574 - val_acc: 0.7396\n",
      "Epoch 2898/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5575 - val_acc: 0.7396\n",
      "Epoch 2899/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3978 - acc: 0.8003 - val_loss: 0.5578 - val_acc: 0.7396\n",
      "Epoch 2900/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5577 - val_acc: 0.7396\n",
      "Epoch 2901/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3976 - acc: 0.8003 - val_loss: 0.5574 - val_acc: 0.7396\n",
      "Epoch 2902/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 0.8021 - val_loss: 0.5575 - val_acc: 0.7396\n",
      "Epoch 2903/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5575 - val_acc: 0.7344\n",
      "Epoch 2904/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5577 - val_acc: 0.7344\n",
      "Epoch 2905/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 0.8003 - val_loss: 0.5580 - val_acc: 0.7344\n",
      "Epoch 2906/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 0.8038 - val_loss: 0.5577 - val_acc: 0.7396\n",
      "Epoch 2907/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3975 - acc: 0.8021 - val_loss: 0.5578 - val_acc: 0.7344\n",
      "Epoch 2908/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3976 - acc: 0.8021 - val_loss: 0.5578 - val_acc: 0.7344\n",
      "Epoch 2909/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 0.8021 - val_loss: 0.5578 - val_acc: 0.7344\n",
      "Epoch 2910/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3974 - acc: 0.8021 - val_loss: 0.5580 - val_acc: 0.7344\n",
      "Epoch 2911/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3974 - acc: 0.8021 - val_loss: 0.5581 - val_acc: 0.7344\n",
      "Epoch 2912/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3974 - acc: 0.8003 - val_loss: 0.5580 - val_acc: 0.7344\n",
      "Epoch 2913/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3974 - acc: 0.8003 - val_loss: 0.5582 - val_acc: 0.7344\n",
      "Epoch 2914/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3974 - acc: 0.8003 - val_loss: 0.5583 - val_acc: 0.7344\n",
      "Epoch 2915/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 0.8003 - val_loss: 0.5584 - val_acc: 0.7344\n",
      "Epoch 2916/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3974 - acc: 0.8003 - val_loss: 0.5584 - val_acc: 0.7344\n",
      "Epoch 2917/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3974 - acc: 0.8003 - val_loss: 0.5585 - val_acc: 0.7344\n",
      "Epoch 2918/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3973 - acc: 0.8003 - val_loss: 0.5586 - val_acc: 0.7344\n",
      "Epoch 2919/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3973 - acc: 0.8003 - val_loss: 0.5586 - val_acc: 0.7344\n",
      "Epoch 2920/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3972 - acc: 0.8021 - val_loss: 0.5587 - val_acc: 0.7344\n",
      "Epoch 2921/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3972 - acc: 0.8021 - val_loss: 0.5585 - val_acc: 0.7344\n",
      "Epoch 2922/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3973 - acc: 0.8003 - val_loss: 0.5585 - val_acc: 0.7344\n",
      "Epoch 2923/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3973 - acc: 0.8003 - val_loss: 0.5587 - val_acc: 0.7292\n",
      "Epoch 2924/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3972 - acc: 0.8056 - val_loss: 0.5587 - val_acc: 0.7344\n",
      "Epoch 2925/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3971 - acc: 0.8038 - val_loss: 0.5587 - val_acc: 0.7344\n",
      "Epoch 2926/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3972 - acc: 0.8003 - val_loss: 0.5589 - val_acc: 0.7344\n",
      "Epoch 2927/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3971 - acc: 0.8021 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 2928/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3971 - acc: 0.8038 - val_loss: 0.5589 - val_acc: 0.7292\n",
      "Epoch 2929/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3971 - acc: 0.8021 - val_loss: 0.5587 - val_acc: 0.7344\n",
      "Epoch 2930/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3972 - acc: 0.8021 - val_loss: 0.5585 - val_acc: 0.7344\n",
      "Epoch 2931/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3971 - acc: 0.8038 - val_loss: 0.5586 - val_acc: 0.7344\n",
      "Epoch 2932/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3971 - acc: 0.8021 - val_loss: 0.5588 - val_acc: 0.7292\n",
      "Epoch 2933/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3971 - acc: 0.8021 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 2934/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3971 - acc: 0.8021 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 2935/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3970 - acc: 0.8003 - val_loss: 0.5592 - val_acc: 0.7292\n",
      "Epoch 2936/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3970 - acc: 0.8038 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 2937/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3970 - acc: 0.8003 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 2938/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3969 - acc: 0.8056 - val_loss: 0.5592 - val_acc: 0.7292\n",
      "Epoch 2939/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3970 - acc: 0.8003 - val_loss: 0.5594 - val_acc: 0.7292\n",
      "Epoch 2940/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3969 - acc: 0.8021 - val_loss: 0.5595 - val_acc: 0.7292\n",
      "Epoch 2941/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3970 - acc: 0.8021 - val_loss: 0.5596 - val_acc: 0.7292\n",
      "Epoch 2942/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3970 - acc: 0.8003 - val_loss: 0.5595 - val_acc: 0.7292\n",
      "Epoch 2943/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3969 - acc: 0.8003 - val_loss: 0.5595 - val_acc: 0.7292\n",
      "Epoch 2944/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3969 - acc: 0.8003 - val_loss: 0.5597 - val_acc: 0.7292\n",
      "Epoch 2945/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3968 - acc: 0.8021 - val_loss: 0.5597 - val_acc: 0.7292\n",
      "Epoch 2946/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3969 - acc: 0.8021 - val_loss: 0.5599 - val_acc: 0.7292\n",
      "Epoch 2947/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3968 - acc: 0.8038 - val_loss: 0.5600 - val_acc: 0.7292\n",
      "Epoch 2948/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3969 - acc: 0.8021 - val_loss: 0.5601 - val_acc: 0.7292\n",
      "Epoch 2949/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3968 - acc: 0.8021 - val_loss: 0.5599 - val_acc: 0.7292\n",
      "Epoch 2950/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3968 - acc: 0.8038 - val_loss: 0.5601 - val_acc: 0.7292\n",
      "Epoch 2951/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5603 - val_acc: 0.7292\n",
      "Epoch 2952/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5603 - val_acc: 0.7292\n",
      "Epoch 2953/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5602 - val_acc: 0.7292\n",
      "Epoch 2954/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3968 - acc: 0.8038 - val_loss: 0.5601 - val_acc: 0.7292\n",
      "Epoch 2955/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3967 - acc: 0.8003 - val_loss: 0.5602 - val_acc: 0.7292\n",
      "Epoch 2956/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5605 - val_acc: 0.7292\n",
      "Epoch 2957/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3968 - acc: 0.8021 - val_loss: 0.5605 - val_acc: 0.7292\n",
      "Epoch 2958/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5607 - val_acc: 0.7292\n",
      "Epoch 2959/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3966 - acc: 0.8038 - val_loss: 0.5608 - val_acc: 0.7292\n",
      "Epoch 2960/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3966 - acc: 0.8021 - val_loss: 0.5606 - val_acc: 0.7292\n",
      "Epoch 2961/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3966 - acc: 0.8021 - val_loss: 0.5606 - val_acc: 0.7292\n",
      "Epoch 2962/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3967 - acc: 0.8021 - val_loss: 0.5608 - val_acc: 0.7292\n",
      "Epoch 2963/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3966 - acc: 0.8038 - val_loss: 0.5607 - val_acc: 0.7292\n",
      "Epoch 2964/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3967 - acc: 0.8003 - val_loss: 0.5609 - val_acc: 0.7292\n",
      "Epoch 2965/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3965 - acc: 0.8021 - val_loss: 0.5609 - val_acc: 0.7292\n",
      "Epoch 2966/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3966 - acc: 0.8003 - val_loss: 0.5609 - val_acc: 0.7292\n",
      "Epoch 2967/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3966 - acc: 0.8038 - val_loss: 0.5611 - val_acc: 0.7292\n",
      "Epoch 2968/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3964 - acc: 0.8021 - val_loss: 0.5610 - val_acc: 0.7292\n",
      "Epoch 2969/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3966 - acc: 0.8021 - val_loss: 0.5608 - val_acc: 0.7292\n",
      "Epoch 2970/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3964 - acc: 0.8003 - val_loss: 0.5609 - val_acc: 0.7292\n",
      "Epoch 2971/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3965 - acc: 0.8038 - val_loss: 0.5608 - val_acc: 0.7292\n",
      "Epoch 2972/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3965 - acc: 0.8021 - val_loss: 0.5611 - val_acc: 0.7292\n",
      "Epoch 2973/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3964 - acc: 0.8021 - val_loss: 0.5612 - val_acc: 0.7292\n",
      "Epoch 2974/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3964 - acc: 0.8038 - val_loss: 0.5612 - val_acc: 0.7292\n",
      "Epoch 2975/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3964 - acc: 0.8021 - val_loss: 0.5614 - val_acc: 0.7292\n",
      "Epoch 2976/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3964 - acc: 0.8038 - val_loss: 0.5612 - val_acc: 0.7292\n",
      "Epoch 2977/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3964 - acc: 0.8021 - val_loss: 0.5615 - val_acc: 0.7292\n",
      "Epoch 2978/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3965 - acc: 0.8021 - val_loss: 0.5618 - val_acc: 0.7292\n",
      "Epoch 2979/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3963 - acc: 0.8021 - val_loss: 0.5616 - val_acc: 0.7292\n",
      "Epoch 2980/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3963 - acc: 0.8021 - val_loss: 0.5616 - val_acc: 0.7292\n",
      "Epoch 2981/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3963 - acc: 0.8021 - val_loss: 0.5617 - val_acc: 0.7292\n",
      "Epoch 2982/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3962 - acc: 0.8038 - val_loss: 0.5616 - val_acc: 0.7292\n",
      "Epoch 2983/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3963 - acc: 0.8021 - val_loss: 0.5616 - val_acc: 0.7292\n",
      "Epoch 2984/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3962 - acc: 0.8021 - val_loss: 0.5618 - val_acc: 0.7292\n",
      "Epoch 2985/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3962 - acc: 0.8021 - val_loss: 0.5618 - val_acc: 0.7292\n",
      "Epoch 2986/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3962 - acc: 0.8038 - val_loss: 0.5619 - val_acc: 0.7292\n",
      "Epoch 2987/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3962 - acc: 0.8038 - val_loss: 0.5618 - val_acc: 0.7292\n",
      "Epoch 2988/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3961 - acc: 0.8021 - val_loss: 0.5618 - val_acc: 0.7292\n",
      "Epoch 2989/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3961 - acc: 0.8038 - val_loss: 0.5620 - val_acc: 0.7292\n",
      "Epoch 2990/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3962 - acc: 0.8038 - val_loss: 0.5621 - val_acc: 0.7292\n",
      "Epoch 2991/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3961 - acc: 0.8038 - val_loss: 0.5624 - val_acc: 0.7292\n",
      "Epoch 2992/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3960 - acc: 0.8038 - val_loss: 0.5624 - val_acc: 0.7292\n",
      "Epoch 2993/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3961 - acc: 0.8021 - val_loss: 0.5624 - val_acc: 0.7292\n",
      "Epoch 2994/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3960 - acc: 0.8021 - val_loss: 0.5624 - val_acc: 0.7292\n",
      "Epoch 2995/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3961 - acc: 0.8038 - val_loss: 0.5623 - val_acc: 0.7292\n",
      "Epoch 2996/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3960 - acc: 0.8021 - val_loss: 0.5626 - val_acc: 0.7292\n",
      "Epoch 2997/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3960 - acc: 0.8056 - val_loss: 0.5625 - val_acc: 0.7292\n",
      "Epoch 2998/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3960 - acc: 0.8038 - val_loss: 0.5625 - val_acc: 0.7292\n",
      "Epoch 2999/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3960 - acc: 0.8021 - val_loss: 0.5625 - val_acc: 0.7292\n",
      "Epoch 3000/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3959 - acc: 0.8038 - val_loss: 0.5627 - val_acc: 0.7292\n",
      "\n",
      "accuracy is 0.729\n",
      "roc-auc is 0.795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For the last one, there was not much change in accuracy but the rocauc score increased\n",
    "\n",
    "\n",
    "#experimenting with different values\n",
    "\n",
    "#Creating Model with 2 hidden layers, each has 6 nodes and relu activation \n",
    "#The final layers has 1 node and sigmoid activation\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape=(8,),activation=\"relu\"), \n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "]) \n",
    "\n",
    "#This function summarizes the details of the model \n",
    "model_3.summary()\n",
    "\n",
    "#Experimenting with a new learning rate and a different number of epochs\n",
    "#Compiling the model with lr=0.006, training for 500 epochs \n",
    "model_3.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_4 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=3000)\n",
    "\n",
    "\n",
    "#plotting values \n",
    "n = len(run_hist_4.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_4.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_4.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_4.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_4.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')\n",
    "\n",
    "y_pred_class_nn_4 = model_3.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_4 = model_3.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_4)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_4)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_4, 'NN-3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
